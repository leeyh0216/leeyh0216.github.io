<!DOCTYPE html><html lang="ko-KR" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8829030678254956" crossorigin="anonymous"></script><meta name="pv-proxy-endpoint" content=""><meta name="generator" content="Jekyll v4.2.0" /><meta property="og:title" content="Kafka의 Topic, Partition, Segment, Message" /><meta name="author" content="leeyh0216" /><meta property="og:locale" content="ko_KR" /><meta name="description" content="Topic Topic은 메시지가 발행되는 카테고리 혹은 Feed로써, 메시지들의 스트림으로 볼 수 있다. 다양한 생산자(Producer)와 소비자(Consumer)들이 Topic에 메시지를 발행하거나, Topic으로부터 발행된 메시지를 가져와 사용한다. Kafka의 문서나 관련 서적에서 Kafka를 분산 커밋 로그(Distributed commit log)라고 부른다. 분산 커밋 로그에서의 로그가 Topic과 일치하는 개념이라고 보면 된다. Kafka 소스코드에는 Topic보다는 Log라는 용어가 더 많이 사용된다. Topic의 파티셔닝 Topic에는 수십 ~ 수천억개 이상의 메시지들이 발행될 수 있다. 하나의 Topic이 하나의 서버에 종속되는 구조라면 아래와 같은 문제점이 발생한다. Topic을 구성하는 데이터의 크기는 종속된 서버의 저장소 크기보다 작아야 한다. 메시지의 발행/소비도 1개 서버의 성능에 종속된다. 이러한 문제점을 해결하기 위하여 Kafka에서는 하나의 Topic을 1개 이상의 파티션(파티션된 로그)으로 구성된다. 각 파티션은 순차적으로 추가된 메시지로 구성되어 있으며, 메시지는 파티션 내에서의 자신의 위치를 표현하는 Offset이라는 ID를 발급받게 된다. 다만 메시지의 처리 순서는 토픽이 아닌 파티션별로 관리된다. Topic을 파티셔닝하므로써 논리적으로 Topic의 데이터 크기와 성능은 수평 확장(Horizontally Scalable) 될 수 있고, Topic을 구성하는 파티션의 갯수만큼 병렬성(Parallelism)을 확보할 수 있게 된다. HDFS에 익숙한 사람이라면 Topic과 파티션의 관계를 파일과 블록의 관계라고 생각하면 편할 것 같다. Topic의 파티션은 코드에서 org.apache.kafka.common.TopicPartition이라는 클래스로 관리된다. /** * A topic name and partition number */ public final class TopicPartition implements Serializable { private static final long serialVersionUID = -613627415771699627L; private int hash = 0; private final int partition; private final String topic; ... 또한 파티션의 이름은 kafka.log.Log 오브젝트의 logDirName을 통해 “Topic명 + 파티션 번호”로 생성한다. /** * Return a directory name for the given topic partition. The name will be in the following * format: topic-partition where topic, partition are variables. */ def logDirName(topicPartition: TopicPartition): String = { s&quot;${topicPartition.topic}-${topicPartition.partition}&quot; } Topic 생성하기 Topic과 파티션의 개념을 알았으니 이제 Kafka에 Topic을 생성해보자. ${KAFKA_HOME}/bin 디렉토리를 보면 kafka-topics.sh 스크립트가 존재하는 것을 볼 수 있다. 아래 명령어를 통해 test 라는 이름의 Topic을 생성한다. 1 2 &gt; ${KAFKA_HOME}/bin/kafka-topics.sh --create --topic test --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 Created topic test 위 명령어에서 사용한 옵션들은 아래와 같다. create: Topic 생성을 요청한다는 의미이다. create 이외에도 alter, describe, delete 기능이 존재한다. topic: 생성할 Topic의 이름이다. bootstrap-server: 작업 수행을 요청할 Kafka Cluster의 Broker를 명시한다. replication-factor: 파티션 복제본의 수이다. 여기서는 1로 설정한다. partitions: Topic을 구성하는 파티션의 수를 의미한다. 정상적으로 Topic이 생성된 경우 “Created topic test”라는 문구가 발생한다. 이미 존재하는 Topic을 생성하려 할 경우 “Error while executing topic command : Topic test already exists”라는 문구가 발생한다. 생성된 Topic의 속성을 확인하기 위해서는 describe 기능을 사용하면 된다. 아래 명령어를 입력하여 위에서 생성한 test Topic의 정보를 확인해보자. 1 2 3 &gt; ${KAFKA_HOME}/bin/kafka-topics.sh --describe --topic test --bootstrap-server localhost:9092 Topic: test PartitionCount: 1 ReplicationFactor: 1 Configs: segment.bytes=1073741824 Topic: test Partition: 0 Leader: 0 Replicas: 0 Isr: 0 위와 같이 생성된 파티션의 정보를 확인할 수 있다. 파티션 데이터는 어떻게 저장될까? Topic을 구성하는 파티션 1개는 Kafka Broker의 파티션 디렉토리 1개와 매핑된다. Broker 설정 파일(${KAFKA_HOME}/config/server.properties)에서 설정한 log.dirs 디렉토리를 확인해보면, 우리가 생성한 test Topic의 0번째 파티션이 생성되어 있는 것을 확인할 수 있다. 1 2 3 &gt; ls cleaner-offset-checkpoint meta.properties replication-offset-checkpoint log-start-offset-checkpoint recovery-point-offset-checkpoint test-0 1개의 파티션(파티션 로그)은 다시 1개 이상의 세그먼트(로그 세그먼트)로 구성된다. test-0 디렉토리에서 ls 명령어를 쳐보면, test-0 파티션을 구성하는 00000000000000000000 세그먼트를 확인할 수 있다. 1 2 3 &gt; ls 00000000000000000000.index 00000000000000000000.timeindex 00000000000000000000.log leader-epoch-checkpoint 세그먼트는 로그, 인덱스 파일로 구성되어 있다. 로그 파일: 세그먼트를 구성하는 실제 데이터가 들어 있는 파일이다. 위에서는 00000000000000000000.log 파일로 기록되어 있다. 인덱스 파일: 파티션의 논리적인 인덱스와 파일의 물리적인 인덱스를 매핑해주는 파일이다. 위에서는 00000000000000000000.index 파일로 기록되어 있다. 파일명에서 등장하는 00000000000000000000는 해당 Segment의 Base Offset이다. 여기서는 0값이 Base Offset이기 때문에, 이 파일들에 처음 기록된 메시지의 Offset은 0으로 시작하게 된다. Segment 생성 옵션 Segment 파일의 크기가 특정 바이트를 넘어섰거나, 파일이 생성된지 일정 기간이 지나면 기존 Segment를 닫고 신규 Segment를 생성하도록 설정할 수 있다. 이와 관련된 옵션은 log.segment.bytes와 log.segment.ms이다. log.segment.bytes 옵션을 사용할 경우 현재 세그먼트 파일이 해당 크기를 넘어설 경우 새로운 세그먼트가 생성된다. 테스트를 위해 해당 값을 256으로 변경하고 Broker를 재시작한 뒤, Topic에 새로운 메시지를 발행한 뒤, test-0 디렉토리를 확인해보았다. 1 2 3 4 &gt; ls 00000000000000000000.index 00000000000000000002.index 00000000000000000002.timeindex 00000000000000000000.log 00000000000000000002.log leader-epoch-checkpoint 00000000000000000000.timeindex 00000000000000000002.snapshot 기존 00000000000000000000 이외에도 00000000000000000002 관련 파일이 생성된 것을 확인할 수 있었다. 해당 Topic에 발행한 메시지의 수가 3개였는데, 두번째 Segment 파일의 Base Offset(파일명)이 2인 것으로 보아 마지막 메시지(Zero-based Index 기준으로 2번째, 실제로는 3번쨰 메시지) 1개만 00000000000000000002 Segment에 존재하는 것을 확인할 수 있었다. 코드에서 확인하기 코드 상에서는 kafka.log.LogSegment 클래스가 하나의 세그먼트와 매핑된다. class LogSegment private[log] (val log: FileRecords, val lazyOffsetIndex: LazyIndex[OffsetIndex], val lazyTimeIndex: LazyIndex[TimeIndex], val txnIndex: TransactionIndex, val baseOffset: Long, val indexIntervalBytes: Int, val rollJitterMs: Long, val time: Time) extends Logging { 생성자의 FileRecords 객체가 실제 메시지를 담고 있는 객체이며, log 확장자를 가진 파일로 저장된다. LazyIndex[OffsetIndex] 객체는 파티션의 논리적인 인덱스와 FileRecords에서의 인덱스의 매핑을 가지고 있는 객체이며, index 확장자를 가진 파일로 저장된다. 데이터의 유지(Retention) RabbitMQ와 같은 시스템들은 Consumer가 메시지를 소비하면 Topic에서 메시지를 삭제하지만, Kafka는 발행된 메시지를 일정 기간동안 유지할 수 있다. 때문에 메시지 유지 기간 동안은 컨슈머가 일시적으로 동작하지 않더라도 후행 처리가 가능하며, 필요하다면 남아 있는 데이터를 Replay하며 재처리할 수도 있다. 이는 Kafka가 메시지를 메모리가 아닌 디스크에 유지하므로써 공간적인 제약에서 일부 자유롭기 때문인 것으로 생각된다. 시간 기준으로 데이터 유지 log.retention.ms: 카프카가 메시지를 얼마 동안 보존할 지 설정할 수 있다(밀리초 단위). (로그 세그먼트 파일의 마지막 수정시간(mtime) + log.retention.ms) 시간 후에 데이터가 삭제된다. log.retention.minutes: log.retention.ms와 동일한 역할을 수행하며, 분 단위로 적용된다. log.retention.hours: log.retention.ms와 동일한 역할을 수행하며, 시간 단위로 적용된다. 위의 값들을 설정하지 않으면 log.retention.hours가 168시간(7일)로 설정된다. 또한 log.retention.ms 값을 -1로 설정하는 경우, 로그가 삭제되지 않고 계속 유지된다. 우선순위는 ms, minutes, hours 순이며, 높은 우선순위를 가진 설정 값이 낮은 우선순위를 가진 설정 값을 무시한다. 크기 기준으로 데이터 유지 log.retention.bytes 값을 설정하므로써 파티션의 로그 크기에 따라 데이터의 보존을 설정할 수 있다. 메시지(레코드) Kafka에서의 데이터 기본 단위는 메시지(혹은 레코드)이다. Message는 아래와 같은 요소로 구성된다. 가변 길이 헤더 가변 길이 키(바이트 배열) 가변 길이 메시지(바이트 배열) 코드에서 확인하기 public interface Record { Header[] EMPTY_HEADERS = new Header[0]; long offset(); int sequence(); ... org.apache.kafka.common.record.Record가 메시지를 표현하는 인터페이스이다. 위의 헤더, 키, 메시지 이외에도 offset, sequence 등 다양한 프로퍼티를 가지고 있다. 이 인터페이스를 구현한 클래스는 org.apache.kafka.common.record.DefaultRecord이다. Apache Kafka - Record 문서를 보면 아래와 같은 포맷으로 Record가 기록되는 것을 알 수 있다. 1 2 3 4 5 6 7 8 9 10 length: varint attributes: int8 bit 0~7: unused timestampDelta: varint offsetDelta: varint keyLength: varint key: byte[] valueLen: varint value: byte[] Headers =&gt; [Header] DefaultRecord 클래스의 writeTo에서 위 포맷대로 데이터를 Output Stream에 기록하는 것을 확인할 수 있다. public static int writeTo(DataOutputStream out, int offsetDelta, long timestampDelta, ByteBuffer key, ByteBuffer value, Header[] headers) throws IOException { int sizeInBytes = sizeOfBodyInBytes(offsetDelta, timestampDelta, key, value, headers); ByteUtils.writeVarint(sizeInBytes, out); ... Record Batch Kafka에서는 쓰기 처리량을 높이기 위해 여러 개의 메시지를 묶어 한번에 저장한다. 이 메시지 묶음을 Record Batch라고 하며, Record Batch에는 1개 이상의 메시지가 포함되어 있다. 또한 하나의 세그먼트에는 1개 이상의 Record Batch가 포함될 수 있다. Apache Kafka - Record Batch를 보면 아래와 같이 Record Batch에 대한 포맷을 확인할 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 baseOffset: int64 batchLength: int32 partitionLeaderEpoch: int32 magic: int8 (current magic value is 2) crc: int32 attributes: int16 bit 0~2: 0: no compression 1: gzip 2: snappy 3: lz4 4: zstd bit 3: timestampType bit 4: isTransactional (0 means not transactional) bit 5: isControlBatch (0 means not a control batch) bit 6~15: unused lastOffsetDelta: int32 firstTimestamp: int64 maxTimestamp: int64 producerId: int64 producerEpoch: int16 baseSequence: int32 records: [Record] 파일에서 확인하기 test-0 디렉토리의 00000000000000000000.log 파일을 Hex Fiend라는 프로그램을 통해 열어보면, 위의 포맷이 정상적으로 기록되었는지 확인할 수 있다. firstTimestamp가 기록된 부분(28byte부터 8byte)을 확인해보았다. Hex 값으로는 0x00000171D1105FE6, Decimal 값으로는 1588350443494이 나오고 이 값을 Timestamp 변환기로 바꾸어보면 첫번째 메시지를 발행한 시각(여기서는 2020년 5월 2일 토요일 오전 1:27:23.494)이 나오게 된다. 코드에서 확인하기 public interface RecordBatch extends Iterable&lt;Record&gt; { ... } org.apache.kafka.common.record.RecordBatch가 Record Batch를 표현하는 인터페이스이다. Record Batch는 1개 이상의 메시지(Record)를 포함하는 개념이기 때문에, 이 인터페이스를 구현한 클래스는 내부 메시지 순회를 위해 Iterable&lt;Record&gt; 인터페이스를 구현해야 한다. 이를 실제로 구현한 클래스는 org.apache.kafka.common.record.DefaultRecordBatch 클래스이며, Record Batch의 데이터를 기록하기 위한 Bytebuffer와 각종 쓰기 메서드들을 가지고 있는 것을 확인할 수 있다. public class DefaultRecordBatch extends AbstractRecordBatch implements MutableRecordBatch { ... private final ByteBuffer buffer; DefaultRecordBatch(ByteBuffer buffer) { this.buffer = buffer; } ... } 세그먼트와 Record Batch 세그먼트는 1개 이상의 Record Batch로 구성되어 있고, Record Batch는 1개 이상의 메시지로 구성되어 있다. 세그먼트의 로그 파일 내에는 1개 이상의 Record Batch가 포함되어 있을 수 있는 것이고, 코드 상에서도 아래와 같이 FileRecords 클래스 내에 여러 개의 RecordBatch를 가지는 구조로 되어 있는 것을 확인할 수 있다. public class FileRecords extends AbstractRecords implements Closeable { ... private final Iterable&lt;FileLogInputStream.FileChannelRecordBatch&gt; batches; ... }" /><meta property="og:description" content="Topic Topic은 메시지가 발행되는 카테고리 혹은 Feed로써, 메시지들의 스트림으로 볼 수 있다. 다양한 생산자(Producer)와 소비자(Consumer)들이 Topic에 메시지를 발행하거나, Topic으로부터 발행된 메시지를 가져와 사용한다. Kafka의 문서나 관련 서적에서 Kafka를 분산 커밋 로그(Distributed commit log)라고 부른다. 분산 커밋 로그에서의 로그가 Topic과 일치하는 개념이라고 보면 된다. Kafka 소스코드에는 Topic보다는 Log라는 용어가 더 많이 사용된다. Topic의 파티셔닝 Topic에는 수십 ~ 수천억개 이상의 메시지들이 발행될 수 있다. 하나의 Topic이 하나의 서버에 종속되는 구조라면 아래와 같은 문제점이 발생한다. Topic을 구성하는 데이터의 크기는 종속된 서버의 저장소 크기보다 작아야 한다. 메시지의 발행/소비도 1개 서버의 성능에 종속된다. 이러한 문제점을 해결하기 위하여 Kafka에서는 하나의 Topic을 1개 이상의 파티션(파티션된 로그)으로 구성된다. 각 파티션은 순차적으로 추가된 메시지로 구성되어 있으며, 메시지는 파티션 내에서의 자신의 위치를 표현하는 Offset이라는 ID를 발급받게 된다. 다만 메시지의 처리 순서는 토픽이 아닌 파티션별로 관리된다. Topic을 파티셔닝하므로써 논리적으로 Topic의 데이터 크기와 성능은 수평 확장(Horizontally Scalable) 될 수 있고, Topic을 구성하는 파티션의 갯수만큼 병렬성(Parallelism)을 확보할 수 있게 된다. HDFS에 익숙한 사람이라면 Topic과 파티션의 관계를 파일과 블록의 관계라고 생각하면 편할 것 같다. Topic의 파티션은 코드에서 org.apache.kafka.common.TopicPartition이라는 클래스로 관리된다. /** * A topic name and partition number */ public final class TopicPartition implements Serializable { private static final long serialVersionUID = -613627415771699627L; private int hash = 0; private final int partition; private final String topic; ... 또한 파티션의 이름은 kafka.log.Log 오브젝트의 logDirName을 통해 “Topic명 + 파티션 번호”로 생성한다. /** * Return a directory name for the given topic partition. The name will be in the following * format: topic-partition where topic, partition are variables. */ def logDirName(topicPartition: TopicPartition): String = { s&quot;${topicPartition.topic}-${topicPartition.partition}&quot; } Topic 생성하기 Topic과 파티션의 개념을 알았으니 이제 Kafka에 Topic을 생성해보자. ${KAFKA_HOME}/bin 디렉토리를 보면 kafka-topics.sh 스크립트가 존재하는 것을 볼 수 있다. 아래 명령어를 통해 test 라는 이름의 Topic을 생성한다. 1 2 &gt; ${KAFKA_HOME}/bin/kafka-topics.sh --create --topic test --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 Created topic test 위 명령어에서 사용한 옵션들은 아래와 같다. create: Topic 생성을 요청한다는 의미이다. create 이외에도 alter, describe, delete 기능이 존재한다. topic: 생성할 Topic의 이름이다. bootstrap-server: 작업 수행을 요청할 Kafka Cluster의 Broker를 명시한다. replication-factor: 파티션 복제본의 수이다. 여기서는 1로 설정한다. partitions: Topic을 구성하는 파티션의 수를 의미한다. 정상적으로 Topic이 생성된 경우 “Created topic test”라는 문구가 발생한다. 이미 존재하는 Topic을 생성하려 할 경우 “Error while executing topic command : Topic test already exists”라는 문구가 발생한다. 생성된 Topic의 속성을 확인하기 위해서는 describe 기능을 사용하면 된다. 아래 명령어를 입력하여 위에서 생성한 test Topic의 정보를 확인해보자. 1 2 3 &gt; ${KAFKA_HOME}/bin/kafka-topics.sh --describe --topic test --bootstrap-server localhost:9092 Topic: test PartitionCount: 1 ReplicationFactor: 1 Configs: segment.bytes=1073741824 Topic: test Partition: 0 Leader: 0 Replicas: 0 Isr: 0 위와 같이 생성된 파티션의 정보를 확인할 수 있다. 파티션 데이터는 어떻게 저장될까? Topic을 구성하는 파티션 1개는 Kafka Broker의 파티션 디렉토리 1개와 매핑된다. Broker 설정 파일(${KAFKA_HOME}/config/server.properties)에서 설정한 log.dirs 디렉토리를 확인해보면, 우리가 생성한 test Topic의 0번째 파티션이 생성되어 있는 것을 확인할 수 있다. 1 2 3 &gt; ls cleaner-offset-checkpoint meta.properties replication-offset-checkpoint log-start-offset-checkpoint recovery-point-offset-checkpoint test-0 1개의 파티션(파티션 로그)은 다시 1개 이상의 세그먼트(로그 세그먼트)로 구성된다. test-0 디렉토리에서 ls 명령어를 쳐보면, test-0 파티션을 구성하는 00000000000000000000 세그먼트를 확인할 수 있다. 1 2 3 &gt; ls 00000000000000000000.index 00000000000000000000.timeindex 00000000000000000000.log leader-epoch-checkpoint 세그먼트는 로그, 인덱스 파일로 구성되어 있다. 로그 파일: 세그먼트를 구성하는 실제 데이터가 들어 있는 파일이다. 위에서는 00000000000000000000.log 파일로 기록되어 있다. 인덱스 파일: 파티션의 논리적인 인덱스와 파일의 물리적인 인덱스를 매핑해주는 파일이다. 위에서는 00000000000000000000.index 파일로 기록되어 있다. 파일명에서 등장하는 00000000000000000000는 해당 Segment의 Base Offset이다. 여기서는 0값이 Base Offset이기 때문에, 이 파일들에 처음 기록된 메시지의 Offset은 0으로 시작하게 된다. Segment 생성 옵션 Segment 파일의 크기가 특정 바이트를 넘어섰거나, 파일이 생성된지 일정 기간이 지나면 기존 Segment를 닫고 신규 Segment를 생성하도록 설정할 수 있다. 이와 관련된 옵션은 log.segment.bytes와 log.segment.ms이다. log.segment.bytes 옵션을 사용할 경우 현재 세그먼트 파일이 해당 크기를 넘어설 경우 새로운 세그먼트가 생성된다. 테스트를 위해 해당 값을 256으로 변경하고 Broker를 재시작한 뒤, Topic에 새로운 메시지를 발행한 뒤, test-0 디렉토리를 확인해보았다. 1 2 3 4 &gt; ls 00000000000000000000.index 00000000000000000002.index 00000000000000000002.timeindex 00000000000000000000.log 00000000000000000002.log leader-epoch-checkpoint 00000000000000000000.timeindex 00000000000000000002.snapshot 기존 00000000000000000000 이외에도 00000000000000000002 관련 파일이 생성된 것을 확인할 수 있었다. 해당 Topic에 발행한 메시지의 수가 3개였는데, 두번째 Segment 파일의 Base Offset(파일명)이 2인 것으로 보아 마지막 메시지(Zero-based Index 기준으로 2번째, 실제로는 3번쨰 메시지) 1개만 00000000000000000002 Segment에 존재하는 것을 확인할 수 있었다. 코드에서 확인하기 코드 상에서는 kafka.log.LogSegment 클래스가 하나의 세그먼트와 매핑된다. class LogSegment private[log] (val log: FileRecords, val lazyOffsetIndex: LazyIndex[OffsetIndex], val lazyTimeIndex: LazyIndex[TimeIndex], val txnIndex: TransactionIndex, val baseOffset: Long, val indexIntervalBytes: Int, val rollJitterMs: Long, val time: Time) extends Logging { 생성자의 FileRecords 객체가 실제 메시지를 담고 있는 객체이며, log 확장자를 가진 파일로 저장된다. LazyIndex[OffsetIndex] 객체는 파티션의 논리적인 인덱스와 FileRecords에서의 인덱스의 매핑을 가지고 있는 객체이며, index 확장자를 가진 파일로 저장된다. 데이터의 유지(Retention) RabbitMQ와 같은 시스템들은 Consumer가 메시지를 소비하면 Topic에서 메시지를 삭제하지만, Kafka는 발행된 메시지를 일정 기간동안 유지할 수 있다. 때문에 메시지 유지 기간 동안은 컨슈머가 일시적으로 동작하지 않더라도 후행 처리가 가능하며, 필요하다면 남아 있는 데이터를 Replay하며 재처리할 수도 있다. 이는 Kafka가 메시지를 메모리가 아닌 디스크에 유지하므로써 공간적인 제약에서 일부 자유롭기 때문인 것으로 생각된다. 시간 기준으로 데이터 유지 log.retention.ms: 카프카가 메시지를 얼마 동안 보존할 지 설정할 수 있다(밀리초 단위). (로그 세그먼트 파일의 마지막 수정시간(mtime) + log.retention.ms) 시간 후에 데이터가 삭제된다. log.retention.minutes: log.retention.ms와 동일한 역할을 수행하며, 분 단위로 적용된다. log.retention.hours: log.retention.ms와 동일한 역할을 수행하며, 시간 단위로 적용된다. 위의 값들을 설정하지 않으면 log.retention.hours가 168시간(7일)로 설정된다. 또한 log.retention.ms 값을 -1로 설정하는 경우, 로그가 삭제되지 않고 계속 유지된다. 우선순위는 ms, minutes, hours 순이며, 높은 우선순위를 가진 설정 값이 낮은 우선순위를 가진 설정 값을 무시한다. 크기 기준으로 데이터 유지 log.retention.bytes 값을 설정하므로써 파티션의 로그 크기에 따라 데이터의 보존을 설정할 수 있다. 메시지(레코드) Kafka에서의 데이터 기본 단위는 메시지(혹은 레코드)이다. Message는 아래와 같은 요소로 구성된다. 가변 길이 헤더 가변 길이 키(바이트 배열) 가변 길이 메시지(바이트 배열) 코드에서 확인하기 public interface Record { Header[] EMPTY_HEADERS = new Header[0]; long offset(); int sequence(); ... org.apache.kafka.common.record.Record가 메시지를 표현하는 인터페이스이다. 위의 헤더, 키, 메시지 이외에도 offset, sequence 등 다양한 프로퍼티를 가지고 있다. 이 인터페이스를 구현한 클래스는 org.apache.kafka.common.record.DefaultRecord이다. Apache Kafka - Record 문서를 보면 아래와 같은 포맷으로 Record가 기록되는 것을 알 수 있다. 1 2 3 4 5 6 7 8 9 10 length: varint attributes: int8 bit 0~7: unused timestampDelta: varint offsetDelta: varint keyLength: varint key: byte[] valueLen: varint value: byte[] Headers =&gt; [Header] DefaultRecord 클래스의 writeTo에서 위 포맷대로 데이터를 Output Stream에 기록하는 것을 확인할 수 있다. public static int writeTo(DataOutputStream out, int offsetDelta, long timestampDelta, ByteBuffer key, ByteBuffer value, Header[] headers) throws IOException { int sizeInBytes = sizeOfBodyInBytes(offsetDelta, timestampDelta, key, value, headers); ByteUtils.writeVarint(sizeInBytes, out); ... Record Batch Kafka에서는 쓰기 처리량을 높이기 위해 여러 개의 메시지를 묶어 한번에 저장한다. 이 메시지 묶음을 Record Batch라고 하며, Record Batch에는 1개 이상의 메시지가 포함되어 있다. 또한 하나의 세그먼트에는 1개 이상의 Record Batch가 포함될 수 있다. Apache Kafka - Record Batch를 보면 아래와 같이 Record Batch에 대한 포맷을 확인할 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 baseOffset: int64 batchLength: int32 partitionLeaderEpoch: int32 magic: int8 (current magic value is 2) crc: int32 attributes: int16 bit 0~2: 0: no compression 1: gzip 2: snappy 3: lz4 4: zstd bit 3: timestampType bit 4: isTransactional (0 means not transactional) bit 5: isControlBatch (0 means not a control batch) bit 6~15: unused lastOffsetDelta: int32 firstTimestamp: int64 maxTimestamp: int64 producerId: int64 producerEpoch: int16 baseSequence: int32 records: [Record] 파일에서 확인하기 test-0 디렉토리의 00000000000000000000.log 파일을 Hex Fiend라는 프로그램을 통해 열어보면, 위의 포맷이 정상적으로 기록되었는지 확인할 수 있다. firstTimestamp가 기록된 부분(28byte부터 8byte)을 확인해보았다. Hex 값으로는 0x00000171D1105FE6, Decimal 값으로는 1588350443494이 나오고 이 값을 Timestamp 변환기로 바꾸어보면 첫번째 메시지를 발행한 시각(여기서는 2020년 5월 2일 토요일 오전 1:27:23.494)이 나오게 된다. 코드에서 확인하기 public interface RecordBatch extends Iterable&lt;Record&gt; { ... } org.apache.kafka.common.record.RecordBatch가 Record Batch를 표현하는 인터페이스이다. Record Batch는 1개 이상의 메시지(Record)를 포함하는 개념이기 때문에, 이 인터페이스를 구현한 클래스는 내부 메시지 순회를 위해 Iterable&lt;Record&gt; 인터페이스를 구현해야 한다. 이를 실제로 구현한 클래스는 org.apache.kafka.common.record.DefaultRecordBatch 클래스이며, Record Batch의 데이터를 기록하기 위한 Bytebuffer와 각종 쓰기 메서드들을 가지고 있는 것을 확인할 수 있다. public class DefaultRecordBatch extends AbstractRecordBatch implements MutableRecordBatch { ... private final ByteBuffer buffer; DefaultRecordBatch(ByteBuffer buffer) { this.buffer = buffer; } ... } 세그먼트와 Record Batch 세그먼트는 1개 이상의 Record Batch로 구성되어 있고, Record Batch는 1개 이상의 메시지로 구성되어 있다. 세그먼트의 로그 파일 내에는 1개 이상의 Record Batch가 포함되어 있을 수 있는 것이고, 코드 상에서도 아래와 같이 FileRecords 클래스 내에 여러 개의 RecordBatch를 가지는 구조로 되어 있는 것을 확인할 수 있다. public class FileRecords extends AbstractRecords implements Closeable { ... private final Iterable&lt;FileLogInputStream.FileChannelRecordBatch&gt; batches; ... }" /><link rel="canonical" href="https://leeyh0216.github.io/posts/kafka_concept/" /><meta property="og:url" content="https://leeyh0216.github.io/posts/kafka_concept/" /><meta property="og:site_name" content="leeyh0216’s devlog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-05-02T15:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Kafka의 Topic, Partition, Segment, Message" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@leeyh0216" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"author":{"@type":"Person","name":"leeyh0216"},"description":"Topic Topic은 메시지가 발행되는 카테고리 혹은 Feed로써, 메시지들의 스트림으로 볼 수 있다. 다양한 생산자(Producer)와 소비자(Consumer)들이 Topic에 메시지를 발행하거나, Topic으로부터 발행된 메시지를 가져와 사용한다. Kafka의 문서나 관련 서적에서 Kafka를 분산 커밋 로그(Distributed commit log)라고 부른다. 분산 커밋 로그에서의 로그가 Topic과 일치하는 개념이라고 보면 된다. Kafka 소스코드에는 Topic보다는 Log라는 용어가 더 많이 사용된다. Topic의 파티셔닝 Topic에는 수십 ~ 수천억개 이상의 메시지들이 발행될 수 있다. 하나의 Topic이 하나의 서버에 종속되는 구조라면 아래와 같은 문제점이 발생한다. Topic을 구성하는 데이터의 크기는 종속된 서버의 저장소 크기보다 작아야 한다. 메시지의 발행/소비도 1개 서버의 성능에 종속된다. 이러한 문제점을 해결하기 위하여 Kafka에서는 하나의 Topic을 1개 이상의 파티션(파티션된 로그)으로 구성된다. 각 파티션은 순차적으로 추가된 메시지로 구성되어 있으며, 메시지는 파티션 내에서의 자신의 위치를 표현하는 Offset이라는 ID를 발급받게 된다. 다만 메시지의 처리 순서는 토픽이 아닌 파티션별로 관리된다. Topic을 파티셔닝하므로써 논리적으로 Topic의 데이터 크기와 성능은 수평 확장(Horizontally Scalable) 될 수 있고, Topic을 구성하는 파티션의 갯수만큼 병렬성(Parallelism)을 확보할 수 있게 된다. HDFS에 익숙한 사람이라면 Topic과 파티션의 관계를 파일과 블록의 관계라고 생각하면 편할 것 같다. Topic의 파티션은 코드에서 org.apache.kafka.common.TopicPartition이라는 클래스로 관리된다. /** * A topic name and partition number */ public final class TopicPartition implements Serializable { private static final long serialVersionUID = -613627415771699627L; private int hash = 0; private final int partition; private final String topic; ... 또한 파티션의 이름은 kafka.log.Log 오브젝트의 logDirName을 통해 “Topic명 + 파티션 번호”로 생성한다. /** * Return a directory name for the given topic partition. The name will be in the following * format: topic-partition where topic, partition are variables. */ def logDirName(topicPartition: TopicPartition): String = { s&quot;${topicPartition.topic}-${topicPartition.partition}&quot; } Topic 생성하기 Topic과 파티션의 개념을 알았으니 이제 Kafka에 Topic을 생성해보자. ${KAFKA_HOME}/bin 디렉토리를 보면 kafka-topics.sh 스크립트가 존재하는 것을 볼 수 있다. 아래 명령어를 통해 test 라는 이름의 Topic을 생성한다. 1 2 &gt; ${KAFKA_HOME}/bin/kafka-topics.sh --create --topic test --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 Created topic test 위 명령어에서 사용한 옵션들은 아래와 같다. create: Topic 생성을 요청한다는 의미이다. create 이외에도 alter, describe, delete 기능이 존재한다. topic: 생성할 Topic의 이름이다. bootstrap-server: 작업 수행을 요청할 Kafka Cluster의 Broker를 명시한다. replication-factor: 파티션 복제본의 수이다. 여기서는 1로 설정한다. partitions: Topic을 구성하는 파티션의 수를 의미한다. 정상적으로 Topic이 생성된 경우 “Created topic test”라는 문구가 발생한다. 이미 존재하는 Topic을 생성하려 할 경우 “Error while executing topic command : Topic test already exists”라는 문구가 발생한다. 생성된 Topic의 속성을 확인하기 위해서는 describe 기능을 사용하면 된다. 아래 명령어를 입력하여 위에서 생성한 test Topic의 정보를 확인해보자. 1 2 3 &gt; ${KAFKA_HOME}/bin/kafka-topics.sh --describe --topic test --bootstrap-server localhost:9092 Topic: test PartitionCount: 1 ReplicationFactor: 1 Configs: segment.bytes=1073741824 Topic: test Partition: 0 Leader: 0 Replicas: 0 Isr: 0 위와 같이 생성된 파티션의 정보를 확인할 수 있다. 파티션 데이터는 어떻게 저장될까? Topic을 구성하는 파티션 1개는 Kafka Broker의 파티션 디렉토리 1개와 매핑된다. Broker 설정 파일(${KAFKA_HOME}/config/server.properties)에서 설정한 log.dirs 디렉토리를 확인해보면, 우리가 생성한 test Topic의 0번째 파티션이 생성되어 있는 것을 확인할 수 있다. 1 2 3 &gt; ls cleaner-offset-checkpoint meta.properties replication-offset-checkpoint log-start-offset-checkpoint recovery-point-offset-checkpoint test-0 1개의 파티션(파티션 로그)은 다시 1개 이상의 세그먼트(로그 세그먼트)로 구성된다. test-0 디렉토리에서 ls 명령어를 쳐보면, test-0 파티션을 구성하는 00000000000000000000 세그먼트를 확인할 수 있다. 1 2 3 &gt; ls 00000000000000000000.index 00000000000000000000.timeindex 00000000000000000000.log leader-epoch-checkpoint 세그먼트는 로그, 인덱스 파일로 구성되어 있다. 로그 파일: 세그먼트를 구성하는 실제 데이터가 들어 있는 파일이다. 위에서는 00000000000000000000.log 파일로 기록되어 있다. 인덱스 파일: 파티션의 논리적인 인덱스와 파일의 물리적인 인덱스를 매핑해주는 파일이다. 위에서는 00000000000000000000.index 파일로 기록되어 있다. 파일명에서 등장하는 00000000000000000000는 해당 Segment의 Base Offset이다. 여기서는 0값이 Base Offset이기 때문에, 이 파일들에 처음 기록된 메시지의 Offset은 0으로 시작하게 된다. Segment 생성 옵션 Segment 파일의 크기가 특정 바이트를 넘어섰거나, 파일이 생성된지 일정 기간이 지나면 기존 Segment를 닫고 신규 Segment를 생성하도록 설정할 수 있다. 이와 관련된 옵션은 log.segment.bytes와 log.segment.ms이다. log.segment.bytes 옵션을 사용할 경우 현재 세그먼트 파일이 해당 크기를 넘어설 경우 새로운 세그먼트가 생성된다. 테스트를 위해 해당 값을 256으로 변경하고 Broker를 재시작한 뒤, Topic에 새로운 메시지를 발행한 뒤, test-0 디렉토리를 확인해보았다. 1 2 3 4 &gt; ls 00000000000000000000.index 00000000000000000002.index 00000000000000000002.timeindex 00000000000000000000.log 00000000000000000002.log leader-epoch-checkpoint 00000000000000000000.timeindex 00000000000000000002.snapshot 기존 00000000000000000000 이외에도 00000000000000000002 관련 파일이 생성된 것을 확인할 수 있었다. 해당 Topic에 발행한 메시지의 수가 3개였는데, 두번째 Segment 파일의 Base Offset(파일명)이 2인 것으로 보아 마지막 메시지(Zero-based Index 기준으로 2번째, 실제로는 3번쨰 메시지) 1개만 00000000000000000002 Segment에 존재하는 것을 확인할 수 있었다. 코드에서 확인하기 코드 상에서는 kafka.log.LogSegment 클래스가 하나의 세그먼트와 매핑된다. class LogSegment private[log] (val log: FileRecords, val lazyOffsetIndex: LazyIndex[OffsetIndex], val lazyTimeIndex: LazyIndex[TimeIndex], val txnIndex: TransactionIndex, val baseOffset: Long, val indexIntervalBytes: Int, val rollJitterMs: Long, val time: Time) extends Logging { 생성자의 FileRecords 객체가 실제 메시지를 담고 있는 객체이며, log 확장자를 가진 파일로 저장된다. LazyIndex[OffsetIndex] 객체는 파티션의 논리적인 인덱스와 FileRecords에서의 인덱스의 매핑을 가지고 있는 객체이며, index 확장자를 가진 파일로 저장된다. 데이터의 유지(Retention) RabbitMQ와 같은 시스템들은 Consumer가 메시지를 소비하면 Topic에서 메시지를 삭제하지만, Kafka는 발행된 메시지를 일정 기간동안 유지할 수 있다. 때문에 메시지 유지 기간 동안은 컨슈머가 일시적으로 동작하지 않더라도 후행 처리가 가능하며, 필요하다면 남아 있는 데이터를 Replay하며 재처리할 수도 있다. 이는 Kafka가 메시지를 메모리가 아닌 디스크에 유지하므로써 공간적인 제약에서 일부 자유롭기 때문인 것으로 생각된다. 시간 기준으로 데이터 유지 log.retention.ms: 카프카가 메시지를 얼마 동안 보존할 지 설정할 수 있다(밀리초 단위). (로그 세그먼트 파일의 마지막 수정시간(mtime) + log.retention.ms) 시간 후에 데이터가 삭제된다. log.retention.minutes: log.retention.ms와 동일한 역할을 수행하며, 분 단위로 적용된다. log.retention.hours: log.retention.ms와 동일한 역할을 수행하며, 시간 단위로 적용된다. 위의 값들을 설정하지 않으면 log.retention.hours가 168시간(7일)로 설정된다. 또한 log.retention.ms 값을 -1로 설정하는 경우, 로그가 삭제되지 않고 계속 유지된다. 우선순위는 ms, minutes, hours 순이며, 높은 우선순위를 가진 설정 값이 낮은 우선순위를 가진 설정 값을 무시한다. 크기 기준으로 데이터 유지 log.retention.bytes 값을 설정하므로써 파티션의 로그 크기에 따라 데이터의 보존을 설정할 수 있다. 메시지(레코드) Kafka에서의 데이터 기본 단위는 메시지(혹은 레코드)이다. Message는 아래와 같은 요소로 구성된다. 가변 길이 헤더 가변 길이 키(바이트 배열) 가변 길이 메시지(바이트 배열) 코드에서 확인하기 public interface Record { Header[] EMPTY_HEADERS = new Header[0]; long offset(); int sequence(); ... org.apache.kafka.common.record.Record가 메시지를 표현하는 인터페이스이다. 위의 헤더, 키, 메시지 이외에도 offset, sequence 등 다양한 프로퍼티를 가지고 있다. 이 인터페이스를 구현한 클래스는 org.apache.kafka.common.record.DefaultRecord이다. Apache Kafka - Record 문서를 보면 아래와 같은 포맷으로 Record가 기록되는 것을 알 수 있다. 1 2 3 4 5 6 7 8 9 10 length: varint attributes: int8 bit 0~7: unused timestampDelta: varint offsetDelta: varint keyLength: varint key: byte[] valueLen: varint value: byte[] Headers =&gt; [Header] DefaultRecord 클래스의 writeTo에서 위 포맷대로 데이터를 Output Stream에 기록하는 것을 확인할 수 있다. public static int writeTo(DataOutputStream out, int offsetDelta, long timestampDelta, ByteBuffer key, ByteBuffer value, Header[] headers) throws IOException { int sizeInBytes = sizeOfBodyInBytes(offsetDelta, timestampDelta, key, value, headers); ByteUtils.writeVarint(sizeInBytes, out); ... Record Batch Kafka에서는 쓰기 처리량을 높이기 위해 여러 개의 메시지를 묶어 한번에 저장한다. 이 메시지 묶음을 Record Batch라고 하며, Record Batch에는 1개 이상의 메시지가 포함되어 있다. 또한 하나의 세그먼트에는 1개 이상의 Record Batch가 포함될 수 있다. Apache Kafka - Record Batch를 보면 아래와 같이 Record Batch에 대한 포맷을 확인할 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 baseOffset: int64 batchLength: int32 partitionLeaderEpoch: int32 magic: int8 (current magic value is 2) crc: int32 attributes: int16 bit 0~2: 0: no compression 1: gzip 2: snappy 3: lz4 4: zstd bit 3: timestampType bit 4: isTransactional (0 means not transactional) bit 5: isControlBatch (0 means not a control batch) bit 6~15: unused lastOffsetDelta: int32 firstTimestamp: int64 maxTimestamp: int64 producerId: int64 producerEpoch: int16 baseSequence: int32 records: [Record] 파일에서 확인하기 test-0 디렉토리의 00000000000000000000.log 파일을 Hex Fiend라는 프로그램을 통해 열어보면, 위의 포맷이 정상적으로 기록되었는지 확인할 수 있다. firstTimestamp가 기록된 부분(28byte부터 8byte)을 확인해보았다. Hex 값으로는 0x00000171D1105FE6, Decimal 값으로는 1588350443494이 나오고 이 값을 Timestamp 변환기로 바꾸어보면 첫번째 메시지를 발행한 시각(여기서는 2020년 5월 2일 토요일 오전 1:27:23.494)이 나오게 된다. 코드에서 확인하기 public interface RecordBatch extends Iterable&lt;Record&gt; { ... } org.apache.kafka.common.record.RecordBatch가 Record Batch를 표현하는 인터페이스이다. Record Batch는 1개 이상의 메시지(Record)를 포함하는 개념이기 때문에, 이 인터페이스를 구현한 클래스는 내부 메시지 순회를 위해 Iterable&lt;Record&gt; 인터페이스를 구현해야 한다. 이를 실제로 구현한 클래스는 org.apache.kafka.common.record.DefaultRecordBatch 클래스이며, Record Batch의 데이터를 기록하기 위한 Bytebuffer와 각종 쓰기 메서드들을 가지고 있는 것을 확인할 수 있다. public class DefaultRecordBatch extends AbstractRecordBatch implements MutableRecordBatch { ... private final ByteBuffer buffer; DefaultRecordBatch(ByteBuffer buffer) { this.buffer = buffer; } ... } 세그먼트와 Record Batch 세그먼트는 1개 이상의 Record Batch로 구성되어 있고, Record Batch는 1개 이상의 메시지로 구성되어 있다. 세그먼트의 로그 파일 내에는 1개 이상의 Record Batch가 포함되어 있을 수 있는 것이고, 코드 상에서도 아래와 같이 FileRecords 클래스 내에 여러 개의 RecordBatch를 가지는 구조로 되어 있는 것을 확인할 수 있다. public class FileRecords extends AbstractRecords implements Closeable { ... private final Iterable&lt;FileLogInputStream.FileChannelRecordBatch&gt; batches; ... }","url":"https://leeyh0216.github.io/posts/kafka_concept/","@type":"BlogPosting","headline":"Kafka의 Topic, Partition, Segment, Message","dateModified":"2020-05-02T15:00:00+09:00","datePublished":"2020-05-02T15:00:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://leeyh0216.github.io/posts/kafka_concept/"},"@context":"https://schema.org"}</script><title>Kafka의 Topic, Partition, Segment, Message | leeyh0216's devlog</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script async src="https://cdn.jsdelivr.net/npm/countup.js@1.9.3/dist/countUp.min.js"></script> <script async src="/assets/js/dist/pvreport.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=UA-129061352-1"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-129061352-1'); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://cdn.jsdelivr.net/gh/cotes2020/chirpy-images/commons/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">leeyh0216's devlog</a></div><div class="site-subtitle font-italic">개발/일상 블로그</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/leeyh0216" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://www.linkedin.com/in/%EC%9A%A9%ED%99%98-%EC%9D%B4-84222a119/" aria-label="linkedin" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['leeyh0216','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Kafka의 Topic, Partition, Segment, Message</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Kafka의 Topic, Partition, Segment, Message</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> leeyh0216 </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Sat, May 2, 2020, 3:00 PM +0900" prep="on" > May 2, 2020 <i class="unloaded">2020-05-02T15:00:00+09:00</i> </span></div><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3244 words">18 min</span> <span id="pv" class="pageviews"><i class="fas fa-spinner fa-spin fa-fw"></i></span></div></div><div class="post-content"><h1 id="topic">Topic</h1><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://kafka.apache.org/25/images/kafka-apis.png" alt="Kafka Use Case" /></p><p>Topic은 메시지가 발행되는 카테고리 혹은 Feed로써, 메시지들의 스트림으로 볼 수 있다. 다양한 생산자(Producer)와 소비자(Consumer)들이 Topic에 메시지를 발행하거나, Topic으로부터 발행된 메시지를 가져와 사용한다.</p><blockquote><p>Kafka의 문서나 관련 서적에서 Kafka를 분산 커밋 로그(Distributed commit log)라고 부른다. 분산 커밋 로그에서의 로그가 Topic과 일치하는 개념이라고 보면 된다. Kafka 소스코드에는 Topic보다는 Log라는 용어가 더 많이 사용된다.</p></blockquote><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://kafka.apache.org/25/images/log_anatomy.png" alt="Kafka Topic" /></p><h2 id="topic의-파티셔닝">Topic의 파티셔닝</h2><p>Topic에는 수십 ~ 수천억개 이상의 메시지들이 발행될 수 있다. 하나의 Topic이 하나의 서버에 종속되는 구조라면 아래와 같은 문제점이 발생한다.</p><ul><li>Topic을 구성하는 데이터의 크기는 종속된 서버의 저장소 크기보다 작아야 한다.<li>메시지의 발행/소비도 1개 서버의 성능에 종속된다.</ul><p>이러한 문제점을 해결하기 위하여 Kafka에서는 <strong>하나의 Topic을 1개 이상의 파티션(파티션된 로그)으로 구성</strong>된다. 각 파티션은 순차적으로 추가된 메시지로 구성되어 있으며, <strong>메시지는 파티션 내에서의 자신의 위치를 표현하는 Offset이라는 ID를 발급</strong>받게 된다.</p><blockquote><p>다만 메시지의 처리 순서는 토픽이 아닌 파티션별로 관리된다.</p></blockquote><p>Topic을 파티셔닝하므로써 논리적으로 Topic의 <strong>데이터 크기와 성능은 수평 확장(Horizontally Scalable)</strong> 될 수 있고, Topic을 구성하는 <strong>파티션의 갯수만큼 병렬성(Parallelism)을 확보</strong>할 수 있게 된다.</p><blockquote><p>HDFS에 익숙한 사람이라면 Topic과 파티션의 관계를 파일과 블록의 관계라고 생각하면 편할 것 같다.</p></blockquote><p>Topic의 파티션은 코드에서 <code class="language-plaintext highlighter-rouge">org.apache.kafka.common.TopicPartition</code>이라는 클래스로 관리된다.</p><figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="cm">/**
 * A topic name and partition number
 */</span>
<span class="kd">public</span> <span class="kd">final</span> <span class="kd">class</span> <span class="nc">TopicPartition</span> <span class="kd">implements</span> <span class="nc">Serializable</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="kd">static</span> <span class="kd">final</span> <span class="kt">long</span> <span class="n">serialVersionUID</span> <span class="o">=</span> <span class="o">-</span><span class="mi">613627415771699627L</span><span class="o">;</span>

    <span class="kd">private</span> <span class="kt">int</span> <span class="n">hash</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="kt">int</span> <span class="n">partition</span><span class="o">;</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="nc">String</span> <span class="n">topic</span><span class="o">;</span>
<span class="o">...</span></code></pre></figure><p>또한 파티션의 이름은 <code class="language-plaintext highlighter-rouge">kafka.log.Log</code> 오브젝트의 <code class="language-plaintext highlighter-rouge">logDirName</code>을 통해 “Topic명 + 파티션 번호”로 생성한다.</p><figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="cm">/**
  * Return a directory name for the given topic partition. The name will be in the following
  * format: topic-partition where topic, partition are variables.
*/</span>
<span class="k">def</span> <span class="nf">logDirName</span><span class="o">(</span><span class="n">topicPartition</span><span class="k">:</span> <span class="kt">TopicPartition</span><span class="o">)</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="o">{</span>
  <span class="n">s</span><span class="s">"${topicPartition.topic}-${topicPartition.partition}"</span>
<span class="o">}</span></code></pre></figure><h2 id="topic-생성하기">Topic 생성하기</h2><p>Topic과 파티션의 개념을 알았으니 이제 Kafka에 Topic을 생성해보자.</p><p><code class="language-plaintext highlighter-rouge">${KAFKA_HOME}/bin</code> 디렉토리를 보면 <code class="language-plaintext highlighter-rouge">kafka-topics.sh</code> 스크립트가 존재하는 것을 볼 수 있다. 아래 명령어를 통해 <code class="language-plaintext highlighter-rouge">test</code> 라는 이름의 Topic을 생성한다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>&gt; ${KAFKA_HOME}/bin/kafka-topics.sh --create --topic test --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1
Created topic test
</pre></table></code></div></div><p>위 명령어에서 사용한 옵션들은 아래와 같다.</p><ul><li>create: Topic 생성을 요청한다는 의미이다. create 이외에도 alter, describe, delete 기능이 존재한다.<li>topic: 생성할 Topic의 이름이다.<li>bootstrap-server: 작업 수행을 요청할 Kafka Cluster의 Broker를 명시한다.<li>replication-factor: 파티션 복제본의 수이다. 여기서는 1로 설정한다.<li>partitions: Topic을 구성하는 파티션의 수를 의미한다.</ul><p>정상적으로 Topic이 생성된 경우 “Created topic test”라는 문구가 발생한다. 이미 존재하는 Topic을 생성하려 할 경우 “Error while executing topic command : Topic test already exists”라는 문구가 발생한다.</p><p>생성된 Topic의 속성을 확인하기 위해서는 describe 기능을 사용하면 된다. 아래 명령어를 입력하여 위에서 생성한 <code class="language-plaintext highlighter-rouge">test</code> Topic의 정보를 확인해보자.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>&gt; ${KAFKA_HOME}/bin/kafka-topics.sh --describe --topic test --bootstrap-server localhost:9092
Topic: test	PartitionCount: 1	ReplicationFactor: 1	Configs: segment.bytes=1073741824
	Topic: test	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
</pre></table></code></div></div><p>위와 같이 생성된 파티션의 정보를 확인할 수 있다.</p><h3 id="파티션-데이터는-어떻게-저장될까">파티션 데이터는 어떻게 저장될까?</h3><p>Topic을 구성하는 <strong>파티션 1개는 Kafka Broker의 파티션 디렉토리 1개와 매핑</strong>된다. Broker 설정 파일(<code class="language-plaintext highlighter-rouge">${KAFKA_HOME}/config/server.properties</code>)에서 설정한 <code class="language-plaintext highlighter-rouge">log.dirs</code> 디렉토리를 확인해보면, 우리가 생성한 <code class="language-plaintext highlighter-rouge">test</code> Topic의 0번째 파티션이 생성되어 있는 것을 확인할 수 있다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>&gt; ls
cleaner-offset-checkpoint        meta.properties                  replication-offset-checkpoint
log-start-offset-checkpoint      recovery-point-offset-checkpoint test-0
</pre></table></code></div></div><p>1개의 파티션(파티션 로그)은 다시 1개 이상의 세그먼트(로그 세그먼트)로 구성된다. <code class="language-plaintext highlighter-rouge">test-0</code> 디렉토리에서 <code class="language-plaintext highlighter-rouge">ls</code> 명령어를 쳐보면, <code class="language-plaintext highlighter-rouge">test-0</code> 파티션을 구성하는 00000000000000000000 세그먼트를 확인할 수 있다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>&gt; ls
00000000000000000000.index     00000000000000000000.timeindex
00000000000000000000.log       leader-epoch-checkpoint
</pre></table></code></div></div><p>세그먼트는 로그, 인덱스 파일로 구성되어 있다.</p><ul><li>로그 파일: 세그먼트를 구성하는 실제 데이터가 들어 있는 파일이다. 위에서는 00000000000000000000.log 파일로 기록되어 있다.<li>인덱스 파일: 파티션의 논리적인 인덱스와 파일의 물리적인 인덱스를 매핑해주는 파일이다. 위에서는 00000000000000000000.index 파일로 기록되어 있다.</ul><p>파일명에서 등장하는 00000000000000000000는 해당 Segment의 Base Offset이다. 여기서는 0값이 Base Offset이기 때문에, 이 파일들에 처음 기록된 메시지의 Offset은 0으로 시작하게 된다.</p><h4 id="segment-생성-옵션">Segment 생성 옵션</h4><p>Segment 파일의 크기가 특정 바이트를 넘어섰거나, 파일이 생성된지 일정 기간이 지나면 기존 Segment를 닫고 신규 Segment를 생성하도록 설정할 수 있다. 이와 관련된 옵션은 <code class="language-plaintext highlighter-rouge">log.segment.bytes</code>와 <code class="language-plaintext highlighter-rouge">log.segment.ms</code>이다.</p><p><code class="language-plaintext highlighter-rouge">log.segment.bytes</code> 옵션을 사용할 경우 현재 세그먼트 파일이 해당 크기를 넘어설 경우 새로운 세그먼트가 생성된다. 테스트를 위해 해당 값을 256으로 변경하고 Broker를 재시작한 뒤, Topic에 새로운 메시지를 발행한 뒤, <code class="language-plaintext highlighter-rouge">test-0</code> 디렉토리를 확인해보았다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>&gt; ls
00000000000000000000.index     00000000000000000002.index     00000000000000000002.timeindex
00000000000000000000.log       00000000000000000002.log       leader-epoch-checkpoint
00000000000000000000.timeindex 00000000000000000002.snapshot
</pre></table></code></div></div><p>기존 00000000000000000000 이외에도 00000000000000000002 관련 파일이 생성된 것을 확인할 수 있었다. 해당 Topic에 발행한 메시지의 수가 3개였는데, 두번째 Segment 파일의 Base Offset(파일명)이 2인 것으로 보아 마지막 메시지(Zero-based Index 기준으로 2번째, 실제로는 3번쨰 메시지) 1개만 00000000000000000002 Segment에 존재하는 것을 확인할 수 있었다.</p><h4 id="코드에서-확인하기">코드에서 확인하기</h4><p>코드 상에서는 <code class="language-plaintext highlighter-rouge">kafka.log.LogSegment</code> 클래스가 하나의 세그먼트와 매핑된다.</p><figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">class</span> <span class="nc">LogSegment</span> <span class="kd">private</span><span class="o">[</span><span class="n">log</span><span class="o">]</span> <span class="o">(</span><span class="n">val</span> <span class="nl">log:</span> <span class="nc">FileRecords</span><span class="o">,</span>
                               <span class="n">val</span> <span class="nl">lazyOffsetIndex:</span> <span class="nc">LazyIndex</span><span class="o">[</span><span class="nc">OffsetIndex</span><span class="o">],</span>
                               <span class="n">val</span> <span class="nl">lazyTimeIndex:</span> <span class="nc">LazyIndex</span><span class="o">[</span><span class="nc">TimeIndex</span><span class="o">],</span>
                               <span class="n">val</span> <span class="nl">txnIndex:</span> <span class="nc">TransactionIndex</span><span class="o">,</span>
                               <span class="n">val</span> <span class="nl">baseOffset:</span> <span class="nc">Long</span><span class="o">,</span>
                               <span class="n">val</span> <span class="nl">indexIntervalBytes:</span> <span class="nc">Int</span><span class="o">,</span>
                               <span class="n">val</span> <span class="nl">rollJitterMs:</span> <span class="nc">Long</span><span class="o">,</span>
                               <span class="n">val</span> <span class="nl">time:</span> <span class="nc">Time</span><span class="o">)</span> <span class="kd">extends</span> <span class="nc">Logging</span> <span class="o">{</span></code></pre></figure><p>생성자의 <code class="language-plaintext highlighter-rouge">FileRecords</code> 객체가 실제 메시지를 담고 있는 객체이며, <code class="language-plaintext highlighter-rouge">log</code> 확장자를 가진 파일로 저장된다. <code class="language-plaintext highlighter-rouge">LazyIndex[OffsetIndex]</code> 객체는 파티션의 논리적인 인덱스와 <code class="language-plaintext highlighter-rouge">FileRecords</code>에서의 인덱스의 매핑을 가지고 있는 객체이며, <code class="language-plaintext highlighter-rouge">index</code> 확장자를 가진 파일로 저장된다.</p><h3 id="데이터의-유지retention">데이터의 유지(Retention)</h3><p>RabbitMQ와 같은 시스템들은 Consumer가 메시지를 소비하면 Topic에서 메시지를 삭제하지만, Kafka는 <strong>발행된 메시지를 일정 기간동안 유지</strong>할 수 있다.</p><p>때문에 메시지 유지 기간 동안은 컨슈머가 일시적으로 동작하지 않더라도 후행 처리가 가능하며, 필요하다면 남아 있는 데이터를 Replay하며 재처리할 수도 있다.</p><p>이는 Kafka가 메시지를 메모리가 아닌 디스크에 유지하므로써 공간적인 제약에서 일부 자유롭기 때문인 것으로 생각된다.</p><h4 id="시간-기준으로-데이터-유지">시간 기준으로 데이터 유지</h4><ul><li><code class="language-plaintext highlighter-rouge">log.retention.ms</code>: 카프카가 메시지를 얼마 동안 보존할 지 설정할 수 있다(밀리초 단위). (<strong>로그 세그먼트 파일의 마지막 수정시간(mtime)</strong> + <code class="language-plaintext highlighter-rouge">log.retention.ms</code>) 시간 후에 데이터가 삭제된다.<li><code class="language-plaintext highlighter-rouge">log.retention.minutes</code>: <code class="language-plaintext highlighter-rouge">log.retention.ms</code>와 동일한 역할을 수행하며, 분 단위로 적용된다.<li><code class="language-plaintext highlighter-rouge">log.retention.hours</code>: <code class="language-plaintext highlighter-rouge">log.retention.ms</code>와 동일한 역할을 수행하며, 시간 단위로 적용된다.</ul><p>위의 값들을 설정하지 않으면 <code class="language-plaintext highlighter-rouge">log.retention.hours</code>가 168시간(7일)로 설정된다. 또한 <code class="language-plaintext highlighter-rouge">log.retention.ms</code> 값을 -1로 설정하는 경우, 로그가 삭제되지 않고 계속 유지된다.</p><p>우선순위는 <code class="language-plaintext highlighter-rouge">ms</code>, <code class="language-plaintext highlighter-rouge">minutes</code>, <code class="language-plaintext highlighter-rouge">hours</code> 순이며, 높은 우선순위를 가진 설정 값이 낮은 우선순위를 가진 설정 값을 무시한다.</p><h4 id="크기-기준으로-데이터-유지">크기 기준으로 데이터 유지</h4><p><code class="language-plaintext highlighter-rouge">log.retention.bytes</code> 값을 설정하므로써 파티션의 로그 크기에 따라 데이터의 보존을 설정할 수 있다.</p><h1 id="메시지레코드">메시지(레코드)</h1><p>Kafka에서의 데이터 기본 단위는 <a href="https://kafka.apache.org/documentation/#messages">메시지</a>(혹은 레코드)이다.</p><p>Message는 아래와 같은 요소로 구성된다.</p><ul><li>가변 길이 헤더<li>가변 길이 키(바이트 배열)<li>가변 길이 메시지(바이트 배열)</ul><h2 id="코드에서-확인하기-1">코드에서 확인하기</h2><figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">interface</span> <span class="nc">Record</span> <span class="o">{</span>

    <span class="nc">Header</span><span class="o">[]</span> <span class="no">EMPTY_HEADERS</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Header</span><span class="o">[</span><span class="mi">0</span><span class="o">];</span>

    <span class="kt">long</span> <span class="nf">offset</span><span class="o">();</span>

    <span class="kt">int</span> <span class="nf">sequence</span><span class="o">();</span>
    
    <span class="o">...</span></code></pre></figure><p><code class="language-plaintext highlighter-rouge">org.apache.kafka.common.record.Record</code>가 메시지를 표현하는 인터페이스이다. 위의 헤더, 키, 메시지 이외에도 <code class="language-plaintext highlighter-rouge">offset</code>, <code class="language-plaintext highlighter-rouge">sequence</code> 등 다양한 프로퍼티를 가지고 있다. 이 인터페이스를 구현한 클래스는 <code class="language-plaintext highlighter-rouge">org.apache.kafka.common.record.DefaultRecord</code>이다.</p><p><a href="https://kafka.apache.org/documentation/#record">Apache Kafka - Record</a> 문서를 보면 아래와 같은 포맷으로 Record가 기록되는 것을 알 수 있다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre>length: varint
attributes: int8
    bit 0~7: unused
timestampDelta: varint
offsetDelta: varint
keyLength: varint
key: byte[]
valueLen: varint
value: byte[]
Headers =&gt; [Header]
</pre></table></code></div></div><p><code class="language-plaintext highlighter-rouge">DefaultRecord</code> 클래스의 <code class="language-plaintext highlighter-rouge">writeTo</code>에서 위 포맷대로 데이터를 Output Stream에 기록하는 것을 확인할 수 있다.</p><figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="kt">int</span> <span class="nf">writeTo</span><span class="o">(</span><span class="nc">DataOutputStream</span> <span class="n">out</span><span class="o">,</span>
                            <span class="kt">int</span> <span class="n">offsetDelta</span><span class="o">,</span>
                            <span class="kt">long</span> <span class="n">timestampDelta</span><span class="o">,</span>
                            <span class="nc">ByteBuffer</span> <span class="n">key</span><span class="o">,</span>
                            <span class="nc">ByteBuffer</span> <span class="n">value</span><span class="o">,</span>
                            <span class="nc">Header</span><span class="o">[]</span> <span class="n">headers</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">IOException</span> <span class="o">{</span>
    <span class="kt">int</span> <span class="n">sizeInBytes</span> <span class="o">=</span> <span class="n">sizeOfBodyInBytes</span><span class="o">(</span><span class="n">offsetDelta</span><span class="o">,</span> <span class="n">timestampDelta</span><span class="o">,</span> <span class="n">key</span><span class="o">,</span> <span class="n">value</span><span class="o">,</span> <span class="n">headers</span><span class="o">);</span>
    <span class="nc">ByteUtils</span><span class="o">.</span><span class="na">writeVarint</span><span class="o">(</span><span class="n">sizeInBytes</span><span class="o">,</span> <span class="n">out</span><span class="o">);</span>
    
    <span class="o">...</span></code></pre></figure><h2 id="record-batch">Record Batch</h2><p>Kafka에서는 쓰기 처리량을 높이기 위해 여러 개의 메시지를 묶어 한번에 저장한다. 이 메시지 묶음을 Record Batch라고 하며, Record Batch에는 1개 이상의 메시지가 포함되어 있다. 또한 하나의 세그먼트에는 1개 이상의 Record Batch가 포함될 수 있다.</p><p><a href="https://kafka.apache.org/documentation/#recordbatch">Apache Kafka - Record Batch</a>를 보면 아래와 같이 Record Batch에 대한 포맷을 확인할 수 있다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</pre><td class="rouge-code"><pre>baseOffset: int64
batchLength: int32
partitionLeaderEpoch: int32
magic: int8 (current magic value is 2)
crc: int32
attributes: int16
    bit 0~2:
        0: no compression
        1: gzip
        2: snappy
        3: lz4
        4: zstd
    bit 3: timestampType
    bit 4: isTransactional (0 means not transactional)
    bit 5: isControlBatch (0 means not a control batch)
    bit 6~15: unused
lastOffsetDelta: int32
firstTimestamp: int64
maxTimestamp: int64
producerId: int64
producerEpoch: int16
baseSequence: int32
records: [Record]
</pre></table></code></div></div><h3 id="파일에서-확인하기">파일에서 확인하기</h3><p><code class="language-plaintext highlighter-rouge">test-0</code> 디렉토리의 00000000000000000000.log 파일을 Hex Fiend라는 프로그램을 통해 열어보면, 위의 포맷이 정상적으로 기록되었는지 확인할 수 있다.</p><p><code class="language-plaintext highlighter-rouge">firstTimestamp</code>가 기록된 부분(28byte부터 8byte)을 확인해보았다.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="../../assets/kafka/20200502/kafka_log_timestamp.png" alt="Kafka Log Timestamp" /></p><p>Hex 값으로는 0x00000171D1105FE6, Decimal 값으로는 1588350443494이 나오고 이 값을 Timestamp 변환기로 바꾸어보면 첫번째 메시지를 발행한 시각(여기서는 2020년 5월 2일 토요일 오전 1:27:23.494)이 나오게 된다.</p><h3 id="코드에서-확인하기-2">코드에서 확인하기</h3><figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">interface</span> <span class="nc">RecordBatch</span> <span class="kd">extends</span> <span class="nc">Iterable</span><span class="o">&lt;</span><span class="nc">Record</span><span class="o">&gt;</span> <span class="o">{</span>
<span class="o">...</span>
<span class="o">}</span></code></pre></figure><p><code class="language-plaintext highlighter-rouge">org.apache.kafka.common.record.RecordBatch</code>가 Record Batch를 표현하는 인터페이스이다. Record Batch는 1개 이상의 메시지(Record)를 포함하는 개념이기 때문에, 이 인터페이스를 구현한 클래스는 내부 메시지 순회를 위해 <code class="language-plaintext highlighter-rouge">Iterable&lt;Record&gt;</code> 인터페이스를 구현해야 한다.</p><p>이를 실제로 구현한 클래스는 <code class="language-plaintext highlighter-rouge">org.apache.kafka.common.record.DefaultRecordBatch</code> 클래스이며, Record Batch의 데이터를 기록하기 위한 <code class="language-plaintext highlighter-rouge">Bytebuffer</code>와 각종 쓰기 메서드들을 가지고 있는 것을 확인할 수 있다.</p><figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">DefaultRecordBatch</span> <span class="kd">extends</span> <span class="nc">AbstractRecordBatch</span> <span class="kd">implements</span> <span class="nc">MutableRecordBatch</span> <span class="o">{</span>
    <span class="o">...</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="nc">ByteBuffer</span> <span class="n">buffer</span><span class="o">;</span>

    <span class="nc">DefaultRecordBatch</span><span class="o">(</span><span class="nc">ByteBuffer</span> <span class="n">buffer</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">buffer</span> <span class="o">=</span> <span class="n">buffer</span><span class="o">;</span>
    <span class="o">}</span>
    <span class="o">...</span>
<span class="o">}</span></code></pre></figure><h2 id="세그먼트와-record-batch">세그먼트와 Record Batch</h2><p>세그먼트는 1개 이상의 Record Batch로 구성되어 있고, Record Batch는 1개 이상의 메시지로 구성되어 있다.</p><p>세그먼트의 로그 파일 내에는 1개 이상의 Record Batch가 포함되어 있을 수 있는 것이고, 코드 상에서도 아래와 같이 <code class="language-plaintext highlighter-rouge">FileRecords</code> 클래스 내에 여러 개의 <code class="language-plaintext highlighter-rouge">RecordBatch</code>를 가지는 구조로 되어 있는 것을 확인할 수 있다.</p><figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">FileRecords</span> <span class="kd">extends</span> <span class="nc">AbstractRecords</span> <span class="kd">implements</span> <span class="nc">Closeable</span> <span class="o">{</span>
    <span class="o">...</span>

    <span class="kd">private</span> <span class="kd">final</span> <span class="nc">Iterable</span><span class="o">&lt;</span><span class="nc">FileLogInputStream</span><span class="o">.</span><span class="na">FileChannelRecordBatch</span><span class="o">&gt;</span> <span class="n">batches</span><span class="o">;</span>

    <span class="o">...</span>
<span class="o">}</span></code></pre></figure></div><div class="post-tail-wrapper text-muted"><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/kafka/" class="post-tag no-text-decoration" >kafka</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Kafka의 Topic, Partition, Segment, Message - leeyh0216's devlog&url=https://leeyh0216.github.io/posts/kafka_concept/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Kafka의 Topic, Partition, Segment, Message - leeyh0216's devlog&u=https://leeyh0216.github.io/posts/kafka_concept/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Kafka의 Topic, Partition, Segment, Message - leeyh0216's devlog&url=https://leeyh0216.github.io/posts/kafka_concept/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/ps/">ps</a> <a class="post-tag" href="/tags/spring/">spring</a> <a class="post-tag" href="/tags/leetcode/">leetcode</a> <a class="post-tag" href="/tags/apache-spark/">apache-spark</a> <a class="post-tag" href="/tags/java/">java</a> <a class="post-tag" href="/tags/kafka/">kafka</a> <a class="post-tag" href="/tags/apache-druid/">apache-druid</a> <a class="post-tag" href="/tags/string/">string</a> <a class="post-tag" href="/tags/study/">study</a> <a class="post-tag" href="/tags/docker/">docker</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/spark-structured-streaming-microbatch/"><div class="card-body"> <span class="timeago small" > Sep 2, 2022 <i class="unloaded">2022-09-02T23:55:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Spark Structured Streaming의 MicroBatch 동작 원리 알아보기</h3><div class="text-muted small"><p> 이 글의 내용은 MicroBatchExecution - Stream Execution Engine of Micro-Batch Stream Processing을 참고하여 작성하였습니다. Spark Structured Streaming의 MicroBatch 동작 원리 알아보기 MicroBatch 기반의 Spark Structured Stream...</p></div></div></a></div><div class="card"> <a href="/posts/kafka_producer/"><div class="card-body"> <span class="timeago small" > May 3, 2020 <i class="unloaded">2020-05-03T18:10:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>간단한 Kafka Producer를 만들고 동작원리를 알아보자</h3><div class="text-muted small"><p> Kafka Producer 메시지 발행/구독 시스템에서 Producer는 메시지의 발행을 수행하는 컴포넌트이다. 이 글에서는 Kafka Client API를 사용하여 Kafka Producer를 만들어보고, 메시지가 실제로 어떤 과정을 거쳐 전달되는지 알아본다. build.gradle에 Kafka Client 의존성 추가하기 build.grad...</p></div></div></a></div><div class="card"> <a href="/posts/kafka_docker/"><div class="card-body"> <span class="timeago small" > May 17, 2020 <i class="unloaded">2020-05-17T22:10:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Docker(compose)로 Kafka Cluster 실행하기</h3><div class="text-muted small"><p> 개요 Kafka 공부 중 Replication 등을 테스트하기 위해 Kafka를 3대로 구성하여 Kafka Cluster를 띄워야 했다. 로컬 환경에 포트와 데이터 경로만 바꿔 실행할 수도 있었지만, 실행/종료가 귀찮을 것이 분명했기 때문에 Kafka를 Docker Image로 만든 뒤 Docker Compose를 통해 띄울 수 있도록 만들어 보았다...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/PalindromeNumber/" class="btn btn-outline-primary" prompt="Older"><p>LeetCode - Palindrome Number</p></a> <a href="/posts/kafka_producer/" class="btn btn-outline-primary" prompt="Newer"><p>간단한 Kafka Producer를 만들고 동작원리를 알아보자</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('.post-content img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2024 <a href="https://twitter.com/username">leeyh0216</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/ps/">ps</a> <a class="post-tag" href="/tags/spring/">spring</a> <a class="post-tag" href="/tags/leetcode/">leetcode</a> <a class="post-tag" href="/tags/apache-spark/">apache spark</a> <a class="post-tag" href="/tags/java/">java</a> <a class="post-tag" href="/tags/kafka/">kafka</a> <a class="post-tag" href="/tags/apache-druid/">apache druid</a> <a class="post-tag" href="/tags/string/">string</a> <a class="post-tag" href="/tags/study/">study</a> <a class="post-tag" href="/tags/docker/">docker</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://leeyh0216.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
