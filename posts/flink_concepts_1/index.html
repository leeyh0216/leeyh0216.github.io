<!DOCTYPE html><html lang="ko-KR" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8829030678254956" crossorigin="anonymous"></script><meta name="pv-proxy-endpoint" content=""><meta name="generator" content="Jekyll v4.2.0" /><meta property="og:title" content="Flink Concept - Operator, Task, Parallelism" /><meta name="author" content="leeyh0216" /><meta property="og:locale" content="ko_KR" /><meta name="description" content="개요 진행 중인 프로젝트에서 Flink를 사용할 기회가 생겼다. 처음 코드를 작성할 때는 ‘Spark과 거의 비슷하네?’ 라는 생각을 했는데, 사용하면 할 수록 다른 부분을 많이 느끼게 되어 정리 차 글을 작성한다. 아래 자료들을 참고하여 작성하였다. Apache Flink - Flink Architecture 삼성 SDS - 연산 처리의 성능 한계에 도전하는 병렬 컴퓨팅 Streaming Processing with Apache Flink - O’REILLY ZDNET - Understanding task and data parallelism 병렬처리 개념 병렬 컴퓨팅을 사용하면 많은 데이터나 작업들을 동시 수행하여 빠르게 처리할 수 있다. 병렬 컴퓨팅은 하나의 방법이 아니며, 아래와 같이 여러 방식들이 존재한다. Bit-Level Parallelism Instruction Level Parallelism Data Parallelism Task Parallelism Flink는 Data Parallelism과 Task Parallelism을 결합하여 사용하기 때문에, 이 글에서는 Data Paralleism과 Task Parallelism만 다룬다. Data Parallelism Data Parallelism은 데이터를 각기 다른 노드(혹은 프로세서)에 분산하여 병렬적으로 연산을 수행하는 방법이다. 아래와 같이 0 ~ 15까지의 합을 구하는 함수를 작성한다고 가정하자. 하나의 합을 구할 때 소요되는 시간은 약 1초이다. @Test public void testSum() throws Exception { long start = System.currentTimeMillis(); int sum = 0; for (int i = 0; i &lt; 16; i++) { sum += i; Thread.sleep(1000); } long end = System.currentTimeMillis(); Assert.assertEquals(120, sum); System.out.println(String.format(&quot;Elapsed: %d&quot;, (end - start))); } 총 16초 가량이 소요된 것을 확인할 수 있다. 여기에 Data Parallelism을 적용한다고 하면 아래와 같은 코드를 작성할 수 있다. class SumRunnable implements Runnable { AtomicInteger sum; int start, end; public SumRunnable(AtomicInteger sum, int start, int end) { this.sum = sum; this.start = start; this.end = end; } @Override public void run() { for (int i = start; i &lt; end; i++) { sum.addAndGet(i); try { Thread.sleep(1000); } catch (Exception e) { //Nothing to do } } } } @Test public void testDataParallelism() throws Exception { long startMillis = System.currentTimeMillis(); AtomicInteger sum = new AtomicInteger(0); List&lt;Thread&gt; threads = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 4; i++) { int start = i * 4; int end = start + 4; Thread t = new Thread(new SumRunnable(sum, start, end)); t.start(); threads.add(t); } for (Thread t : threads) t.join(); long endMillis = System.currentTimeMillis(); Assert.assertEquals(120, sum.get()); System.out.println(String.format(&quot;Elapsed: %d&quot;, (endMillis - startMillis))); } 0 ~ 16까지의 값을 [0 ~ 3], [4 ~ 7], [8 ~ 11], [12 ~ 15] 로 총 4개의 범위로 분할한 뒤, 각 범위를 하나의 프로세서(스레드)에게 할당하였다. 기존 N의 작업을 N/4 씩 나누어 동시에 수행하기 때문에 전체 소요 시간도 16초 -&gt; 4초로 감소한 것을 확인할 수 있다. Task Parallelism Task Parallelism은 데이터가 아닌 작업들을 나누어 수행하는 방법이다. 흔히 볼 수 있는 Task Parallelism은 Pipelining이 있다. 자동차 공장에서 자동차를 만들 때 수행해야 하는 공정이 아래와 같다고 하자. 부품 만들기(A) 차체 만들기(B) 조립하기(C) 도장하기(D) 내장 조립하기(E) 하부 조립하기(F) 이 중 A와 B, E와 F는 서로 동시에 진행될 수 있다고 할 때 공정을 아래와 같이 나눌 수 있을 것이다.(괄호 안의 공정은 동시에 수행될 수 있다는 의미) (A, B) -&gt; C -&gt; D -&gt; (E, F) 동일한 차(데이터)에 대해 A, B와 E, F 작업을 나누어 동시에 처리하였다. 또 다른 예제는 아래와 같다. 입력에 대해 합을 구하는 연산자(A)와 곱을 구하는 연산자(B)가 있고, 이를 처리할 수 있는 프로세서 2개(Processor1, Processor2)가 있다고 하자. Task Parallelism은 Processor1에 A 연산, Processor2에 B 연산을 할당하여 입력 데이터에 대해 각기 다른 연산을 동시에 처리한다. 예를 들어 아래와 같이 특정 구간의 합과 곱을 구하는 함수를 작성한다고 하자. 합 연산의 경우 1초, 곱 연산의 경우 2초가 소요된다고 가정하자. @Test public void testSumAndMultiple() throws Exception { int sum = 0, multiple = 1; long start = System.currentTimeMillis(); for (int i = 1; i &lt;= 8; i++) { sum += i; Thread.sleep(1000); } for (int i = 1; i &lt;= 8; i++) { multiple *= i; Thread.sleep(2000); } long end = System.currentTimeMillis(); Assert.assertEquals(36, sum); Assert.assertEquals(40320, multiple); System.out.println(String.format(&quot;Elapsed: %d&quot;, (end - start))); } 총 24초의 시간이 소요된 것을 확인할 수 있다. 여기에 Task Parallelism을 적용하면 아래와 같은 코드를 작성할 수 있다. class SumRunnable implements Runnable { AtomicInteger sum; int start, end; public SumRunnable(AtomicInteger sum, int start, int end) { this.sum = sum; this.start = start; this.end = end; } @Override public void run() { for (int i = start; i &lt;= end; i++) { sum.addAndGet(i); try { Thread.sleep(1000); } catch (Exception e) { //Nothing to do } } } } class MultipleRunnable implements Runnable { AtomicInteger multiple; int start, end; public MultipleRunnable(AtomicInteger multiple, int start, int end) { this.multiple = multiple; this.start = start; this.end = end; } @Override public void run() { for (int i = start; i &lt;= end; i++) { final int toMultiple = i; multiple.updateAndGet(v -&gt; v * toMultiple); try { Thread.sleep(2); } catch (Exception e) { //Nothing to do } } } } @Test public void testTaskParallelism() throws Exception { AtomicInteger sum = new AtomicInteger(0), multiple = new AtomicInteger(1); long start = System.currentTimeMillis(); Thread sumThread = new Thread(new SumRunnable(sum, 1, 8)); Thread multipleThread = new Thread(new MultipleRunnable(multiple, 1, 8)); sumThread.start(); multipleThread.start(); sumThread.join(); multipleThread.join(); long end = System.currentTimeMillis(); Assert.assertEquals(36, sum.get()); Assert.assertEquals(40320, multiple.get()); System.out.println(String.format(&quot;Elapsed: %d&quot;, (end - start))); } 합 연산을 수행하는 작업(sumThread)과 곱 연산을 수행하는 작업(multipleThread)을 각 작업 당 하나의 프로세서(스레드)가 수행할 수 있도록 하였다. 결과적으로 총 소요 시간이 24초 -&gt; 8초로 줄어든 것을 확인할 수 있었다. 병렬처리와 성능 병렬처리를 통해 얻을 수 있는 성능 향상은 암달의 법칙(Amdahl’s law)과 구스타프슨의 법칙(Gustafson’s Law)에서 다룬다. 암달의 법칙(Amdahl’s law) 위 Task Parallelism의 자동차 예제에서도 나왔지만, 작업 파이프라인 중에는 병렬화가 가능한 부분도 있지만 병렬화가 불가능한 부분(직렬)도 있다. 암달의 법칙은 컴퓨터 시스템의 일부를 개선(병렬화)할 때 전체적으로 얼마만큼의 성능 향상(기존 직렬적인 부분 + 병렬화된 부분)이 있는지 계산하는데에 사용된다. 공식은 아래와 같다. 전체 성능 향상 = 1 / ((1 - P) + (P / S)) 위 공식에서 P는 성능 향상을 이루어낸(병렬화된) 부분의 비율이고, S는 향상된 성능을 나타낸다. 예를 들어 작업의 80%에 대해 속도를 4배로 늘렸다 하면 아래와 같이 계산할 수 있다. 전체 성능 향상 = 1 / ((1 - 0.8) + (0.8 / 4)) = 2.5 작업의 80%에 대해 4배의 성능 향상을 이루어냈더라도 전체적으로는 고작 2.5배의 성능 향상밖에 이루어내지 못했다. 아래와 같이 작업의 99%에 대해 수천, 수만 배의 성능 향상이 이루어진다 해도 전체적으로는 최대 20배의 성능 향상 밖에 이루어내지 못한다는 절망적인 법칙이다. 그림 출처: Wikipedia - 암달의 법칙 구스타프슨의 법칙(Gustafson’s Law) 구스타프슨의 법칙은 암달의 법칙과 반대로 대용량 작업은 효율적으로 병렬화 할 수 있다는 가정 하에 만들어진 법칙이다. 공식은 아래와 같다. S(P) = P - α(P - 1) 위 공식에서 P는 프로세서의 수, S는 성능 향상, α는 병렬화되지 않는 순차적인 부분의 비율이다. 자세한 공식 유도 방법은 Wikipedia - 구스타프슨의 법칙을 참고하면 좋다. 위 공식대로라면 순차적인 부분의 비율이 낮을 수록 거의 프로세서 수 만큼의 성능 향상을 이뤄낼 수 있다. 따라서 문제의 크기가 커진다 해도 프로세서의 수를 늘리면 동일한 시간 안에 처리할 수 있다는 결론이 나오게 된다. Spark나 Flink와 같은 병렬 처리 프레임워크를 사용하며 데이터 처리를 수행하며 느낀 것은 어느정도 구스타프슨의 법칙이 맞아 떨어진다는 것이다. 거의 대부분의 경우에서 프로세서(혹은 장비)의 수를 늘리면 전체적인 성능 향상이 크게 나타나는 것을 느꼈다. 다만 현실 세계 문제에서는 Shuffle 등에 사용되는 Network Overhead나 Source, Sink 과정에서 사용되는 Persistent Storage 들의 성능이 오히려 전체 파이프라인 성능에 크게 영향을 주는 것이 많았던 것 같다. Flink에서의 병렬 처리 그림 출처: Apache Flink - Task and operator chains Operator, Task Operator는 Flink에서 수행되는 연산의 가장 작은 단위로 map, flatMap 등이 존재한다. 이러한 Operator들을 Chaining하여 Task로 만들 수 있다. 각 Task는 하나의 Thread에서 수행되며, Operator를 Task로 묶음으로써 Task 간 데이터 교환 오버헤드를 줄일 수 있다. Flink에서 Task는 동일한 TaskManager에서 수행될 수도 있지만, 다른 장비에서 수행되고 있는 TaskManager에 의해 실행될 수도 있기 때문에, Task 간 데이터 교환에는 아래와 같은 작업이 수행된다. Task A의 결과 데이터를 Serialization 한다. Serialization 된 결과 데이터를 TCP를 통해 다른 장비에서 실행 중인 TaskManager로 전달한다. 데이터를 수신한 TaskManager는 Deserialization을 수행하여 새로운 Task의 입력 데이터로 활용한다. 여러 개의 Operator를 한 개의 Task로 묶으면 하나의 Thread에서 Method Chaining 처럼 동작하기 때문에 위와 같은 Overhead의 발생을 피할 수 있다. TaskManager와 Task Slot Flink에서 TaskManager는 Task의 실행을 담당하는 컴포넌트이다. TaskManager는 1개의 JVM Process로써 동작하며, 내부적으로 1개 이상의 스레드를 통해 1개 이상의 Task를 실행할 수 있다.(Task Parallelism) 위의 각 스레드를 Task Slot이라 한다. 1개의 TaskManager가 1개 이상의 Task Slot을 소유하므로써 가지는 특징은 아래와 같다. JVM 메모리 공유 하나의 TaskManager에 속한 Task Slot들은 TaskManager의 메모리를 나누어 사용한다. 예를 들어 600MB의 Heap 공간을 가진 TaskManager에 3개의 Slot이 존재한다면, 각 Slot은 200MB 씩 메모리를 나누어 가진다. JVM 실행에 필요한 메모리가 존재하기 때문에, TaskManager에 Slot의 수가 많을 수록 이러한 메모리 오버헤드를 줄일 수 있다. CPU Isolation 불가 다만 1개의 TaskManager에 속한 Slot들은 JVM Thread로써 동작하기 때문에 CPU Isolation은 이룰 수 없다. CPU Isolation이 필요하다면 TaskManager 별로 Slot을 1개씩 가지게 하고, 각 TaskManager를 통해 CPU Isolation을 달성해야 한다. TaskManager에서 사용하는 자원 공유 TaskManager에는 데이터 교환을 위한 TCP 연결이나 내부 객체 등 다양한 리소스가 존재한다. 하나의 TaskManager에 속한 Slot들은 이러한 자원을 공유하게 된다. Task와 Subtask 그리고 Slot Sharing 그림 출처: Apache Flink - Task Slots and Resources 1개의 Task는 1개 이상의 Subtask로 나뉠 수 있다. 즉, 동일한 연산(Task, Operator Set)을 수행하는 Processor들이 여러 개 존재하는 구조이다.(Data Parallelism) 위의 Task Slot에서 실행하는 작업의 단위는 사실 Task가 아닌 Subtask 단위이다. 만일 2개의 Task(Task A, Task B)가 존재하고, 각 Task마다 3개의 Subtask로 실행해야 한다고 가정하면, 총 6개의 Slot이 필요하다. 그런데 Task A는 Task B에 비해 매우 빠르게 수행되는 연산이라고 가정해보자. Task A를 담당하는 CPU는 Utilization이 낮고, Task B를 담당하는 CPU는 Utilization이 매우 높을 것이다. 이러한 비효율을 줄이기 위해 Flink에서는 Slot Sharing을 지원한다. Slot Sharing은 Job을 구성하는 Task 중 가장 높은 Parallelism(Subtask의 수)만큼의 Slot을 만들고, 모든 Task들이 이 Slot을 공유하는 방식이다. 어차피 Subtask들은 Thread이기 때문에 Time slicing을 통해 균등하게 작업 시간을 할당받을 것이고, Task A 처리가 끝나고 Task B 처리만 남았을 때는 Task B가 모든 CPU 자원을 사용할 수 있기 때문에 매우 효율적인 자원 운용이 가능해진다." /><meta property="og:description" content="개요 진행 중인 프로젝트에서 Flink를 사용할 기회가 생겼다. 처음 코드를 작성할 때는 ‘Spark과 거의 비슷하네?’ 라는 생각을 했는데, 사용하면 할 수록 다른 부분을 많이 느끼게 되어 정리 차 글을 작성한다. 아래 자료들을 참고하여 작성하였다. Apache Flink - Flink Architecture 삼성 SDS - 연산 처리의 성능 한계에 도전하는 병렬 컴퓨팅 Streaming Processing with Apache Flink - O’REILLY ZDNET - Understanding task and data parallelism 병렬처리 개념 병렬 컴퓨팅을 사용하면 많은 데이터나 작업들을 동시 수행하여 빠르게 처리할 수 있다. 병렬 컴퓨팅은 하나의 방법이 아니며, 아래와 같이 여러 방식들이 존재한다. Bit-Level Parallelism Instruction Level Parallelism Data Parallelism Task Parallelism Flink는 Data Parallelism과 Task Parallelism을 결합하여 사용하기 때문에, 이 글에서는 Data Paralleism과 Task Parallelism만 다룬다. Data Parallelism Data Parallelism은 데이터를 각기 다른 노드(혹은 프로세서)에 분산하여 병렬적으로 연산을 수행하는 방법이다. 아래와 같이 0 ~ 15까지의 합을 구하는 함수를 작성한다고 가정하자. 하나의 합을 구할 때 소요되는 시간은 약 1초이다. @Test public void testSum() throws Exception { long start = System.currentTimeMillis(); int sum = 0; for (int i = 0; i &lt; 16; i++) { sum += i; Thread.sleep(1000); } long end = System.currentTimeMillis(); Assert.assertEquals(120, sum); System.out.println(String.format(&quot;Elapsed: %d&quot;, (end - start))); } 총 16초 가량이 소요된 것을 확인할 수 있다. 여기에 Data Parallelism을 적용한다고 하면 아래와 같은 코드를 작성할 수 있다. class SumRunnable implements Runnable { AtomicInteger sum; int start, end; public SumRunnable(AtomicInteger sum, int start, int end) { this.sum = sum; this.start = start; this.end = end; } @Override public void run() { for (int i = start; i &lt; end; i++) { sum.addAndGet(i); try { Thread.sleep(1000); } catch (Exception e) { //Nothing to do } } } } @Test public void testDataParallelism() throws Exception { long startMillis = System.currentTimeMillis(); AtomicInteger sum = new AtomicInteger(0); List&lt;Thread&gt; threads = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 4; i++) { int start = i * 4; int end = start + 4; Thread t = new Thread(new SumRunnable(sum, start, end)); t.start(); threads.add(t); } for (Thread t : threads) t.join(); long endMillis = System.currentTimeMillis(); Assert.assertEquals(120, sum.get()); System.out.println(String.format(&quot;Elapsed: %d&quot;, (endMillis - startMillis))); } 0 ~ 16까지의 값을 [0 ~ 3], [4 ~ 7], [8 ~ 11], [12 ~ 15] 로 총 4개의 범위로 분할한 뒤, 각 범위를 하나의 프로세서(스레드)에게 할당하였다. 기존 N의 작업을 N/4 씩 나누어 동시에 수행하기 때문에 전체 소요 시간도 16초 -&gt; 4초로 감소한 것을 확인할 수 있다. Task Parallelism Task Parallelism은 데이터가 아닌 작업들을 나누어 수행하는 방법이다. 흔히 볼 수 있는 Task Parallelism은 Pipelining이 있다. 자동차 공장에서 자동차를 만들 때 수행해야 하는 공정이 아래와 같다고 하자. 부품 만들기(A) 차체 만들기(B) 조립하기(C) 도장하기(D) 내장 조립하기(E) 하부 조립하기(F) 이 중 A와 B, E와 F는 서로 동시에 진행될 수 있다고 할 때 공정을 아래와 같이 나눌 수 있을 것이다.(괄호 안의 공정은 동시에 수행될 수 있다는 의미) (A, B) -&gt; C -&gt; D -&gt; (E, F) 동일한 차(데이터)에 대해 A, B와 E, F 작업을 나누어 동시에 처리하였다. 또 다른 예제는 아래와 같다. 입력에 대해 합을 구하는 연산자(A)와 곱을 구하는 연산자(B)가 있고, 이를 처리할 수 있는 프로세서 2개(Processor1, Processor2)가 있다고 하자. Task Parallelism은 Processor1에 A 연산, Processor2에 B 연산을 할당하여 입력 데이터에 대해 각기 다른 연산을 동시에 처리한다. 예를 들어 아래와 같이 특정 구간의 합과 곱을 구하는 함수를 작성한다고 하자. 합 연산의 경우 1초, 곱 연산의 경우 2초가 소요된다고 가정하자. @Test public void testSumAndMultiple() throws Exception { int sum = 0, multiple = 1; long start = System.currentTimeMillis(); for (int i = 1; i &lt;= 8; i++) { sum += i; Thread.sleep(1000); } for (int i = 1; i &lt;= 8; i++) { multiple *= i; Thread.sleep(2000); } long end = System.currentTimeMillis(); Assert.assertEquals(36, sum); Assert.assertEquals(40320, multiple); System.out.println(String.format(&quot;Elapsed: %d&quot;, (end - start))); } 총 24초의 시간이 소요된 것을 확인할 수 있다. 여기에 Task Parallelism을 적용하면 아래와 같은 코드를 작성할 수 있다. class SumRunnable implements Runnable { AtomicInteger sum; int start, end; public SumRunnable(AtomicInteger sum, int start, int end) { this.sum = sum; this.start = start; this.end = end; } @Override public void run() { for (int i = start; i &lt;= end; i++) { sum.addAndGet(i); try { Thread.sleep(1000); } catch (Exception e) { //Nothing to do } } } } class MultipleRunnable implements Runnable { AtomicInteger multiple; int start, end; public MultipleRunnable(AtomicInteger multiple, int start, int end) { this.multiple = multiple; this.start = start; this.end = end; } @Override public void run() { for (int i = start; i &lt;= end; i++) { final int toMultiple = i; multiple.updateAndGet(v -&gt; v * toMultiple); try { Thread.sleep(2); } catch (Exception e) { //Nothing to do } } } } @Test public void testTaskParallelism() throws Exception { AtomicInteger sum = new AtomicInteger(0), multiple = new AtomicInteger(1); long start = System.currentTimeMillis(); Thread sumThread = new Thread(new SumRunnable(sum, 1, 8)); Thread multipleThread = new Thread(new MultipleRunnable(multiple, 1, 8)); sumThread.start(); multipleThread.start(); sumThread.join(); multipleThread.join(); long end = System.currentTimeMillis(); Assert.assertEquals(36, sum.get()); Assert.assertEquals(40320, multiple.get()); System.out.println(String.format(&quot;Elapsed: %d&quot;, (end - start))); } 합 연산을 수행하는 작업(sumThread)과 곱 연산을 수행하는 작업(multipleThread)을 각 작업 당 하나의 프로세서(스레드)가 수행할 수 있도록 하였다. 결과적으로 총 소요 시간이 24초 -&gt; 8초로 줄어든 것을 확인할 수 있었다. 병렬처리와 성능 병렬처리를 통해 얻을 수 있는 성능 향상은 암달의 법칙(Amdahl’s law)과 구스타프슨의 법칙(Gustafson’s Law)에서 다룬다. 암달의 법칙(Amdahl’s law) 위 Task Parallelism의 자동차 예제에서도 나왔지만, 작업 파이프라인 중에는 병렬화가 가능한 부분도 있지만 병렬화가 불가능한 부분(직렬)도 있다. 암달의 법칙은 컴퓨터 시스템의 일부를 개선(병렬화)할 때 전체적으로 얼마만큼의 성능 향상(기존 직렬적인 부분 + 병렬화된 부분)이 있는지 계산하는데에 사용된다. 공식은 아래와 같다. 전체 성능 향상 = 1 / ((1 - P) + (P / S)) 위 공식에서 P는 성능 향상을 이루어낸(병렬화된) 부분의 비율이고, S는 향상된 성능을 나타낸다. 예를 들어 작업의 80%에 대해 속도를 4배로 늘렸다 하면 아래와 같이 계산할 수 있다. 전체 성능 향상 = 1 / ((1 - 0.8) + (0.8 / 4)) = 2.5 작업의 80%에 대해 4배의 성능 향상을 이루어냈더라도 전체적으로는 고작 2.5배의 성능 향상밖에 이루어내지 못했다. 아래와 같이 작업의 99%에 대해 수천, 수만 배의 성능 향상이 이루어진다 해도 전체적으로는 최대 20배의 성능 향상 밖에 이루어내지 못한다는 절망적인 법칙이다. 그림 출처: Wikipedia - 암달의 법칙 구스타프슨의 법칙(Gustafson’s Law) 구스타프슨의 법칙은 암달의 법칙과 반대로 대용량 작업은 효율적으로 병렬화 할 수 있다는 가정 하에 만들어진 법칙이다. 공식은 아래와 같다. S(P) = P - α(P - 1) 위 공식에서 P는 프로세서의 수, S는 성능 향상, α는 병렬화되지 않는 순차적인 부분의 비율이다. 자세한 공식 유도 방법은 Wikipedia - 구스타프슨의 법칙을 참고하면 좋다. 위 공식대로라면 순차적인 부분의 비율이 낮을 수록 거의 프로세서 수 만큼의 성능 향상을 이뤄낼 수 있다. 따라서 문제의 크기가 커진다 해도 프로세서의 수를 늘리면 동일한 시간 안에 처리할 수 있다는 결론이 나오게 된다. Spark나 Flink와 같은 병렬 처리 프레임워크를 사용하며 데이터 처리를 수행하며 느낀 것은 어느정도 구스타프슨의 법칙이 맞아 떨어진다는 것이다. 거의 대부분의 경우에서 프로세서(혹은 장비)의 수를 늘리면 전체적인 성능 향상이 크게 나타나는 것을 느꼈다. 다만 현실 세계 문제에서는 Shuffle 등에 사용되는 Network Overhead나 Source, Sink 과정에서 사용되는 Persistent Storage 들의 성능이 오히려 전체 파이프라인 성능에 크게 영향을 주는 것이 많았던 것 같다. Flink에서의 병렬 처리 그림 출처: Apache Flink - Task and operator chains Operator, Task Operator는 Flink에서 수행되는 연산의 가장 작은 단위로 map, flatMap 등이 존재한다. 이러한 Operator들을 Chaining하여 Task로 만들 수 있다. 각 Task는 하나의 Thread에서 수행되며, Operator를 Task로 묶음으로써 Task 간 데이터 교환 오버헤드를 줄일 수 있다. Flink에서 Task는 동일한 TaskManager에서 수행될 수도 있지만, 다른 장비에서 수행되고 있는 TaskManager에 의해 실행될 수도 있기 때문에, Task 간 데이터 교환에는 아래와 같은 작업이 수행된다. Task A의 결과 데이터를 Serialization 한다. Serialization 된 결과 데이터를 TCP를 통해 다른 장비에서 실행 중인 TaskManager로 전달한다. 데이터를 수신한 TaskManager는 Deserialization을 수행하여 새로운 Task의 입력 데이터로 활용한다. 여러 개의 Operator를 한 개의 Task로 묶으면 하나의 Thread에서 Method Chaining 처럼 동작하기 때문에 위와 같은 Overhead의 발생을 피할 수 있다. TaskManager와 Task Slot Flink에서 TaskManager는 Task의 실행을 담당하는 컴포넌트이다. TaskManager는 1개의 JVM Process로써 동작하며, 내부적으로 1개 이상의 스레드를 통해 1개 이상의 Task를 실행할 수 있다.(Task Parallelism) 위의 각 스레드를 Task Slot이라 한다. 1개의 TaskManager가 1개 이상의 Task Slot을 소유하므로써 가지는 특징은 아래와 같다. JVM 메모리 공유 하나의 TaskManager에 속한 Task Slot들은 TaskManager의 메모리를 나누어 사용한다. 예를 들어 600MB의 Heap 공간을 가진 TaskManager에 3개의 Slot이 존재한다면, 각 Slot은 200MB 씩 메모리를 나누어 가진다. JVM 실행에 필요한 메모리가 존재하기 때문에, TaskManager에 Slot의 수가 많을 수록 이러한 메모리 오버헤드를 줄일 수 있다. CPU Isolation 불가 다만 1개의 TaskManager에 속한 Slot들은 JVM Thread로써 동작하기 때문에 CPU Isolation은 이룰 수 없다. CPU Isolation이 필요하다면 TaskManager 별로 Slot을 1개씩 가지게 하고, 각 TaskManager를 통해 CPU Isolation을 달성해야 한다. TaskManager에서 사용하는 자원 공유 TaskManager에는 데이터 교환을 위한 TCP 연결이나 내부 객체 등 다양한 리소스가 존재한다. 하나의 TaskManager에 속한 Slot들은 이러한 자원을 공유하게 된다. Task와 Subtask 그리고 Slot Sharing 그림 출처: Apache Flink - Task Slots and Resources 1개의 Task는 1개 이상의 Subtask로 나뉠 수 있다. 즉, 동일한 연산(Task, Operator Set)을 수행하는 Processor들이 여러 개 존재하는 구조이다.(Data Parallelism) 위의 Task Slot에서 실행하는 작업의 단위는 사실 Task가 아닌 Subtask 단위이다. 만일 2개의 Task(Task A, Task B)가 존재하고, 각 Task마다 3개의 Subtask로 실행해야 한다고 가정하면, 총 6개의 Slot이 필요하다. 그런데 Task A는 Task B에 비해 매우 빠르게 수행되는 연산이라고 가정해보자. Task A를 담당하는 CPU는 Utilization이 낮고, Task B를 담당하는 CPU는 Utilization이 매우 높을 것이다. 이러한 비효율을 줄이기 위해 Flink에서는 Slot Sharing을 지원한다. Slot Sharing은 Job을 구성하는 Task 중 가장 높은 Parallelism(Subtask의 수)만큼의 Slot을 만들고, 모든 Task들이 이 Slot을 공유하는 방식이다. 어차피 Subtask들은 Thread이기 때문에 Time slicing을 통해 균등하게 작업 시간을 할당받을 것이고, Task A 처리가 끝나고 Task B 처리만 남았을 때는 Task B가 모든 CPU 자원을 사용할 수 있기 때문에 매우 효율적인 자원 운용이 가능해진다." /><link rel="canonical" href="https://leeyh0216.github.io/posts/flink_concepts_1/" /><meta property="og:url" content="https://leeyh0216.github.io/posts/flink_concepts_1/" /><meta property="og:site_name" content="leeyh0216’s devlog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-08-02T18:10:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Flink Concept - Operator, Task, Parallelism" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@leeyh0216" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"author":{"@type":"Person","name":"leeyh0216"},"description":"개요 진행 중인 프로젝트에서 Flink를 사용할 기회가 생겼다. 처음 코드를 작성할 때는 ‘Spark과 거의 비슷하네?’ 라는 생각을 했는데, 사용하면 할 수록 다른 부분을 많이 느끼게 되어 정리 차 글을 작성한다. 아래 자료들을 참고하여 작성하였다. Apache Flink - Flink Architecture 삼성 SDS - 연산 처리의 성능 한계에 도전하는 병렬 컴퓨팅 Streaming Processing with Apache Flink - O’REILLY ZDNET - Understanding task and data parallelism 병렬처리 개념 병렬 컴퓨팅을 사용하면 많은 데이터나 작업들을 동시 수행하여 빠르게 처리할 수 있다. 병렬 컴퓨팅은 하나의 방법이 아니며, 아래와 같이 여러 방식들이 존재한다. Bit-Level Parallelism Instruction Level Parallelism Data Parallelism Task Parallelism Flink는 Data Parallelism과 Task Parallelism을 결합하여 사용하기 때문에, 이 글에서는 Data Paralleism과 Task Parallelism만 다룬다. Data Parallelism Data Parallelism은 데이터를 각기 다른 노드(혹은 프로세서)에 분산하여 병렬적으로 연산을 수행하는 방법이다. 아래와 같이 0 ~ 15까지의 합을 구하는 함수를 작성한다고 가정하자. 하나의 합을 구할 때 소요되는 시간은 약 1초이다. @Test public void testSum() throws Exception { long start = System.currentTimeMillis(); int sum = 0; for (int i = 0; i &lt; 16; i++) { sum += i; Thread.sleep(1000); } long end = System.currentTimeMillis(); Assert.assertEquals(120, sum); System.out.println(String.format(&quot;Elapsed: %d&quot;, (end - start))); } 총 16초 가량이 소요된 것을 확인할 수 있다. 여기에 Data Parallelism을 적용한다고 하면 아래와 같은 코드를 작성할 수 있다. class SumRunnable implements Runnable { AtomicInteger sum; int start, end; public SumRunnable(AtomicInteger sum, int start, int end) { this.sum = sum; this.start = start; this.end = end; } @Override public void run() { for (int i = start; i &lt; end; i++) { sum.addAndGet(i); try { Thread.sleep(1000); } catch (Exception e) { //Nothing to do } } } } @Test public void testDataParallelism() throws Exception { long startMillis = System.currentTimeMillis(); AtomicInteger sum = new AtomicInteger(0); List&lt;Thread&gt; threads = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 4; i++) { int start = i * 4; int end = start + 4; Thread t = new Thread(new SumRunnable(sum, start, end)); t.start(); threads.add(t); } for (Thread t : threads) t.join(); long endMillis = System.currentTimeMillis(); Assert.assertEquals(120, sum.get()); System.out.println(String.format(&quot;Elapsed: %d&quot;, (endMillis - startMillis))); } 0 ~ 16까지의 값을 [0 ~ 3], [4 ~ 7], [8 ~ 11], [12 ~ 15] 로 총 4개의 범위로 분할한 뒤, 각 범위를 하나의 프로세서(스레드)에게 할당하였다. 기존 N의 작업을 N/4 씩 나누어 동시에 수행하기 때문에 전체 소요 시간도 16초 -&gt; 4초로 감소한 것을 확인할 수 있다. Task Parallelism Task Parallelism은 데이터가 아닌 작업들을 나누어 수행하는 방법이다. 흔히 볼 수 있는 Task Parallelism은 Pipelining이 있다. 자동차 공장에서 자동차를 만들 때 수행해야 하는 공정이 아래와 같다고 하자. 부품 만들기(A) 차체 만들기(B) 조립하기(C) 도장하기(D) 내장 조립하기(E) 하부 조립하기(F) 이 중 A와 B, E와 F는 서로 동시에 진행될 수 있다고 할 때 공정을 아래와 같이 나눌 수 있을 것이다.(괄호 안의 공정은 동시에 수행될 수 있다는 의미) (A, B) -&gt; C -&gt; D -&gt; (E, F) 동일한 차(데이터)에 대해 A, B와 E, F 작업을 나누어 동시에 처리하였다. 또 다른 예제는 아래와 같다. 입력에 대해 합을 구하는 연산자(A)와 곱을 구하는 연산자(B)가 있고, 이를 처리할 수 있는 프로세서 2개(Processor1, Processor2)가 있다고 하자. Task Parallelism은 Processor1에 A 연산, Processor2에 B 연산을 할당하여 입력 데이터에 대해 각기 다른 연산을 동시에 처리한다. 예를 들어 아래와 같이 특정 구간의 합과 곱을 구하는 함수를 작성한다고 하자. 합 연산의 경우 1초, 곱 연산의 경우 2초가 소요된다고 가정하자. @Test public void testSumAndMultiple() throws Exception { int sum = 0, multiple = 1; long start = System.currentTimeMillis(); for (int i = 1; i &lt;= 8; i++) { sum += i; Thread.sleep(1000); } for (int i = 1; i &lt;= 8; i++) { multiple *= i; Thread.sleep(2000); } long end = System.currentTimeMillis(); Assert.assertEquals(36, sum); Assert.assertEquals(40320, multiple); System.out.println(String.format(&quot;Elapsed: %d&quot;, (end - start))); } 총 24초의 시간이 소요된 것을 확인할 수 있다. 여기에 Task Parallelism을 적용하면 아래와 같은 코드를 작성할 수 있다. class SumRunnable implements Runnable { AtomicInteger sum; int start, end; public SumRunnable(AtomicInteger sum, int start, int end) { this.sum = sum; this.start = start; this.end = end; } @Override public void run() { for (int i = start; i &lt;= end; i++) { sum.addAndGet(i); try { Thread.sleep(1000); } catch (Exception e) { //Nothing to do } } } } class MultipleRunnable implements Runnable { AtomicInteger multiple; int start, end; public MultipleRunnable(AtomicInteger multiple, int start, int end) { this.multiple = multiple; this.start = start; this.end = end; } @Override public void run() { for (int i = start; i &lt;= end; i++) { final int toMultiple = i; multiple.updateAndGet(v -&gt; v * toMultiple); try { Thread.sleep(2); } catch (Exception e) { //Nothing to do } } } } @Test public void testTaskParallelism() throws Exception { AtomicInteger sum = new AtomicInteger(0), multiple = new AtomicInteger(1); long start = System.currentTimeMillis(); Thread sumThread = new Thread(new SumRunnable(sum, 1, 8)); Thread multipleThread = new Thread(new MultipleRunnable(multiple, 1, 8)); sumThread.start(); multipleThread.start(); sumThread.join(); multipleThread.join(); long end = System.currentTimeMillis(); Assert.assertEquals(36, sum.get()); Assert.assertEquals(40320, multiple.get()); System.out.println(String.format(&quot;Elapsed: %d&quot;, (end - start))); } 합 연산을 수행하는 작업(sumThread)과 곱 연산을 수행하는 작업(multipleThread)을 각 작업 당 하나의 프로세서(스레드)가 수행할 수 있도록 하였다. 결과적으로 총 소요 시간이 24초 -&gt; 8초로 줄어든 것을 확인할 수 있었다. 병렬처리와 성능 병렬처리를 통해 얻을 수 있는 성능 향상은 암달의 법칙(Amdahl’s law)과 구스타프슨의 법칙(Gustafson’s Law)에서 다룬다. 암달의 법칙(Amdahl’s law) 위 Task Parallelism의 자동차 예제에서도 나왔지만, 작업 파이프라인 중에는 병렬화가 가능한 부분도 있지만 병렬화가 불가능한 부분(직렬)도 있다. 암달의 법칙은 컴퓨터 시스템의 일부를 개선(병렬화)할 때 전체적으로 얼마만큼의 성능 향상(기존 직렬적인 부분 + 병렬화된 부분)이 있는지 계산하는데에 사용된다. 공식은 아래와 같다. 전체 성능 향상 = 1 / ((1 - P) + (P / S)) 위 공식에서 P는 성능 향상을 이루어낸(병렬화된) 부분의 비율이고, S는 향상된 성능을 나타낸다. 예를 들어 작업의 80%에 대해 속도를 4배로 늘렸다 하면 아래와 같이 계산할 수 있다. 전체 성능 향상 = 1 / ((1 - 0.8) + (0.8 / 4)) = 2.5 작업의 80%에 대해 4배의 성능 향상을 이루어냈더라도 전체적으로는 고작 2.5배의 성능 향상밖에 이루어내지 못했다. 아래와 같이 작업의 99%에 대해 수천, 수만 배의 성능 향상이 이루어진다 해도 전체적으로는 최대 20배의 성능 향상 밖에 이루어내지 못한다는 절망적인 법칙이다. 그림 출처: Wikipedia - 암달의 법칙 구스타프슨의 법칙(Gustafson’s Law) 구스타프슨의 법칙은 암달의 법칙과 반대로 대용량 작업은 효율적으로 병렬화 할 수 있다는 가정 하에 만들어진 법칙이다. 공식은 아래와 같다. S(P) = P - α(P - 1) 위 공식에서 P는 프로세서의 수, S는 성능 향상, α는 병렬화되지 않는 순차적인 부분의 비율이다. 자세한 공식 유도 방법은 Wikipedia - 구스타프슨의 법칙을 참고하면 좋다. 위 공식대로라면 순차적인 부분의 비율이 낮을 수록 거의 프로세서 수 만큼의 성능 향상을 이뤄낼 수 있다. 따라서 문제의 크기가 커진다 해도 프로세서의 수를 늘리면 동일한 시간 안에 처리할 수 있다는 결론이 나오게 된다. Spark나 Flink와 같은 병렬 처리 프레임워크를 사용하며 데이터 처리를 수행하며 느낀 것은 어느정도 구스타프슨의 법칙이 맞아 떨어진다는 것이다. 거의 대부분의 경우에서 프로세서(혹은 장비)의 수를 늘리면 전체적인 성능 향상이 크게 나타나는 것을 느꼈다. 다만 현실 세계 문제에서는 Shuffle 등에 사용되는 Network Overhead나 Source, Sink 과정에서 사용되는 Persistent Storage 들의 성능이 오히려 전체 파이프라인 성능에 크게 영향을 주는 것이 많았던 것 같다. Flink에서의 병렬 처리 그림 출처: Apache Flink - Task and operator chains Operator, Task Operator는 Flink에서 수행되는 연산의 가장 작은 단위로 map, flatMap 등이 존재한다. 이러한 Operator들을 Chaining하여 Task로 만들 수 있다. 각 Task는 하나의 Thread에서 수행되며, Operator를 Task로 묶음으로써 Task 간 데이터 교환 오버헤드를 줄일 수 있다. Flink에서 Task는 동일한 TaskManager에서 수행될 수도 있지만, 다른 장비에서 수행되고 있는 TaskManager에 의해 실행될 수도 있기 때문에, Task 간 데이터 교환에는 아래와 같은 작업이 수행된다. Task A의 결과 데이터를 Serialization 한다. Serialization 된 결과 데이터를 TCP를 통해 다른 장비에서 실행 중인 TaskManager로 전달한다. 데이터를 수신한 TaskManager는 Deserialization을 수행하여 새로운 Task의 입력 데이터로 활용한다. 여러 개의 Operator를 한 개의 Task로 묶으면 하나의 Thread에서 Method Chaining 처럼 동작하기 때문에 위와 같은 Overhead의 발생을 피할 수 있다. TaskManager와 Task Slot Flink에서 TaskManager는 Task의 실행을 담당하는 컴포넌트이다. TaskManager는 1개의 JVM Process로써 동작하며, 내부적으로 1개 이상의 스레드를 통해 1개 이상의 Task를 실행할 수 있다.(Task Parallelism) 위의 각 스레드를 Task Slot이라 한다. 1개의 TaskManager가 1개 이상의 Task Slot을 소유하므로써 가지는 특징은 아래와 같다. JVM 메모리 공유 하나의 TaskManager에 속한 Task Slot들은 TaskManager의 메모리를 나누어 사용한다. 예를 들어 600MB의 Heap 공간을 가진 TaskManager에 3개의 Slot이 존재한다면, 각 Slot은 200MB 씩 메모리를 나누어 가진다. JVM 실행에 필요한 메모리가 존재하기 때문에, TaskManager에 Slot의 수가 많을 수록 이러한 메모리 오버헤드를 줄일 수 있다. CPU Isolation 불가 다만 1개의 TaskManager에 속한 Slot들은 JVM Thread로써 동작하기 때문에 CPU Isolation은 이룰 수 없다. CPU Isolation이 필요하다면 TaskManager 별로 Slot을 1개씩 가지게 하고, 각 TaskManager를 통해 CPU Isolation을 달성해야 한다. TaskManager에서 사용하는 자원 공유 TaskManager에는 데이터 교환을 위한 TCP 연결이나 내부 객체 등 다양한 리소스가 존재한다. 하나의 TaskManager에 속한 Slot들은 이러한 자원을 공유하게 된다. Task와 Subtask 그리고 Slot Sharing 그림 출처: Apache Flink - Task Slots and Resources 1개의 Task는 1개 이상의 Subtask로 나뉠 수 있다. 즉, 동일한 연산(Task, Operator Set)을 수행하는 Processor들이 여러 개 존재하는 구조이다.(Data Parallelism) 위의 Task Slot에서 실행하는 작업의 단위는 사실 Task가 아닌 Subtask 단위이다. 만일 2개의 Task(Task A, Task B)가 존재하고, 각 Task마다 3개의 Subtask로 실행해야 한다고 가정하면, 총 6개의 Slot이 필요하다. 그런데 Task A는 Task B에 비해 매우 빠르게 수행되는 연산이라고 가정해보자. Task A를 담당하는 CPU는 Utilization이 낮고, Task B를 담당하는 CPU는 Utilization이 매우 높을 것이다. 이러한 비효율을 줄이기 위해 Flink에서는 Slot Sharing을 지원한다. Slot Sharing은 Job을 구성하는 Task 중 가장 높은 Parallelism(Subtask의 수)만큼의 Slot을 만들고, 모든 Task들이 이 Slot을 공유하는 방식이다. 어차피 Subtask들은 Thread이기 때문에 Time slicing을 통해 균등하게 작업 시간을 할당받을 것이고, Task A 처리가 끝나고 Task B 처리만 남았을 때는 Task B가 모든 CPU 자원을 사용할 수 있기 때문에 매우 효율적인 자원 운용이 가능해진다.","url":"https://leeyh0216.github.io/posts/flink_concepts_1/","@type":"BlogPosting","headline":"Flink Concept - Operator, Task, Parallelism","dateModified":"2020-08-02T18:10:00+09:00","datePublished":"2020-08-02T18:10:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://leeyh0216.github.io/posts/flink_concepts_1/"},"@context":"https://schema.org"}</script><title>Flink Concept - Operator, Task, Parallelism | leeyh0216's devlog</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script async src="https://cdn.jsdelivr.net/npm/countup.js@1.9.3/dist/countUp.min.js"></script> <script async src="/assets/js/dist/pvreport.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=UA-129061352-1"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-129061352-1'); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://cdn.jsdelivr.net/gh/cotes2020/chirpy-images/commons/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">leeyh0216's devlog</a></div><div class="site-subtitle font-italic">개발/일상 블로그</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/leeyh0216" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://www.linkedin.com/in/%EC%9A%A9%ED%99%98-%EC%9D%B4-84222a119/" aria-label="linkedin" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['leeyh0216','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Flink Concept - Operator, Task, Parallelism</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Flink Concept - Operator, Task, Parallelism</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> leeyh0216 </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Sun, Aug 2, 2020, 6:10 PM +0900" prep="on" > Aug 2, 2020 <i class="unloaded">2020-08-02T18:10:00+09:00</i> </span></div><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3290 words">18 min</span> <span id="pv" class="pageviews"><i class="fas fa-spinner fa-spin fa-fw"></i></span></div></div><div class="post-content"><h1 id="개요">개요</h1><p>진행 중인 프로젝트에서 Flink를 사용할 기회가 생겼다. 처음 코드를 작성할 때는 ‘Spark과 거의 비슷하네?’ 라는 생각을 했는데, 사용하면 할 수록 다른 부분을 많이 느끼게 되어 정리 차 글을 작성한다.</p><p>아래 자료들을 참고하여 작성하였다.</p><ul><li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/flink-architecture.html">Apache Flink - Flink Architecture</a><li><a href="https://www.samsungsds.com/global/ko/news/story/1203227_2919.html">삼성 SDS - 연산 처리의 성능 한계에 도전하는 병렬 컴퓨팅</a><li><a href="http://acornpub.co.kr/book/stream-processing-flink">Streaming Processing with Apache Flink - O’REILLY</a><li><a href="https://www.zdnet.com/article/understanding-task-and-data-parallelism-3039289129/">ZDNET - Understanding task and data parallelism</a></ul><h2 id="병렬처리-개념">병렬처리 개념</h2><p>병렬 컴퓨팅을 사용하면 많은 데이터나 작업들을 동시 수행하여 빠르게 처리할 수 있다. 병렬 컴퓨팅은 하나의 방법이 아니며, 아래와 같이 여러 방식들이 존재한다.</p><ul><li><a href="https://en.wikipedia.org/wiki/Bit-level_parallelism">Bit-Level Parallelism</a><li><a href="https://en.wikipedia.org/wiki/Instruction-level_parallelism">Instruction Level Parallelism</a><li><a href="https://en.wikipedia.org/wiki/Data_parallelism">Data Parallelism</a><li><a href="https://en.wikipedia.org/wiki/Data_parallelism">Task Parallelism</a></ul><p>Flink는 Data Parallelism과 Task Parallelism을 결합하여 사용하기 때문에, 이 글에서는 Data Paralleism과 Task Parallelism만 다룬다.</p><h3 id="data-parallelism">Data Parallelism</h3><p>Data Parallelism은 데이터를 각기 다른 노드(혹은 프로세서)에 분산하여 병렬적으로 연산을 수행하는 방법이다.</p><p>아래와 같이 0 ~ 15까지의 합을 구하는 함수를 작성한다고 가정하자. 하나의 합을 구할 때 소요되는 시간은 약 1초이다.</p><figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nd">@Test</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">testSum</span><span class="o">()</span> <span class="kd">throws</span> <span class="nc">Exception</span> <span class="o">{</span>
  <span class="kt">long</span> <span class="n">start</span> <span class="o">=</span> <span class="nc">System</span><span class="o">.</span><span class="na">currentTimeMillis</span><span class="o">();</span>
  <span class="kt">int</span> <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
  <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">16</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
    <span class="n">sum</span> <span class="o">+=</span> <span class="n">i</span><span class="o">;</span>
    <span class="nc">Thread</span><span class="o">.</span><span class="na">sleep</span><span class="o">(</span><span class="mi">1000</span><span class="o">);</span>
  <span class="o">}</span>
  <span class="kt">long</span> <span class="n">end</span> <span class="o">=</span> <span class="nc">System</span><span class="o">.</span><span class="na">currentTimeMillis</span><span class="o">();</span>
  <span class="nc">Assert</span><span class="o">.</span><span class="na">assertEquals</span><span class="o">(</span><span class="mi">120</span><span class="o">,</span> <span class="n">sum</span><span class="o">);</span>
  <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="nc">String</span><span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">"Elapsed: %d"</span><span class="o">,</span> <span class="o">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="o">)));</span>
<span class="o">}</span></code></pre></figure><p>총 16초 가량이 소요된 것을 확인할 수 있다.</p><p>여기에 Data Parallelism을 적용한다고 하면 아래와 같은 코드를 작성할 수 있다.</p><figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">class</span> <span class="nc">SumRunnable</span> <span class="kd">implements</span> <span class="nc">Runnable</span> <span class="o">{</span>
  <span class="nc">AtomicInteger</span> <span class="n">sum</span><span class="o">;</span>
  <span class="kt">int</span> <span class="n">start</span><span class="o">,</span> <span class="n">end</span><span class="o">;</span>

  <span class="kd">public</span> <span class="nf">SumRunnable</span><span class="o">(</span><span class="nc">AtomicInteger</span> <span class="n">sum</span><span class="o">,</span> <span class="kt">int</span> <span class="n">start</span><span class="o">,</span> <span class="kt">int</span> <span class="n">end</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">this</span><span class="o">.</span><span class="na">sum</span> <span class="o">=</span> <span class="n">sum</span><span class="o">;</span>
    <span class="k">this</span><span class="o">.</span><span class="na">start</span> <span class="o">=</span> <span class="n">start</span><span class="o">;</span>
    <span class="k">this</span><span class="o">.</span><span class="na">end</span> <span class="o">=</span> <span class="n">end</span><span class="o">;</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">run</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">start</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">end</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
      <span class="n">sum</span><span class="o">.</span><span class="na">addAndGet</span><span class="o">(</span><span class="n">i</span><span class="o">);</span>
      <span class="k">try</span> <span class="o">{</span>
        <span class="nc">Thread</span><span class="o">.</span><span class="na">sleep</span><span class="o">(</span><span class="mi">1000</span><span class="o">);</span>
      <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="nc">Exception</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
        <span class="c1">//Nothing to do
</span>
      <span class="o">}</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="nd">@Test</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">testDataParallelism</span><span class="o">()</span> <span class="kd">throws</span> <span class="nc">Exception</span> <span class="o">{</span>
  <span class="kt">long</span> <span class="n">startMillis</span> <span class="o">=</span> <span class="nc">System</span><span class="o">.</span><span class="na">currentTimeMillis</span><span class="o">();</span>
  <span class="nc">AtomicInteger</span> <span class="n">sum</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">AtomicInteger</span><span class="o">(</span><span class="mi">0</span><span class="o">);</span>
  <span class="nc">List</span><span class="o">&lt;</span><span class="nc">Thread</span><span class="o">&gt;</span> <span class="n">threads</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ArrayList</span><span class="o">&lt;&gt;();</span>
  <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">4</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
    <span class="kt">int</span> <span class="n">start</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="mi">4</span><span class="o">;</span>
    <span class="kt">int</span> <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="mi">4</span><span class="o">;</span>
    <span class="nc">Thread</span> <span class="n">t</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Thread</span><span class="o">(</span><span class="k">new</span> <span class="nc">SumRunnable</span><span class="o">(</span><span class="n">sum</span><span class="o">,</span> <span class="n">start</span><span class="o">,</span> <span class="n">end</span><span class="o">));</span>
    <span class="n">t</span><span class="o">.</span><span class="na">start</span><span class="o">();</span>
    <span class="n">threads</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">t</span><span class="o">);</span>
  <span class="o">}</span>
  <span class="k">for</span> <span class="o">(</span><span class="nc">Thread</span> <span class="n">t</span> <span class="o">:</span> <span class="n">threads</span><span class="o">)</span>
    <span class="n">t</span><span class="o">.</span><span class="na">join</span><span class="o">();</span>
  <span class="kt">long</span> <span class="n">endMillis</span> <span class="o">=</span> <span class="nc">System</span><span class="o">.</span><span class="na">currentTimeMillis</span><span class="o">();</span>
  <span class="nc">Assert</span><span class="o">.</span><span class="na">assertEquals</span><span class="o">(</span><span class="mi">120</span><span class="o">,</span> <span class="n">sum</span><span class="o">.</span><span class="na">get</span><span class="o">());</span>
  <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="nc">String</span><span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">"Elapsed: %d"</span><span class="o">,</span> <span class="o">(</span><span class="n">endMillis</span> <span class="o">-</span> <span class="n">startMillis</span><span class="o">)));</span>
<span class="o">}</span></code></pre></figure><p>0 ~ 16까지의 값을 [0 ~ 3], [4 ~ 7], [8 ~ 11], [12 ~ 15] 로 총 4개의 범위로 분할한 뒤, 각 범위를 하나의 프로세서(스레드)에게 할당하였다.</p><p>기존 N의 작업을 N/4 씩 나누어 동시에 수행하기 때문에 전체 소요 시간도 16초 -&gt; 4초로 감소한 것을 확인할 수 있다.</p><h3 id="task-parallelism">Task Parallelism</h3><p>Task Parallelism은 데이터가 아닌 작업들을 나누어 수행하는 방법이다.</p><p>흔히 볼 수 있는 Task Parallelism은 Pipelining이 있다. 자동차 공장에서 자동차를 만들 때 수행해야 하는 공정이 아래와 같다고 하자.</p><ul><li>부품 만들기(A)<li>차체 만들기(B)<li>조립하기(C)<li>도장하기(D)<li>내장 조립하기(E)<li>하부 조립하기(F)</ul><p>이 중 A와 B, E와 F는 서로 동시에 진행될 수 있다고 할 때 공정을 아래와 같이 나눌 수 있을 것이다.(괄호 안의 공정은 동시에 수행될 수 있다는 의미)</p><p>(A, B) -&gt; C -&gt; D -&gt; (E, F)</p><p>동일한 차(데이터)에 대해 A, B와 E, F 작업을 나누어 동시에 처리하였다. 또 다른 예제는 아래와 같다.</p><p>입력에 대해 합을 구하는 연산자(A)와 곱을 구하는 연산자(B)가 있고, 이를 처리할 수 있는 프로세서 2개(Processor1, Processor2)가 있다고 하자. Task Parallelism은 Processor1에 A 연산, Processor2에 B 연산을 할당하여 입력 데이터에 대해 각기 다른 연산을 동시에 처리한다.</p><p>예를 들어 아래와 같이 특정 구간의 합과 곱을 구하는 함수를 작성한다고 하자. 합 연산의 경우 1초, 곱 연산의 경우 2초가 소요된다고 가정하자.</p><figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nd">@Test</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">testSumAndMultiple</span><span class="o">()</span> <span class="kd">throws</span> <span class="nc">Exception</span> <span class="o">{</span>
  <span class="kt">int</span> <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span><span class="o">,</span> <span class="n">multiple</span> <span class="o">=</span> <span class="mi">1</span><span class="o">;</span>
  <span class="kt">long</span> <span class="n">start</span> <span class="o">=</span> <span class="nc">System</span><span class="o">.</span><span class="na">currentTimeMillis</span><span class="o">();</span>
  <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="mi">8</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
    <span class="n">sum</span> <span class="o">+=</span> <span class="n">i</span><span class="o">;</span>
    <span class="nc">Thread</span><span class="o">.</span><span class="na">sleep</span><span class="o">(</span><span class="mi">1000</span><span class="o">);</span>
  <span class="o">}</span>
  <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="mi">8</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
    <span class="n">multiple</span> <span class="o">*=</span> <span class="n">i</span><span class="o">;</span>
    <span class="nc">Thread</span><span class="o">.</span><span class="na">sleep</span><span class="o">(</span><span class="mi">2000</span><span class="o">);</span>
  <span class="o">}</span>
  <span class="kt">long</span> <span class="n">end</span> <span class="o">=</span> <span class="nc">System</span><span class="o">.</span><span class="na">currentTimeMillis</span><span class="o">();</span>

  <span class="nc">Assert</span><span class="o">.</span><span class="na">assertEquals</span><span class="o">(</span><span class="mi">36</span><span class="o">,</span> <span class="n">sum</span><span class="o">);</span>
  <span class="nc">Assert</span><span class="o">.</span><span class="na">assertEquals</span><span class="o">(</span><span class="mi">40320</span><span class="o">,</span> <span class="n">multiple</span><span class="o">);</span>
  <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="nc">String</span><span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">"Elapsed: %d"</span><span class="o">,</span> <span class="o">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="o">)));</span>
<span class="o">}</span></code></pre></figure><p>총 24초의 시간이 소요된 것을 확인할 수 있다.</p><p>여기에 Task Parallelism을 적용하면 아래와 같은 코드를 작성할 수 있다.</p><figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">class</span> <span class="nc">SumRunnable</span> <span class="kd">implements</span> <span class="nc">Runnable</span> <span class="o">{</span>
  <span class="nc">AtomicInteger</span> <span class="n">sum</span><span class="o">;</span>
  <span class="kt">int</span> <span class="n">start</span><span class="o">,</span> <span class="n">end</span><span class="o">;</span>

  <span class="kd">public</span> <span class="nf">SumRunnable</span><span class="o">(</span><span class="nc">AtomicInteger</span> <span class="n">sum</span><span class="o">,</span> <span class="kt">int</span> <span class="n">start</span><span class="o">,</span> <span class="kt">int</span> <span class="n">end</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">this</span><span class="o">.</span><span class="na">sum</span> <span class="o">=</span> <span class="n">sum</span><span class="o">;</span>
    <span class="k">this</span><span class="o">.</span><span class="na">start</span> <span class="o">=</span> <span class="n">start</span><span class="o">;</span>
    <span class="k">this</span><span class="o">.</span><span class="na">end</span> <span class="o">=</span> <span class="n">end</span><span class="o">;</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">run</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">start</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">end</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
      <span class="n">sum</span><span class="o">.</span><span class="na">addAndGet</span><span class="o">(</span><span class="n">i</span><span class="o">);</span>
      <span class="k">try</span> <span class="o">{</span>
        <span class="nc">Thread</span><span class="o">.</span><span class="na">sleep</span><span class="o">(</span><span class="mi">1000</span><span class="o">);</span>
      <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="nc">Exception</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
        <span class="c1">//Nothing to do
</span>
      <span class="o">}</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="kd">class</span> <span class="nc">MultipleRunnable</span> <span class="kd">implements</span> <span class="nc">Runnable</span> <span class="o">{</span>
  <span class="nc">AtomicInteger</span> <span class="n">multiple</span><span class="o">;</span>
  <span class="kt">int</span> <span class="n">start</span><span class="o">,</span> <span class="n">end</span><span class="o">;</span>

  <span class="kd">public</span> <span class="nf">MultipleRunnable</span><span class="o">(</span><span class="nc">AtomicInteger</span> <span class="n">multiple</span><span class="o">,</span> <span class="kt">int</span> <span class="n">start</span><span class="o">,</span> <span class="kt">int</span> <span class="n">end</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">this</span><span class="o">.</span><span class="na">multiple</span> <span class="o">=</span> <span class="n">multiple</span><span class="o">;</span>
    <span class="k">this</span><span class="o">.</span><span class="na">start</span> <span class="o">=</span> <span class="n">start</span><span class="o">;</span>
    <span class="k">this</span><span class="o">.</span><span class="na">end</span> <span class="o">=</span> <span class="n">end</span><span class="o">;</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">run</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">start</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">end</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
      <span class="kd">final</span> <span class="kt">int</span> <span class="n">toMultiple</span> <span class="o">=</span> <span class="n">i</span><span class="o">;</span>
      <span class="n">multiple</span><span class="o">.</span><span class="na">updateAndGet</span><span class="o">(</span><span class="n">v</span> <span class="o">-&gt;</span> <span class="n">v</span> <span class="o">*</span> <span class="n">toMultiple</span><span class="o">);</span>
      <span class="k">try</span> <span class="o">{</span>
        <span class="nc">Thread</span><span class="o">.</span><span class="na">sleep</span><span class="o">(</span><span class="mi">2</span><span class="o">);</span>
      <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="nc">Exception</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
        <span class="c1">//Nothing to do
</span>
      <span class="o">}</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="nd">@Test</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">testTaskParallelism</span><span class="o">()</span> <span class="kd">throws</span> <span class="nc">Exception</span> <span class="o">{</span>
  <span class="nc">AtomicInteger</span> <span class="n">sum</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">AtomicInteger</span><span class="o">(</span><span class="mi">0</span><span class="o">),</span> <span class="n">multiple</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">AtomicInteger</span><span class="o">(</span><span class="mi">1</span><span class="o">);</span>

  <span class="kt">long</span> <span class="n">start</span> <span class="o">=</span> <span class="nc">System</span><span class="o">.</span><span class="na">currentTimeMillis</span><span class="o">();</span>
  <span class="nc">Thread</span> <span class="n">sumThread</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Thread</span><span class="o">(</span><span class="k">new</span> <span class="nc">SumRunnable</span><span class="o">(</span><span class="n">sum</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">8</span><span class="o">));</span>
  <span class="nc">Thread</span> <span class="n">multipleThread</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Thread</span><span class="o">(</span><span class="k">new</span> <span class="nc">MultipleRunnable</span><span class="o">(</span><span class="n">multiple</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">8</span><span class="o">));</span>
  <span class="n">sumThread</span><span class="o">.</span><span class="na">start</span><span class="o">();</span>
  <span class="n">multipleThread</span><span class="o">.</span><span class="na">start</span><span class="o">();</span>
  <span class="n">sumThread</span><span class="o">.</span><span class="na">join</span><span class="o">();</span>
  <span class="n">multipleThread</span><span class="o">.</span><span class="na">join</span><span class="o">();</span>
  <span class="kt">long</span> <span class="n">end</span> <span class="o">=</span> <span class="nc">System</span><span class="o">.</span><span class="na">currentTimeMillis</span><span class="o">();</span>

  <span class="nc">Assert</span><span class="o">.</span><span class="na">assertEquals</span><span class="o">(</span><span class="mi">36</span><span class="o">,</span> <span class="n">sum</span><span class="o">.</span><span class="na">get</span><span class="o">());</span>
  <span class="nc">Assert</span><span class="o">.</span><span class="na">assertEquals</span><span class="o">(</span><span class="mi">40320</span><span class="o">,</span> <span class="n">multiple</span><span class="o">.</span><span class="na">get</span><span class="o">());</span>
  <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="nc">String</span><span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">"Elapsed: %d"</span><span class="o">,</span> <span class="o">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="o">)));</span>
<span class="o">}</span></code></pre></figure><p>합 연산을 수행하는 작업(<code class="language-plaintext highlighter-rouge">sumThread</code>)과 곱 연산을 수행하는 작업(<code class="language-plaintext highlighter-rouge">multipleThread</code>)을 각 작업 당 하나의 프로세서(스레드)가 수행할 수 있도록 하였다.</p><p>결과적으로 총 소요 시간이 24초 -&gt; 8초로 줄어든 것을 확인할 수 있었다.</p><h3 id="병렬처리와-성능">병렬처리와 성능</h3><p>병렬처리를 통해 얻을 수 있는 성능 향상은 <a href="https://ko.wikipedia.org/wiki/%EC%95%94%EB%8B%AC%EC%9D%98_%EB%B2%95%EC%B9%99">암달의 법칙(Amdahl’s law)</a>과 <a href="https://ko.wikipedia.org/wiki/%EA%B5%AC%EC%8A%A4%ED%83%80%ED%94%84%EC%8A%A8%EC%9D%98_%EB%B2%95%EC%B9%99">구스타프슨의 법칙(Gustafson’s Law)</a>에서 다룬다.</p><h4 id="암달의-법칙amdahls-law">암달의 법칙(Amdahl’s law)</h4><p>위 Task Parallelism의 자동차 예제에서도 나왔지만, 작업 파이프라인 중에는 병렬화가 가능한 부분도 있지만 병렬화가 불가능한 부분(직렬)도 있다.</p><p>암달의 법칙은 컴퓨터 시스템의 일부를 개선(병렬화)할 때 전체적으로 얼마만큼의 성능 향상(기존 직렬적인 부분 + 병렬화된 부분)이 있는지 계산하는데에 사용된다. 공식은 아래와 같다.</p><p>전체 성능 향상 = 1 / ((1 - P) + (P / S))</p><p>위 공식에서 P는 성능 향상을 이루어낸(병렬화된) 부분의 비율이고, S는 향상된 성능을 나타낸다. 예를 들어 작업의 80%에 대해 속도를 4배로 늘렸다 하면 아래와 같이 계산할 수 있다.</p><p>전체 성능 향상 = 1 / ((1 - 0.8) + (0.8 / 4)) = 2.5</p><p>작업의 80%에 대해 4배의 성능 향상을 이루어냈더라도 전체적으로는 고작 2.5배의 성능 향상밖에 이루어내지 못했다. 아래와 같이 작업의 99%에 대해 수천, 수만 배의 성능 향상이 이루어진다 해도 전체적으로는 최대 20배의 성능 향상 밖에 이루어내지 못한다는 절망적인 법칙이다.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/AmdahlsLaw.svg/600px-AmdahlsLaw.svg.png" alt="암달의 법칙, 출처: Wikipedia" /></p><blockquote><p>그림 출처: <a href="https://ko.wikipedia.org/wiki/%EC%95%94%EB%8B%AC%EC%9D%98_%EB%B2%95%EC%B9%99">Wikipedia - 암달의 법칙</a></p></blockquote><h4 id="구스타프슨의-법칙gustafsons-law">구스타프슨의 법칙(Gustafson’s Law)</h4><p>구스타프슨의 법칙은 암달의 법칙과 반대로 대용량 작업은 효율적으로 병렬화 할 수 있다는 가정 하에 만들어진 법칙이다. 공식은 아래와 같다.</p><p>S(P) = P - α(P - 1)</p><p>위 공식에서 P는 프로세서의 수, S는 성능 향상, α는 병렬화되지 않는 순차적인 부분의 비율이다. 자세한 공식 유도 방법은 <a href="https://ko.wikipedia.org/wiki/%EA%B5%AC%EC%8A%A4%ED%83%80%ED%94%84%EC%8A%A8%EC%9D%98_%EB%B2%95%EC%B9%99">Wikipedia - 구스타프슨의 법칙</a>을 참고하면 좋다.</p><p>위 공식대로라면 순차적인 부분의 비율이 낮을 수록 거의 프로세서 수 만큼의 성능 향상을 이뤄낼 수 있다. 따라서 문제의 크기가 커진다 해도 프로세서의 수를 늘리면 동일한 시간 안에 처리할 수 있다는 결론이 나오게 된다.</p><hr /><blockquote><p>Spark나 Flink와 같은 병렬 처리 프레임워크를 사용하며 데이터 처리를 수행하며 느낀 것은 어느정도 구스타프슨의 법칙이 맞아 떨어진다는 것이다. 거의 대부분의 경우에서 프로세서(혹은 장비)의 수를 늘리면 전체적인 성능 향상이 크게 나타나는 것을 느꼈다.</p><p>다만 현실 세계 문제에서는 Shuffle 등에 사용되는 Network Overhead나 Source, Sink 과정에서 사용되는 Persistent Storage 들의 성능이 오히려 전체 파이프라인 성능에 크게 영향을 주는 것이 많았던 것 같다.</p></blockquote><h2 id="flink에서의-병렬-처리">Flink에서의 병렬 처리</h2><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/tasks_chains.svg" alt="Apache Flink - Task and operators" /></p><blockquote><p>그림 출처: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/flink-architecture.html">Apache Flink - Task and operator chains</a></p></blockquote><h3 id="operator-task">Operator, Task</h3><p>Operator는 Flink에서 수행되는 연산의 가장 작은 단위로 <code class="language-plaintext highlighter-rouge">map</code>, <code class="language-plaintext highlighter-rouge">flatMap</code> 등이 존재한다. 이러한 Operator들을 Chaining하여 Task로 만들 수 있다.</p><p>각 Task는 하나의 Thread에서 수행되며, Operator를 Task로 묶음으로써 Task 간 데이터 교환 오버헤드를 줄일 수 있다. Flink에서 Task는 동일한 TaskManager에서 수행될 수도 있지만, 다른 장비에서 수행되고 있는 TaskManager에 의해 실행될 수도 있기 때문에, Task 간 데이터 교환에는 아래와 같은 작업이 수행된다.</p><ul><li>Task A의 결과 데이터를 Serialization 한다.<li>Serialization 된 결과 데이터를 TCP를 통해 다른 장비에서 실행 중인 TaskManager로 전달한다.<li>데이터를 수신한 TaskManager는 Deserialization을 수행하여 새로운 Task의 입력 데이터로 활용한다.</ul><p>여러 개의 Operator를 한 개의 Task로 묶으면 하나의 Thread에서 Method Chaining 처럼 동작하기 때문에 위와 같은 Overhead의 발생을 피할 수 있다.</p><h3 id="taskmanager와-task-slot">TaskManager와 Task Slot</h3><p>Flink에서 TaskManager는 Task의 실행을 담당하는 컴포넌트이다. TaskManager는 1개의 JVM Process로써 동작하며, 내부적으로 1개 이상의 스레드를 통해 1개 이상의 Task를 실행할 수 있다.(Task Parallelism)</p><p>위의 각 스레드를 Task Slot이라 한다. 1개의 TaskManager가 1개 이상의 Task Slot을 소유하므로써 가지는 특징은 아래와 같다.</p><h4 id="jvm-메모리-공유">JVM 메모리 공유</h4><p>하나의 TaskManager에 속한 Task Slot들은 TaskManager의 메모리를 나누어 사용한다. 예를 들어 600MB의 Heap 공간을 가진 TaskManager에 3개의 Slot이 존재한다면, 각 Slot은 200MB 씩 메모리를 나누어 가진다.</p><blockquote><p>JVM 실행에 필요한 메모리가 존재하기 때문에, TaskManager에 Slot의 수가 많을 수록 이러한 메모리 오버헤드를 줄일 수 있다.</p></blockquote><h4 id="cpu-isolation-불가">CPU Isolation 불가</h4><p>다만 1개의 TaskManager에 속한 Slot들은 JVM Thread로써 동작하기 때문에 CPU Isolation은 이룰 수 없다. CPU Isolation이 필요하다면 TaskManager 별로 Slot을 1개씩 가지게 하고, 각 TaskManager를 통해 CPU Isolation을 달성해야 한다.</p><h4 id="taskmanager에서-사용하는-자원-공유">TaskManager에서 사용하는 자원 공유</h4><p>TaskManager에는 데이터 교환을 위한 TCP 연결이나 내부 객체 등 다양한 리소스가 존재한다. 하나의 TaskManager에 속한 Slot들은 이러한 자원을 공유하게 된다.</p><h3 id="task와-subtask-그리고-slot-sharing">Task와 Subtask 그리고 Slot Sharing</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://ci.apache.org/projects/flink/flink-docs-release-1.11/fig/slot_sharing.svg" alt="Apache Flink - Slot Sharing" /></p><blockquote><p>그림 출처: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/flink-architecture.html#task-slots-and-resources">Apache Flink - Task Slots and Resources</a></p></blockquote><p>1개의 Task는 1개 이상의 Subtask로 나뉠 수 있다. 즉, 동일한 연산(Task, Operator Set)을 수행하는 Processor들이 여러 개 존재하는 구조이다.(Data Parallelism)</p><p>위의 Task Slot에서 실행하는 작업의 단위는 사실 Task가 아닌 Subtask 단위이다. 만일 2개의 Task(Task A, Task B)가 존재하고, 각 Task마다 3개의 Subtask로 실행해야 한다고 가정하면, 총 6개의 Slot이 필요하다.</p><p>그런데 Task A는 Task B에 비해 매우 빠르게 수행되는 연산이라고 가정해보자. Task A를 담당하는 CPU는 Utilization이 낮고, Task B를 담당하는 CPU는 Utilization이 매우 높을 것이다. 이러한 비효율을 줄이기 위해 Flink에서는 Slot Sharing을 지원한다.</p><p>Slot Sharing은 Job을 구성하는 Task 중 가장 높은 Parallelism(Subtask의 수)만큼의 Slot을 만들고, 모든 Task들이 이 Slot을 공유하는 방식이다.</p><p>어차피 Subtask들은 Thread이기 때문에 Time slicing을 통해 균등하게 작업 시간을 할당받을 것이고, Task A 처리가 끝나고 Task B 처리만 남았을 때는 Task B가 모든 CPU 자원을 사용할 수 있기 때문에 매우 효율적인 자원 운용이 가능해진다.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/flink/'>flink</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Flink Concept - Operator, Task, Parallelism - leeyh0216's devlog&url=https://leeyh0216.github.io/posts/flink_concepts_1/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Flink Concept - Operator, Task, Parallelism - leeyh0216's devlog&u=https://leeyh0216.github.io/posts/flink_concepts_1/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Flink Concept - Operator, Task, Parallelism - leeyh0216's devlog&url=https://leeyh0216.github.io/posts/flink_concepts_1/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/ps/">ps</a> <a class="post-tag" href="/tags/spring/">spring</a> <a class="post-tag" href="/tags/leetcode/">leetcode</a> <a class="post-tag" href="/tags/apache-spark/">apache-spark</a> <a class="post-tag" href="/tags/java/">java</a> <a class="post-tag" href="/tags/kafka/">kafka</a> <a class="post-tag" href="/tags/apache-druid/">apache-druid</a> <a class="post-tag" href="/tags/string/">string</a> <a class="post-tag" href="/tags/study/">study</a> <a class="post-tag" href="/tags/docker/">docker</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/flink_checkpoint_1/"><div class="card-body"> <span class="timeago small" > Mar 1, 2021 <i class="unloaded">2021-03-01T17:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Flink Concept - Checkpointing(1)</h3><div class="text-muted small"><p> 이 글은 Coursera - Cloud Computing Concepts, Part 1을 참고하여 작성하였습니다. 개요 스트리밍 애플리케이션은 매우 긴 시간 동안 수행되며 내부적으로 상태를 가지고 있다. 예를 들어 아래와 같이 (사용자, 페이지 체류 시간)이 입력으로 들어오고, 평균 사용자 체류 시간을 계산하는 애플리케이션이 있다고 가정하자...</p></div></div></a></div><div class="card"> <a href="/posts/flink_output/"><div class="card-body"> <span class="timeago small" > Mar 26, 2021 <i class="unloaded">2021-03-26T00:10:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Flink Concept - Operator 간 데이터 교환</h3><div class="text-muted small"><p> 개요 Flink Job의 Operator 간의 데이터 교환이 어떻게 이루어지는지 알아보고, 유의해야 할 옵션은 어떤 것이 있는지 알아보도록 한다. Flink의 Input과 Ouptut 위와 같이 3개의 Operator가 연결되어 있다고 생각해보자. 한 Operator의 출력 데이터는 다른 Operator의 입력 데이터로 사용된다. 그래프 관점...</p></div></div></a></div><div class="card"> <a href="/posts/flink_object_reuse/"><div class="card-body"> <span class="timeago small" > Mar 27, 2021 <i class="unloaded">2021-03-27T00:10:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Flink Concept - pipeline.object_reuse</h3><div class="text-muted small"><p> 개요 이전 글에서 pipeline.object_reuse 옵션에 대해 설명하였다. 이 옵션을 사용하면 안되는 경우에 대해서는 Flink 공식 문서에 나와 있지 않으며, 이전 글에서도 제대로 설명하지 못했다. 이번 글에서는 언제 이 옵션을 사용하면 안되는지와 그럼에도 불구하고 옵션을 적용하고 싶은 경우 우회하는 방법에 대해 알아보도록 한다. pip...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/java_nio_buffer/" class="btn btn-outline-primary" prompt="Older"><p>Java NIO - 2. Buffers</p></a> <a href="/posts/fold_left_right/" class="btn btn-outline-primary" prompt="Newer"><p>FoldLeft와 FoldRight 제대로 알고 사용하기</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('.post-content img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2024 <a href="https://twitter.com/username">leeyh0216</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/ps/">ps</a> <a class="post-tag" href="/tags/spring/">spring</a> <a class="post-tag" href="/tags/leetcode/">leetcode</a> <a class="post-tag" href="/tags/apache-spark/">apache spark</a> <a class="post-tag" href="/tags/java/">java</a> <a class="post-tag" href="/tags/kafka/">kafka</a> <a class="post-tag" href="/tags/apache-druid/">apache druid</a> <a class="post-tag" href="/tags/string/">string</a> <a class="post-tag" href="/tags/study/">study</a> <a class="post-tag" href="/tags/docker/">docker</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://leeyh0216.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
