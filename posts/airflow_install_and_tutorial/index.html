<!DOCTYPE html><html lang="ko-KR" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8829030678254956" crossorigin="anonymous"></script><meta name="pv-proxy-endpoint" content=""><meta name="generator" content="Jekyll v4.2.0" /><meta property="og:title" content="Airflow 튜토리얼 실행해보기" /><meta name="author" content="leeyh0216" /><meta property="og:locale" content="ko_KR" /><meta name="description" content="Airflow 튜토리얼 실행해보기 Airflow 기본 개념 - DAG와 Operator 개요 Airflow를 사용할 일이 많아질 것 같아 사용법 정리 포스팅을 진행한다. Ubuntu 환경에서 설치, 운영, 활용 실습을 진행하려 했으나, 시간도 넉넉하지 않고 Airflow 자체를 설치하거나 운영하기보다는 활용하는 법을 손에 익히는 일이 중요할 것 같아 Docker airflow라는 Github에 올라와 있는 Docker compose 파일을 사용하여 실습을 진행한다. Airflow 실행 미리 준비해야할 사항 Docker Image로 만들어진 Airflow를 사용할 것이기 때문에 실행 환경에 Docker Engine과 Docker Compose가 미리 설치되어 있어야 한다. 실행 환경 Macbook Pro Early 2015, Mojave 10.14.6 Docker Desktop 2.1.0.5 Docker Engine 19.03.5 Docker Compose 1.24.1 Docker Compose로 Airflow 실행하기 Docker Hub에 올라와 있는 Dockerhub - puckel/docker-airflow 이미지를 Pull 한다. 1 &gt; docker pull puckel/docker-airflow Airflow 뿐만 아니라 Metadata Database로 사용되는 Postgresql과 CeleryExecutor를 사용하기 위한 Redis를 함께 실행하기 위해 Docker Compose로 실행해야 한다. 이 또한 [Github - puckel/docker-airflow]에 미리 정의된 Docker Compose 파일이 있기 때문에 아래와 같이 실행한다. 1 &gt; git clone https://github.com/puckel/docker-airflow.git Pull이 완료된 이후 docker-airflow 디렉토리로 접근해보면 아래와 같은 파일들이 존재하는 것을 확인할 수 있다. 1 2 3 Dockerfile config docker-compose-LocalExecutor.yml LICENSE dags script README.md docker-compose-CeleryExecutor.yml 우리가 사용할 Docker Compose 파일은 docker-compose-CeleryExecutor.yml이다. 해당 파일을 열어보면 실행할 Docker Container들과 사용할 포트, Volumn 경로 등이 지정되어 있는데, 필요하다면 수정하면 된다.(나는 8080포트가 이미 다른 프로세스에서 사용 중이라 Airflow Webserver의 Port mapping을 8080:8080에서 8081:8080으로 변경했다) 아래 명령어를 수행하여 Airflow Docker Image를 실행한다. 1 &gt; docker-compose -f docker-compose-CeleryExecutor.yml up -d 정상적으로 실행된다면 아래와 같은 로그를 남기며 명령어가 종료될 것이다. 1 2 3 4 5 6 7 Removing docker-airflow_webserver_1 docker-airflow_redis_1 is up-to-date docker-airflow_postgres_1 is up-to-date docker-airflow_flower_1 is up-to-date Starting 184bc6a95ed6_docker-airflow_webserver_1 ... done Starting docker-airflow_scheduler_1 ... done Starting docker-airflow_worker_1 ... done Airflow Webserver가 잘 떳는지 http://localhost:8080 주소로 들어가 확인해본다. Airflow Tutorial 진행 Airflow Tutorial 페이지를 참고하여 Tutorial을 진행한다. simple_bash.py DAG 파일 생성 simple_bash라는 이름의 DAG를 생성할 것이다. Docker Compose를 실행한 경로(다른 경로로 이동하지 않았다면 docker-airflow)에 dag라는 디렉토리가 있을 것이다. 이 디렉토리에 simple_bash.py 파일을 생성하고, 작성을 시작한다. import 구문 1 2 3 from datetime import datetime, timedelta from airflow import DAG from airflow.operators.bash_operator import BashOperator from airflow import DAG: 정의할 DAG에 매핑하는 클래스를 임포트한다. from airflow.operators.bash_operator import BashOperator: Bash 명령어를 실행할 Task Operator 클래스를 임포트한다. Default Arguments 객체 생성 DAG 및 DAG 내 Task들에 일괄적으로 적용할 속성 객체를 작성한다. 1 2 3 4 5 6 7 8 9 10 default_args={ &#39;owner&#39;: &#39;airflow&#39;, &#39;depends_on_past&#39;: False, &#39;start_date&#39;: datetime(2020, 5, 16, 14, 0), &#39;email&#39;: [&#39;leeyh0216@gmail.com&#39;], &#39;email_on_failure&#39;: False, &#39;email_on_retry&#39;: False, &#39;retries&#39;: 1, &#39;retry_delay&#39;: timedelta(minutes=1), } owner: 작업 소유자 ID depends_on_past: 특정 작업의 Upstream이 성공한 경우에만 해당 작업을 Trigger할 것인지에 대한 여부 start_date: DAG 최초 실행 시간(과거 혹은 예약 가능) email: 작업 실행 관련 이메일 수신 주소 목록 email_on_failure: 작업 실패 시 이메일 수신 여부 email_on_retry: 작업 재시도 시 이메일 수신 여부 retries: 작업 재시도 횟수 retry_delay: 작업 재시도 간격 DAG 정의 DAG 객체를 정의한다. 1 2 3 4 5 6 dag = DAG( &#39;tutorial_bash&#39;, default_args=default_args, description=&#39;My first tutorial bash DAG&#39;, schedule_interval= &#39;* * * * *&#39; ) schedule_interval: DAG 스케쥴링 간격(Cron 표현식 혹은 미리 정의된 속성 사용 가능) Task 정의 “hello world”를 출력하는 작업(say_hello)과 현재 시간을 출력하는 작업(what_time)을 정의할 것이다. 1 2 3 4 5 6 7 8 9 10 11 12 13 t1 = BashOperator( task_id=&#39;say_hello&#39;, bash_command=&#39;echo &quot;hello world&quot;&#39;, dag=dag ) t2 = BashOperator( task_id=&#39;what_time&#39;, bash_command=&#39;date&#39;, dag=dag ) t1 &gt;&gt; t2 BashOperator에는 다음과 같은 속성이 존재한다. task_id: 작업의 ID bash_command: 실행할 Bash Command dag: 작업이 속할 DAG 또한 t1 &gt;&gt; t2는 t1이 실행된 후 t2를 실행한다는 의미이다.(t1이 t2의 Upstream Task) Airflow CLI와 Webserver를 통해 생성된 DAG 확인하기 Airflow CLI로 방금 만든 DAG가 잘 반영되었는지 확인해보자. 원래는 airflow list_dags 명령어로 Airflow에 등록된 DAG 목록을 출력할 수 있는데, 여기서는 Docker Compose로 띄워 놓았기 때문에 airflow list_dags 명령어 앞에 docker-compose -f docker-compose-CeleryExecutor.yml run --rm webserver를 붙여주어야 한다. 1 2 3 4 5 6 7 &gt; docker-compose -f docker-compose-CeleryExecutor.yml run --rm webserver airflow list_dags ------------------------------------------------------------------- DAGS ------------------------------------------------------------------- tutorial tutorial_bash WebServer에서도 일정 시간이 지나면 아래와 같이 tutorial_bash가 만들어진 것을 확인할 수 있다. DAG를 활성화하여 실행 확인하기 만들어진 DAG는 활성화된 상태가 아니어서(Paused) 실행되지 않는다. 실행을 위해서는 CLI나 Web UI 상에서 ‘Off’ 버튼을 눌러 ‘On’ 상태로 변경해주어야 한다. CLI Command는 airflow unpause [DAG ID]로써 여기서는 Docker compose 명령어와 함께 아래와 같이 실행하면 된다. 1 2 3 4 &gt; docker-compose -f docker-compose-CeleryExecutor.yml run --rm webserver airflow unpause tutorial_bash [2020-05-16 06:04:41,772] INFO - Filling up the DagBag from /usr/local/airflow/dags/tutorial_bash.py Dag: tutorial_bash, paused: False Web UI에서 확인하면 ‘Off’였던 상태가 ‘On’으로 변경되고, DAG가 실행되고 있는 것을 볼 수 있다. 정리 UI와 개념에 익숙해지지 않아 오래 걸렸는데, 며칠 만져보면 운영에 큰 지장이 없을 정도로 사용 가능할 것 같다. 다만 실제 운영 환경에서 Airflow를 구축할 때 dags 디렉토리의 동기화나 프로젝트 배포 등을 어떻게 할지가 참 궁금하다." /><meta property="og:description" content="Airflow 튜토리얼 실행해보기 Airflow 기본 개념 - DAG와 Operator 개요 Airflow를 사용할 일이 많아질 것 같아 사용법 정리 포스팅을 진행한다. Ubuntu 환경에서 설치, 운영, 활용 실습을 진행하려 했으나, 시간도 넉넉하지 않고 Airflow 자체를 설치하거나 운영하기보다는 활용하는 법을 손에 익히는 일이 중요할 것 같아 Docker airflow라는 Github에 올라와 있는 Docker compose 파일을 사용하여 실습을 진행한다. Airflow 실행 미리 준비해야할 사항 Docker Image로 만들어진 Airflow를 사용할 것이기 때문에 실행 환경에 Docker Engine과 Docker Compose가 미리 설치되어 있어야 한다. 실행 환경 Macbook Pro Early 2015, Mojave 10.14.6 Docker Desktop 2.1.0.5 Docker Engine 19.03.5 Docker Compose 1.24.1 Docker Compose로 Airflow 실행하기 Docker Hub에 올라와 있는 Dockerhub - puckel/docker-airflow 이미지를 Pull 한다. 1 &gt; docker pull puckel/docker-airflow Airflow 뿐만 아니라 Metadata Database로 사용되는 Postgresql과 CeleryExecutor를 사용하기 위한 Redis를 함께 실행하기 위해 Docker Compose로 실행해야 한다. 이 또한 [Github - puckel/docker-airflow]에 미리 정의된 Docker Compose 파일이 있기 때문에 아래와 같이 실행한다. 1 &gt; git clone https://github.com/puckel/docker-airflow.git Pull이 완료된 이후 docker-airflow 디렉토리로 접근해보면 아래와 같은 파일들이 존재하는 것을 확인할 수 있다. 1 2 3 Dockerfile config docker-compose-LocalExecutor.yml LICENSE dags script README.md docker-compose-CeleryExecutor.yml 우리가 사용할 Docker Compose 파일은 docker-compose-CeleryExecutor.yml이다. 해당 파일을 열어보면 실행할 Docker Container들과 사용할 포트, Volumn 경로 등이 지정되어 있는데, 필요하다면 수정하면 된다.(나는 8080포트가 이미 다른 프로세스에서 사용 중이라 Airflow Webserver의 Port mapping을 8080:8080에서 8081:8080으로 변경했다) 아래 명령어를 수행하여 Airflow Docker Image를 실행한다. 1 &gt; docker-compose -f docker-compose-CeleryExecutor.yml up -d 정상적으로 실행된다면 아래와 같은 로그를 남기며 명령어가 종료될 것이다. 1 2 3 4 5 6 7 Removing docker-airflow_webserver_1 docker-airflow_redis_1 is up-to-date docker-airflow_postgres_1 is up-to-date docker-airflow_flower_1 is up-to-date Starting 184bc6a95ed6_docker-airflow_webserver_1 ... done Starting docker-airflow_scheduler_1 ... done Starting docker-airflow_worker_1 ... done Airflow Webserver가 잘 떳는지 http://localhost:8080 주소로 들어가 확인해본다. Airflow Tutorial 진행 Airflow Tutorial 페이지를 참고하여 Tutorial을 진행한다. simple_bash.py DAG 파일 생성 simple_bash라는 이름의 DAG를 생성할 것이다. Docker Compose를 실행한 경로(다른 경로로 이동하지 않았다면 docker-airflow)에 dag라는 디렉토리가 있을 것이다. 이 디렉토리에 simple_bash.py 파일을 생성하고, 작성을 시작한다. import 구문 1 2 3 from datetime import datetime, timedelta from airflow import DAG from airflow.operators.bash_operator import BashOperator from airflow import DAG: 정의할 DAG에 매핑하는 클래스를 임포트한다. from airflow.operators.bash_operator import BashOperator: Bash 명령어를 실행할 Task Operator 클래스를 임포트한다. Default Arguments 객체 생성 DAG 및 DAG 내 Task들에 일괄적으로 적용할 속성 객체를 작성한다. 1 2 3 4 5 6 7 8 9 10 default_args={ &#39;owner&#39;: &#39;airflow&#39;, &#39;depends_on_past&#39;: False, &#39;start_date&#39;: datetime(2020, 5, 16, 14, 0), &#39;email&#39;: [&#39;leeyh0216@gmail.com&#39;], &#39;email_on_failure&#39;: False, &#39;email_on_retry&#39;: False, &#39;retries&#39;: 1, &#39;retry_delay&#39;: timedelta(minutes=1), } owner: 작업 소유자 ID depends_on_past: 특정 작업의 Upstream이 성공한 경우에만 해당 작업을 Trigger할 것인지에 대한 여부 start_date: DAG 최초 실행 시간(과거 혹은 예약 가능) email: 작업 실행 관련 이메일 수신 주소 목록 email_on_failure: 작업 실패 시 이메일 수신 여부 email_on_retry: 작업 재시도 시 이메일 수신 여부 retries: 작업 재시도 횟수 retry_delay: 작업 재시도 간격 DAG 정의 DAG 객체를 정의한다. 1 2 3 4 5 6 dag = DAG( &#39;tutorial_bash&#39;, default_args=default_args, description=&#39;My first tutorial bash DAG&#39;, schedule_interval= &#39;* * * * *&#39; ) schedule_interval: DAG 스케쥴링 간격(Cron 표현식 혹은 미리 정의된 속성 사용 가능) Task 정의 “hello world”를 출력하는 작업(say_hello)과 현재 시간을 출력하는 작업(what_time)을 정의할 것이다. 1 2 3 4 5 6 7 8 9 10 11 12 13 t1 = BashOperator( task_id=&#39;say_hello&#39;, bash_command=&#39;echo &quot;hello world&quot;&#39;, dag=dag ) t2 = BashOperator( task_id=&#39;what_time&#39;, bash_command=&#39;date&#39;, dag=dag ) t1 &gt;&gt; t2 BashOperator에는 다음과 같은 속성이 존재한다. task_id: 작업의 ID bash_command: 실행할 Bash Command dag: 작업이 속할 DAG 또한 t1 &gt;&gt; t2는 t1이 실행된 후 t2를 실행한다는 의미이다.(t1이 t2의 Upstream Task) Airflow CLI와 Webserver를 통해 생성된 DAG 확인하기 Airflow CLI로 방금 만든 DAG가 잘 반영되었는지 확인해보자. 원래는 airflow list_dags 명령어로 Airflow에 등록된 DAG 목록을 출력할 수 있는데, 여기서는 Docker Compose로 띄워 놓았기 때문에 airflow list_dags 명령어 앞에 docker-compose -f docker-compose-CeleryExecutor.yml run --rm webserver를 붙여주어야 한다. 1 2 3 4 5 6 7 &gt; docker-compose -f docker-compose-CeleryExecutor.yml run --rm webserver airflow list_dags ------------------------------------------------------------------- DAGS ------------------------------------------------------------------- tutorial tutorial_bash WebServer에서도 일정 시간이 지나면 아래와 같이 tutorial_bash가 만들어진 것을 확인할 수 있다. DAG를 활성화하여 실행 확인하기 만들어진 DAG는 활성화된 상태가 아니어서(Paused) 실행되지 않는다. 실행을 위해서는 CLI나 Web UI 상에서 ‘Off’ 버튼을 눌러 ‘On’ 상태로 변경해주어야 한다. CLI Command는 airflow unpause [DAG ID]로써 여기서는 Docker compose 명령어와 함께 아래와 같이 실행하면 된다. 1 2 3 4 &gt; docker-compose -f docker-compose-CeleryExecutor.yml run --rm webserver airflow unpause tutorial_bash [2020-05-16 06:04:41,772] INFO - Filling up the DagBag from /usr/local/airflow/dags/tutorial_bash.py Dag: tutorial_bash, paused: False Web UI에서 확인하면 ‘Off’였던 상태가 ‘On’으로 변경되고, DAG가 실행되고 있는 것을 볼 수 있다. 정리 UI와 개념에 익숙해지지 않아 오래 걸렸는데, 며칠 만져보면 운영에 큰 지장이 없을 정도로 사용 가능할 것 같다. 다만 실제 운영 환경에서 Airflow를 구축할 때 dags 디렉토리의 동기화나 프로젝트 배포 등을 어떻게 할지가 참 궁금하다." /><link rel="canonical" href="https://leeyh0216.github.io/posts/airflow_install_and_tutorial/" /><meta property="og:url" content="https://leeyh0216.github.io/posts/airflow_install_and_tutorial/" /><meta property="og:site_name" content="leeyh0216’s devlog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-05-16T14:30:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Airflow 튜토리얼 실행해보기" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@leeyh0216" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"author":{"@type":"Person","name":"leeyh0216"},"description":"Airflow 튜토리얼 실행해보기 Airflow 기본 개념 - DAG와 Operator 개요 Airflow를 사용할 일이 많아질 것 같아 사용법 정리 포스팅을 진행한다. Ubuntu 환경에서 설치, 운영, 활용 실습을 진행하려 했으나, 시간도 넉넉하지 않고 Airflow 자체를 설치하거나 운영하기보다는 활용하는 법을 손에 익히는 일이 중요할 것 같아 Docker airflow라는 Github에 올라와 있는 Docker compose 파일을 사용하여 실습을 진행한다. Airflow 실행 미리 준비해야할 사항 Docker Image로 만들어진 Airflow를 사용할 것이기 때문에 실행 환경에 Docker Engine과 Docker Compose가 미리 설치되어 있어야 한다. 실행 환경 Macbook Pro Early 2015, Mojave 10.14.6 Docker Desktop 2.1.0.5 Docker Engine 19.03.5 Docker Compose 1.24.1 Docker Compose로 Airflow 실행하기 Docker Hub에 올라와 있는 Dockerhub - puckel/docker-airflow 이미지를 Pull 한다. 1 &gt; docker pull puckel/docker-airflow Airflow 뿐만 아니라 Metadata Database로 사용되는 Postgresql과 CeleryExecutor를 사용하기 위한 Redis를 함께 실행하기 위해 Docker Compose로 실행해야 한다. 이 또한 [Github - puckel/docker-airflow]에 미리 정의된 Docker Compose 파일이 있기 때문에 아래와 같이 실행한다. 1 &gt; git clone https://github.com/puckel/docker-airflow.git Pull이 완료된 이후 docker-airflow 디렉토리로 접근해보면 아래와 같은 파일들이 존재하는 것을 확인할 수 있다. 1 2 3 Dockerfile config docker-compose-LocalExecutor.yml LICENSE dags script README.md docker-compose-CeleryExecutor.yml 우리가 사용할 Docker Compose 파일은 docker-compose-CeleryExecutor.yml이다. 해당 파일을 열어보면 실행할 Docker Container들과 사용할 포트, Volumn 경로 등이 지정되어 있는데, 필요하다면 수정하면 된다.(나는 8080포트가 이미 다른 프로세스에서 사용 중이라 Airflow Webserver의 Port mapping을 8080:8080에서 8081:8080으로 변경했다) 아래 명령어를 수행하여 Airflow Docker Image를 실행한다. 1 &gt; docker-compose -f docker-compose-CeleryExecutor.yml up -d 정상적으로 실행된다면 아래와 같은 로그를 남기며 명령어가 종료될 것이다. 1 2 3 4 5 6 7 Removing docker-airflow_webserver_1 docker-airflow_redis_1 is up-to-date docker-airflow_postgres_1 is up-to-date docker-airflow_flower_1 is up-to-date Starting 184bc6a95ed6_docker-airflow_webserver_1 ... done Starting docker-airflow_scheduler_1 ... done Starting docker-airflow_worker_1 ... done Airflow Webserver가 잘 떳는지 http://localhost:8080 주소로 들어가 확인해본다. Airflow Tutorial 진행 Airflow Tutorial 페이지를 참고하여 Tutorial을 진행한다. simple_bash.py DAG 파일 생성 simple_bash라는 이름의 DAG를 생성할 것이다. Docker Compose를 실행한 경로(다른 경로로 이동하지 않았다면 docker-airflow)에 dag라는 디렉토리가 있을 것이다. 이 디렉토리에 simple_bash.py 파일을 생성하고, 작성을 시작한다. import 구문 1 2 3 from datetime import datetime, timedelta from airflow import DAG from airflow.operators.bash_operator import BashOperator from airflow import DAG: 정의할 DAG에 매핑하는 클래스를 임포트한다. from airflow.operators.bash_operator import BashOperator: Bash 명령어를 실행할 Task Operator 클래스를 임포트한다. Default Arguments 객체 생성 DAG 및 DAG 내 Task들에 일괄적으로 적용할 속성 객체를 작성한다. 1 2 3 4 5 6 7 8 9 10 default_args={ &#39;owner&#39;: &#39;airflow&#39;, &#39;depends_on_past&#39;: False, &#39;start_date&#39;: datetime(2020, 5, 16, 14, 0), &#39;email&#39;: [&#39;leeyh0216@gmail.com&#39;], &#39;email_on_failure&#39;: False, &#39;email_on_retry&#39;: False, &#39;retries&#39;: 1, &#39;retry_delay&#39;: timedelta(minutes=1), } owner: 작업 소유자 ID depends_on_past: 특정 작업의 Upstream이 성공한 경우에만 해당 작업을 Trigger할 것인지에 대한 여부 start_date: DAG 최초 실행 시간(과거 혹은 예약 가능) email: 작업 실행 관련 이메일 수신 주소 목록 email_on_failure: 작업 실패 시 이메일 수신 여부 email_on_retry: 작업 재시도 시 이메일 수신 여부 retries: 작업 재시도 횟수 retry_delay: 작업 재시도 간격 DAG 정의 DAG 객체를 정의한다. 1 2 3 4 5 6 dag = DAG( &#39;tutorial_bash&#39;, default_args=default_args, description=&#39;My first tutorial bash DAG&#39;, schedule_interval= &#39;* * * * *&#39; ) schedule_interval: DAG 스케쥴링 간격(Cron 표현식 혹은 미리 정의된 속성 사용 가능) Task 정의 “hello world”를 출력하는 작업(say_hello)과 현재 시간을 출력하는 작업(what_time)을 정의할 것이다. 1 2 3 4 5 6 7 8 9 10 11 12 13 t1 = BashOperator( task_id=&#39;say_hello&#39;, bash_command=&#39;echo &quot;hello world&quot;&#39;, dag=dag ) t2 = BashOperator( task_id=&#39;what_time&#39;, bash_command=&#39;date&#39;, dag=dag ) t1 &gt;&gt; t2 BashOperator에는 다음과 같은 속성이 존재한다. task_id: 작업의 ID bash_command: 실행할 Bash Command dag: 작업이 속할 DAG 또한 t1 &gt;&gt; t2는 t1이 실행된 후 t2를 실행한다는 의미이다.(t1이 t2의 Upstream Task) Airflow CLI와 Webserver를 통해 생성된 DAG 확인하기 Airflow CLI로 방금 만든 DAG가 잘 반영되었는지 확인해보자. 원래는 airflow list_dags 명령어로 Airflow에 등록된 DAG 목록을 출력할 수 있는데, 여기서는 Docker Compose로 띄워 놓았기 때문에 airflow list_dags 명령어 앞에 docker-compose -f docker-compose-CeleryExecutor.yml run --rm webserver를 붙여주어야 한다. 1 2 3 4 5 6 7 &gt; docker-compose -f docker-compose-CeleryExecutor.yml run --rm webserver airflow list_dags ------------------------------------------------------------------- DAGS ------------------------------------------------------------------- tutorial tutorial_bash WebServer에서도 일정 시간이 지나면 아래와 같이 tutorial_bash가 만들어진 것을 확인할 수 있다. DAG를 활성화하여 실행 확인하기 만들어진 DAG는 활성화된 상태가 아니어서(Paused) 실행되지 않는다. 실행을 위해서는 CLI나 Web UI 상에서 ‘Off’ 버튼을 눌러 ‘On’ 상태로 변경해주어야 한다. CLI Command는 airflow unpause [DAG ID]로써 여기서는 Docker compose 명령어와 함께 아래와 같이 실행하면 된다. 1 2 3 4 &gt; docker-compose -f docker-compose-CeleryExecutor.yml run --rm webserver airflow unpause tutorial_bash [2020-05-16 06:04:41,772] INFO - Filling up the DagBag from /usr/local/airflow/dags/tutorial_bash.py Dag: tutorial_bash, paused: False Web UI에서 확인하면 ‘Off’였던 상태가 ‘On’으로 변경되고, DAG가 실행되고 있는 것을 볼 수 있다. 정리 UI와 개념에 익숙해지지 않아 오래 걸렸는데, 며칠 만져보면 운영에 큰 지장이 없을 정도로 사용 가능할 것 같다. 다만 실제 운영 환경에서 Airflow를 구축할 때 dags 디렉토리의 동기화나 프로젝트 배포 등을 어떻게 할지가 참 궁금하다.","url":"https://leeyh0216.github.io/posts/airflow_install_and_tutorial/","@type":"BlogPosting","headline":"Airflow 튜토리얼 실행해보기","dateModified":"2020-05-16T14:30:00+09:00","datePublished":"2020-05-16T14:30:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://leeyh0216.github.io/posts/airflow_install_and_tutorial/"},"@context":"https://schema.org"}</script><title>Airflow 튜토리얼 실행해보기 | leeyh0216's devlog</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script async src="https://cdn.jsdelivr.net/npm/countup.js@1.9.3/dist/countUp.min.js"></script> <script async src="/assets/js/dist/pvreport.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=UA-129061352-1"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-129061352-1'); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://cdn.jsdelivr.net/gh/cotes2020/chirpy-images/commons/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">leeyh0216's devlog</a></div><div class="site-subtitle font-italic">개발/일상 블로그</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/leeyh0216" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://www.linkedin.com/in/%EC%9A%A9%ED%99%98-%EC%9D%B4-84222a119/" aria-label="linkedin" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['leeyh0216','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Airflow 튜토리얼 실행해보기</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Airflow 튜토리얼 실행해보기</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> leeyh0216 </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Sat, May 16, 2020, 2:30 PM +0900" prep="on" > May 16, 2020 <i class="unloaded">2020-05-16T14:30:00+09:00</i> </span></div><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1540 words">8 min</span> <span id="pv" class="pageviews"><i class="fas fa-spinner fa-spin fa-fw"></i></span></div></div><div class="post-content"><ul><li><strong>Airflow 튜토리얼 실행해보기</strong><li><a href="https://leeyh0216.github.io/2020-05-16/airflow_concept_dag_operator">Airflow 기본 개념 - DAG와 Operator</a></ul><h1 id="개요">개요</h1><p>Airflow를 사용할 일이 많아질 것 같아 사용법 정리 포스팅을 진행한다.</p><p>Ubuntu 환경에서 설치, 운영, 활용 실습을 진행하려 했으나, 시간도 넉넉하지 않고 Airflow 자체를 설치하거나 운영하기보다는 활용하는 법을 손에 익히는 일이 중요할 것 같아 <a href="https://github.com/puckel/docker-airflow">Docker airflow</a>라는 Github에 올라와 있는 Docker compose 파일을 사용하여 실습을 진행한다.</p><h1 id="airflow-실행">Airflow 실행</h1><h2 id="미리-준비해야할-사항">미리 준비해야할 사항</h2><p>Docker Image로 만들어진 Airflow를 사용할 것이기 때문에 실행 환경에 Docker Engine과 Docker Compose가 미리 설치되어 있어야 한다.</p><h2 id="실행-환경">실행 환경</h2><ul><li>Macbook Pro Early 2015, Mojave 10.14.6<li>Docker Desktop 2.1.0.5<ul><li>Docker Engine 19.03.5<li>Docker Compose 1.24.1</ul></ul><h2 id="docker-compose로-airflow-실행하기">Docker Compose로 Airflow 실행하기</h2><p>Docker Hub에 올라와 있는 <a href="https://hub.docker.com/r/puckel/docker-airflow">Dockerhub - puckel/docker-airflow</a> 이미지를 Pull 한다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>&gt; docker pull puckel/docker-airflow
</pre></table></code></div></div><p>Airflow 뿐만 아니라 Metadata Database로 사용되는 Postgresql과 CeleryExecutor를 사용하기 위한 Redis를 함께 실행하기 위해 Docker Compose로 실행해야 한다. 이 또한 [Github - puckel/docker-airflow]에 미리 정의된 Docker Compose 파일이 있기 때문에 아래와 같이 실행한다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>&gt; git clone https://github.com/puckel/docker-airflow.git
</pre></table></code></div></div><p>Pull이 완료된 이후 docker-airflow 디렉토리로 접근해보면 아래와 같은 파일들이 존재하는 것을 확인할 수 있다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>Dockerfile                        config                            docker-compose-LocalExecutor.yml
LICENSE                           dags                              script
README.md                         docker-compose-CeleryExecutor.yml
</pre></table></code></div></div><p>우리가 사용할 Docker Compose 파일은 <code class="language-plaintext highlighter-rouge">docker-compose-CeleryExecutor.yml</code>이다. 해당 파일을 열어보면 실행할 Docker Container들과 사용할 포트, Volumn 경로 등이 지정되어 있는데, 필요하다면 수정하면 된다.(나는 8080포트가 이미 다른 프로세스에서 사용 중이라 Airflow Webserver의 Port mapping을 8080:8080에서 8081:8080으로 변경했다)</p><p>아래 명령어를 수행하여 Airflow Docker Image를 실행한다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>&gt; docker-compose -f docker-compose-CeleryExecutor.yml up -d
</pre></table></code></div></div><p>정상적으로 실행된다면 아래와 같은 로그를 남기며 명령어가 종료될 것이다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre>Removing docker-airflow_webserver_1
docker-airflow_redis_1 is up-to-date
docker-airflow_postgres_1 is up-to-date
docker-airflow_flower_1 is up-to-date
Starting 184bc6a95ed6_docker-airflow_webserver_1 ... done
Starting docker-airflow_scheduler_1              ... done
Starting docker-airflow_worker_1                 ... done
</pre></table></code></div></div><p>Airflow Webserver가 잘 떳는지 <code class="language-plaintext highlighter-rouge">http://localhost:8080</code> 주소로 들어가 확인해본다.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="../../assets/airflow/20200516/airflow_webserver_main.png" alt="Airflow webserver main page" /></p><h1 id="airflow-tutorial-진행">Airflow Tutorial 진행</h1><blockquote><p><a href="https://airflow.apache.org/docs/stable/tutorial.html">Airflow Tutorial</a> 페이지를 참고하여 Tutorial을 진행한다.</p></blockquote><h2 id="simple_bashpy-dag-파일-생성"><code class="language-plaintext highlighter-rouge">simple_bash.py</code> DAG 파일 생성</h2><p><code class="language-plaintext highlighter-rouge">simple_bash</code>라는 이름의 DAG를 생성할 것이다. Docker Compose를 실행한 경로(다른 경로로 이동하지 않았다면 docker-airflow)에 <code class="language-plaintext highlighter-rouge">dag</code>라는 디렉토리가 있을 것이다. 이 디렉토리에 <code class="language-plaintext highlighter-rouge">simple_bash.py</code> 파일을 생성하고, 작성을 시작한다.</p><h3 id="import-구문">import 구문</h3><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.bash_operator import BashOperator
</pre></table></code></div></div><ul><li><code class="language-plaintext highlighter-rouge">from airflow import DAG</code>: 정의할 DAG에 매핑하는 클래스를 임포트한다.<li><code class="language-plaintext highlighter-rouge">from airflow.operators.bash_operator import BashOperator</code>: Bash 명령어를 실행할 Task Operator 클래스를 임포트한다.</ul><h3 id="default-arguments-객체-생성">Default Arguments 객체 생성</h3><p>DAG 및 DAG 내 Task들에 일괄적으로 적용할 속성 객체를 작성한다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre>default_args={
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2020, 5, 16, 14, 0),
    'email': ['leeyh0216@gmail.com'],
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=1),
}
</pre></table></code></div></div><ul><li><code class="language-plaintext highlighter-rouge">owner</code>: 작업 소유자 ID<li><code class="language-plaintext highlighter-rouge">depends_on_past</code>: 특정 작업의 Upstream이 성공한 경우에만 해당 작업을 Trigger할 것인지에 대한 여부<li><code class="language-plaintext highlighter-rouge">start_date</code>: DAG 최초 실행 시간(과거 혹은 예약 가능)<li><code class="language-plaintext highlighter-rouge">email</code>: 작업 실행 관련 이메일 수신 주소 목록<li><code class="language-plaintext highlighter-rouge">email_on_failure</code>: 작업 실패 시 이메일 수신 여부<li><code class="language-plaintext highlighter-rouge">email_on_retry</code>: 작업 재시도 시 이메일 수신 여부<li><code class="language-plaintext highlighter-rouge">retries</code>: 작업 재시도 횟수<li><code class="language-plaintext highlighter-rouge">retry_delay</code>: 작업 재시도 간격</ul><h3 id="dag-정의">DAG 정의</h3><p>DAG 객체를 정의한다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre>dag = DAG(
    'tutorial_bash',
    default_args=default_args,
    description='My first tutorial bash DAG',
    schedule_interval= '* * * * *'
)
</pre></table></code></div></div><ul><li><code class="language-plaintext highlighter-rouge">schedule_interval</code>: DAG 스케쥴링 간격(Cron 표현식 혹은 미리 정의된 속성 사용 가능)</ul><h3 id="task-정의">Task 정의</h3><p>“hello world”를 출력하는 작업(say_hello)과 현재 시간을 출력하는 작업(what_time)을 정의할 것이다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre>t1 = BashOperator(
    task_id='say_hello',
    bash_command='echo "hello world"',
    dag=dag
)

t2 = BashOperator(
    task_id='what_time',
    bash_command='date',
    dag=dag
)

t1 &gt;&gt; t2
</pre></table></code></div></div><p><code class="language-plaintext highlighter-rouge">BashOperator</code>에는 다음과 같은 속성이 존재한다.</p><ul><li><code class="language-plaintext highlighter-rouge">task_id</code>: 작업의 ID<li><code class="language-plaintext highlighter-rouge">bash_command</code>: 실행할 Bash Command<li><code class="language-plaintext highlighter-rouge">dag</code>: 작업이 속할 DAG</ul><p>또한 <code class="language-plaintext highlighter-rouge">t1 &gt;&gt; t2</code>는 t1이 실행된 후 t2를 실행한다는 의미이다.(t1이 t2의 Upstream Task)</p><h2 id="airflow-cli와-webserver를-통해-생성된-dag-확인하기">Airflow CLI와 Webserver를 통해 생성된 DAG 확인하기</h2><p>Airflow CLI로 방금 만든 DAG가 잘 반영되었는지 확인해보자. 원래는 <code class="language-plaintext highlighter-rouge">airflow list_dags</code> 명령어로 Airflow에 등록된 DAG 목록을 출력할 수 있는데, 여기서는 Docker Compose로 띄워 놓았기 때문에 <code class="language-plaintext highlighter-rouge">airflow list_dags</code> 명령어 앞에 <code class="language-plaintext highlighter-rouge">docker-compose -f docker-compose-CeleryExecutor.yml run --rm webserver</code>를 붙여주어야 한다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre>&gt; docker-compose -f docker-compose-CeleryExecutor.yml run --rm webserver airflow list_dags

-------------------------------------------------------------------
DAGS
-------------------------------------------------------------------
tutorial
tutorial_bash
</pre></table></code></div></div><p>WebServer에서도 일정 시간이 지나면 아래와 같이 tutorial_bash가 만들어진 것을 확인할 수 있다.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="../../assets/airflow/20200516/airflow_webserver_dag_list.png" alt="airflow_webserver_daglist" /></p><h2 id="dag를-활성화하여-실행-확인하기">DAG를 활성화하여 실행 확인하기</h2><p>만들어진 DAG는 활성화된 상태가 아니어서(Paused) 실행되지 않는다. 실행을 위해서는 CLI나 Web UI 상에서 ‘Off’ 버튼을 눌러 ‘On’ 상태로 변경해주어야 한다.</p><p>CLI Command는 <code class="language-plaintext highlighter-rouge">airflow unpause [DAG ID]</code>로써 여기서는 Docker compose 명령어와 함께 아래와 같이 실행하면 된다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>&gt; docker-compose -f docker-compose-CeleryExecutor.yml run --rm webserver airflow unpause tutorial_bash

[2020-05-16 06:04:41,772]  INFO - Filling up the DagBag from /usr/local/airflow/dags/tutorial_bash.py
Dag: tutorial_bash, paused: False
</pre></table></code></div></div><p>Web UI에서 확인하면 ‘Off’였던 상태가 ‘On’으로 변경되고, DAG가 실행되고 있는 것을 볼 수 있다.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="../../assets/airflow/20200516/airflow_webserver_dag_running.png" alt="airflow_webserver_dag_running" /></p><h1 id="정리">정리</h1><p>UI와 개념에 익숙해지지 않아 오래 걸렸는데, 며칠 만져보면 운영에 큰 지장이 없을 정도로 사용 가능할 것 같다.</p><p>다만 실제 운영 환경에서 Airflow를 구축할 때 <code class="language-plaintext highlighter-rouge">dags</code> 디렉토리의 동기화나 프로젝트 배포 등을 어떻게 할지가 참 궁금하다.</p></div><div class="post-tail-wrapper text-muted"><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/docker/" class="post-tag no-text-decoration" >docker</a> <a href="/tags/airflow/" class="post-tag no-text-decoration" >airflow</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Airflow 튜토리얼 실행해보기 - leeyh0216's devlog&url=https://leeyh0216.github.io/posts/airflow_install_and_tutorial/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Airflow 튜토리얼 실행해보기 - leeyh0216's devlog&u=https://leeyh0216.github.io/posts/airflow_install_and_tutorial/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Airflow 튜토리얼 실행해보기 - leeyh0216's devlog&url=https://leeyh0216.github.io/posts/airflow_install_and_tutorial/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/ps/">ps</a> <a class="post-tag" href="/tags/spring/">spring</a> <a class="post-tag" href="/tags/leetcode/">leetcode</a> <a class="post-tag" href="/tags/apache-spark/">apache-spark</a> <a class="post-tag" href="/tags/java/">java</a> <a class="post-tag" href="/tags/kafka/">kafka</a> <a class="post-tag" href="/tags/apache-druid/">apache-druid</a> <a class="post-tag" href="/tags/string/">string</a> <a class="post-tag" href="/tags/study/">study</a> <a class="post-tag" href="/tags/docker/">docker</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/spring-with-docker-1/"><div class="card-body"> <span class="timeago small" > May 6, 2019 <i class="unloaded">2019-05-06T10:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Spring + MongoDB + Docker 조합 사용 테스트</h3><div class="text-muted small"><p> 프로젝트 초기화 git 초기화 Git 페이지에서 spring_mongodb_docker Repository를 초기화한다. git pull https://github.com/leeyh0216/spring_mongodb_docker.git 명령어를 통해 로컬로 Clone 한다. gitignore.io ...</p></div></div></a></div><div class="card"> <a href="/posts/airflow_concept_dag_operator/"><div class="card-body"> <span class="timeago small" > May 16, 2020 <i class="unloaded">2020-05-16T23:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Airflow 기본 개념 - DAG와 Operator</h3><div class="text-muted small"><p> Airflow 튜토리얼 실행해보기 Airflow 기본 개념 - DAG와 Operator 개요 Airflow에서 사용되는 개념들을 살펴본다. Airflow concepts 페이지를 참고하여 작성하였다. 개념 DAG DAG(Directed Acyclic Graph)는 관계와 의존성을 가진 작업들의 집합이다. DAG는 파이썬 파일로 정의...</p></div></div></a></div><div class="card"> <a href="/posts/kafka_docker/"><div class="card-body"> <span class="timeago small" > May 17, 2020 <i class="unloaded">2020-05-17T22:10:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Docker(compose)로 Kafka Cluster 실행하기</h3><div class="text-muted small"><p> 개요 Kafka 공부 중 Replication 등을 테스트하기 위해 Kafka를 3대로 구성하여 Kafka Cluster를 띄워야 했다. 로컬 환경에 포트와 데이터 경로만 바꿔 실행할 수도 있었지만, 실행/종료가 귀찮을 것이 분명했기 때문에 Kafka를 Docker Image로 만든 뒤 Docker Compose를 통해 띄울 수 있도록 만들어 보았다...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/java_nio_why_java_io_slow/" class="btn btn-outline-primary" prompt="Older"><p>Java NIO - 1. 왜 자바의 IO 패키지는 느린가?</p></a> <a href="/posts/airflow_concept_dag_operator/" class="btn btn-outline-primary" prompt="Newer"><p>Airflow 기본 개념 - DAG와 Operator</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('.post-content img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2024 <a href="https://twitter.com/username">leeyh0216</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/ps/">ps</a> <a class="post-tag" href="/tags/spring/">spring</a> <a class="post-tag" href="/tags/leetcode/">leetcode</a> <a class="post-tag" href="/tags/apache-spark/">apache spark</a> <a class="post-tag" href="/tags/java/">java</a> <a class="post-tag" href="/tags/kafka/">kafka</a> <a class="post-tag" href="/tags/apache-druid/">apache druid</a> <a class="post-tag" href="/tags/string/">string</a> <a class="post-tag" href="/tags/study/">study</a> <a class="post-tag" href="/tags/docker/">docker</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://leeyh0216.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
