<!DOCTYPE html><html lang="ko-KR" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8829030678254956" crossorigin="anonymous"></script><meta name="pv-proxy-endpoint" content=""><meta name="generator" content="Jekyll v4.2.0" /><meta property="og:title" content="Spark Structured Streaming의 MicroBatch 동작 원리 알아보기" /><meta name="author" content="leeyh0216" /><meta property="og:locale" content="ko_KR" /><meta name="description" content="이 글의 내용은 MicroBatchExecution - Stream Execution Engine of Micro-Batch Stream Processing을 참고하여 작성하였습니다." /><meta property="og:description" content="이 글의 내용은 MicroBatchExecution - Stream Execution Engine of Micro-Batch Stream Processing을 참고하여 작성하였습니다." /><link rel="canonical" href="https://leeyh0216.github.io/posts/spark-structured-streaming-microbatch/" /><meta property="og:url" content="https://leeyh0216.github.io/posts/spark-structured-streaming-microbatch/" /><meta property="og:site_name" content="leeyh0216’s devlog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-09-02T23:55:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Spark Structured Streaming의 MicroBatch 동작 원리 알아보기" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@leeyh0216" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"author":{"@type":"Person","name":"leeyh0216"},"description":"이 글의 내용은 MicroBatchExecution - Stream Execution Engine of Micro-Batch Stream Processing을 참고하여 작성하였습니다.","url":"https://leeyh0216.github.io/posts/spark-structured-streaming-microbatch/","@type":"BlogPosting","headline":"Spark Structured Streaming의 MicroBatch 동작 원리 알아보기","dateModified":"2022-09-02T23:55:00+09:00","datePublished":"2022-09-02T23:55:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://leeyh0216.github.io/posts/spark-structured-streaming-microbatch/"},"@context":"https://schema.org"}</script><title>Spark Structured Streaming의 MicroBatch 동작 원리 알아보기 | leeyh0216's devlog</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script async src="https://cdn.jsdelivr.net/npm/countup.js@1.9.3/dist/countUp.min.js"></script> <script async src="/assets/js/dist/pvreport.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=UA-129061352-1"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-129061352-1'); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://cdn.jsdelivr.net/gh/cotes2020/chirpy-images/commons/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">leeyh0216's devlog</a></div><div class="site-subtitle font-italic">개발/일상 블로그</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/leeyh0216" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://www.linkedin.com/in/%EC%9A%A9%ED%99%98-%EC%9D%B4-84222a119/" aria-label="linkedin" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['leeyh0216','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Spark Structured Streaming의 MicroBatch 동작 원리 알아보기</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Spark Structured Streaming의 MicroBatch 동작 원리 알아보기</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> leeyh0216 </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Fri, Sep 2, 2022, 11:55 PM +0900" prep="on" > Sep 2, 2022 <i class="unloaded">2022-09-02T23:55:00+09:00</i> </span></div><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3898 words">21 min</span> <span id="pv" class="pageviews"><i class="fas fa-spinner fa-spin fa-fw"></i></span></div></div><div class="post-content"><blockquote><p>이 글의 내용은 <a href="https://jaceklaskowski.gitbooks.io/spark-structured-streaming/content/spark-sql-streaming-MicroBatchExecution.html">MicroBatchExecution - Stream Execution Engine of Micro-Batch Stream Processing</a>을 참고하여 작성하였습니다.</p></blockquote><h1 id="spark-structured-streaming의-microbatch-동작-원리-알아보기">Spark Structured Streaming의 MicroBatch 동작 원리 알아보기</h1><p>MicroBatch 기반의 Spark Structured Streaming이 어떻게 동작하는지 알아본다.</p><h2 id="microbatch-stream-processing">MicroBatch Stream Processing</h2><p><a href="https://en.wikipedia.org/wiki/Streaming_data">Wikipedia - Streaming Data</a>에서 정의한 스트리밍 데이터는 “서로 다른 소스에서 발생하는 한정되지 않고(Unbounded), 연속적인(Continuous) 데이터”이다.</p><p>이러한 스트리밍 데이터를 처리하는 방식은 크게 Native 방식과 Micro Batch 방식으로 나뉜다.</p><ul><li>Native: 유입되는 레코드를 도착하는 시점에 하나씩 처리한다.<li>Micro Batch: 유입되는 레코드를 특정 주기로 모아서 한번에 처리한다.</ul><p>Micro Batch 방식은 레코드를 한번에 모아서 처리하기 때문에 상대적으로 Native에 비해 Latency가 크다는 단점을 가진다.</p><p>데이터 처리 프레임워크 중 Apache Flink, Storm가 Native Processing 방식을 지원하고, Apache Spark의 경우 Native(Continuous Streaming), Micro Batch 방식 모두를 지원하고 있다.</p><blockquote><p>다만 Apache Spark의 Native 방식의 경우 Expermiental이며, Static Source와의 Join이 불가능하다는 제약사항 등이 존재한다.</p></blockquote><p>이 글에서는 간단히 아래와 같은 코드를 실행했다고 가정하고, 실행 순서를 확인해본다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>df.writeStream
  .format("console")
  .trigger(Trigger.ProcessingTime("2 seconds"))
  .start()
</pre></table></code></div></div><h2 id="spark-structured-streaming에서의-micro-batch의-구현">Spark Structured Streaming에서의 Micro Batch의 구현</h2><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre>abstract class StreamExecution(
    override val sparkSession: SparkSession,
    override val name: String,
    val resolvedCheckpointRoot: String,
    val analyzedPlan: LogicalPlan,
    val sink: Table,
    val trigger: Trigger,
    val triggerClock: Clock,
    val outputMode: OutputMode,
    deleteCheckpointOnStop: Boolean)
  extends StreamingQuery with ProgressReporter with Logging
</pre></table></code></div></div><p>Spark Structured Streaming은 Streaming Query의 실행을 <a href="https://github.com/apache/spark/blob/v3.2.2/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/StreamExecution.scala"><code class="language-plaintext highlighter-rouge">StreamExecution</code></a>이라는 클래스로 추상화했다. 생성자 시그니처에서 확인할 수 있듯 Streaming Query 실행에 필요한 기본적인 정보(Query Plan, Sink 대상 정보, Trigger 정보 등)를 포함하고 있다.</p><p><code class="language-plaintext highlighter-rouge">StreamExecution</code>은 <a href="https://github.com/apache/spark/blob/v3.2.2/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/continuous/ContinuousExecution.scala"><code class="language-plaintext highlighter-rouge">ContinuousExecution</code></a>과 <a href="https://github.com/apache/spark/blob/v3.2.2/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/MicroBatchExecution.scala"><code class="language-plaintext highlighter-rouge">MicroBatchExecution</code></a>이 구현하고 있으며, 상속 구조와 세부 내용은 아래와 같다.</p><ul><li><code class="language-plaintext highlighter-rouge">StreamExecution</code>: Streaming Query 실행 정보/로직을 추상화한 클래스<ul><li><code class="language-plaintext highlighter-rouge">MicroBatchExecution</code>: Micro Batch 방식의 Streaming Query 실행에 사용되는 클래스. <code class="language-plaintext highlighter-rouge">Trigger.processingTime</code>으로 쿼리의 Trigger를 초기화했을 때 선택된다.<li><code class="language-plaintext highlighter-rouge">ContinuousExecution</code>: Continuous 방식의 Streaming Query 실행에 사용되는 클래스. <code class="language-plaintext highlighter-rouge">Trigger.Continuous</code>으로 쿼리의 Trigger를 초기화했을 때 선택된다.</ul></ul><blockquote><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>df.writeStream
  .format("console")
  .trigger(Trigger.ProcessingTime("2 seconds")) //이 부분에서 StreamExecution의 종류가 결정
  .start()
</pre></table></code></div></div><p>위 코드의 주석에도 쓰여 있듯, <code class="language-plaintext highlighter-rouge">trigger</code> 메서드가 <code class="language-plaintext highlighter-rouge">StreamExecution</code>의 종류를 결정한다.</p></blockquote><p><code class="language-plaintext highlighter-rouge">StreamExecution</code>의 종류가 결정된 이후 <code class="language-plaintext highlighter-rouge">start</code> 메서드를 호출하면, 내부적으로 <code class="language-plaintext highlighter-rouge">StreamExecution</code>의 <code class="language-plaintext highlighter-rouge">runActivatedStream</code>이 호출되며 실질적인 처리가 시작된다.</p><h3 id="microbatch의-주기적-실행을-담당하는-triggerexecutor">MicroBatch의 주기적 실행을 담당하는 <code class="language-plaintext highlighter-rouge">TriggerExecutor</code></h3><p><code class="language-plaintext highlighter-rouge">runActivatedStream</code>의 내부를 알아보기 전 MicroBatch의 주기적인 실행을 담당하는 <code class="language-plaintext highlighter-rouge">TriggerExecutor</code>에 대해 알아보기로 한다.</p><p><code class="language-plaintext highlighter-rouge">MicroBatchExecution</code>에서는 생성자로 전달받은 <code class="language-plaintext highlighter-rouge">Trigger</code> 종류에 따라 쿼리를 주기적으로(혹은 한번만) 실행하는 <code class="language-plaintext highlighter-rouge">TriggerExecutor</code>를 초기화한다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>private val triggerExecutor = trigger match {
  case t: ProcessingTimeTrigger =&gt; ProcessingTimeExecutor(t, triggerClock)
  case OneTimeTrigger =&gt; OneTimeExecutor()
  case _ =&gt; throw new IllegalStateException(s"Unknown type of trigger: $trigger")
}
</pre></table></code></div></div><p><a href="https://github.com/apache/spark/blob/v3.2.2/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/TriggerExecutor.scala"><code class="language-plaintext highlighter-rouge">TriggerExecutor</code></a>는 매개변수로 전달받은 <code class="language-plaintext highlighter-rouge">Unit</code> =&gt; <code class="language-plaintext highlighter-rouge">Boolean</code> 타입의 함수를 주기적으로(혹은 한번만) 실행하는 <code class="language-plaintext highlighter-rouge">execute</code>라는 메서드를 선언하고 있으며, 이를 상속하는 <code class="language-plaintext highlighter-rouge">ProcessingTimeTrigger</code>와 <code class="language-plaintext highlighter-rouge">OneTimeTrigger</code>는 각각 이를 구현하고 있다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre>trait TriggerExecutor {
  /**
   * Execute batches using `batchRunner`. If `batchRunner` runs `false`, terminate the execution.
   */
  def execute(batchRunner: () =&gt; Boolean): Unit
}
</pre></table></code></div></div><p>전달받은 함수의 결과 타입은 <code class="language-plaintext highlighter-rouge">Boolean</code>이며, 주석에도 나와 있듯 이 값이 <code class="language-plaintext highlighter-rouge">false</code>로 전달되었을 때는 호출을 중지해야 한다.(사용자가 쿼리를 terminate 했거나, 마지막 Offset까지 가져온 경우에 <code class="language-plaintext highlighter-rouge">false</code>가 반환된다)</p><blockquote><p>“Streaming Query인데 마지막 Offset이 어디있어?” 라는 질문을 할 수도 있다.</p><p>그러나 <a href="https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html">Spark Structured Streaming + Kafka Integration</a> 문서의 <code class="language-plaintext highlighter-rouge">endingOffsets</code>를 보면 마지막 Offset을 지정할 수 있는 것을 확인할 수 있다.</p></blockquote><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>case class OneTimeExecutor() extends TriggerExecutor {
  override def execute(batchRunner: () =&gt; Boolean): Unit = batchRunner()
}
</pre></table></code></div></div><p><a href="https://github.com/apache/spark/blob/v3.2.2/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/TriggerExecutor.scala#L34"><code class="language-plaintext highlighter-rouge">OneTimeExecutor</code></a>는 말 그대로 “딱 한번만” 실행하는 방식으로써, 전달받은 함수를 한번 호출하고 종료한다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre>case class ProcessingTimeExecutor(
    processingTimeTrigger: ProcessingTimeTrigger,
    clock: Clock = new SystemClock())
  extends TriggerExecutor with Logging {

  private val intervalMs = processingTimeTrigger.intervalMs
  require(intervalMs &gt;= 0)

  override def execute(triggerHandler: () =&gt; Boolean): Unit = {
    while (true) {
      val triggerTimeMs = clock.getTimeMillis
      val nextTriggerTimeMs = nextBatchTime(triggerTimeMs)
      val terminated = !triggerHandler()
      ...
    }
  }
}
</pre></table></code></div></div><p><a href="https://github.com/apache/spark/blob/v3.2.2/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/TriggerExecutor.scala#L45"><code class="language-plaintext highlighter-rouge">ProcessingTimeExecutor</code></a>는 <code class="language-plaintext highlighter-rouge">Trigger</code> 설정을 통해 전달받은 주기 별로 함수를 실행한다. 내부적으로는 위와 같이 무한 루프를 돌며 전달받은 함수를 실행하는 것을 볼 수 있다.</p><h3 id="streaming-query-실행을-담당하는-runactivatedstream">Streaming Query 실행을 담당하는 <code class="language-plaintext highlighter-rouge">runActivatedStream</code></h3><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>df.writeStream
  .format("console")
  .trigger(Trigger.ProcessingTime("2 seconds"))
  .start() //이 부분
</pre></table></code></div></div><p>위 코드의 <code class="language-plaintext highlighter-rouge">start</code> 메서드를 호출하면 생성된 <code class="language-plaintext highlighter-rouge">MicroBatchExecution</code>의 <a href="https://github.com/apache/spark/blob/v3.2.2/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/MicroBatchExecution.scala#L182"><code class="language-plaintext highlighter-rouge">runActivatedStream</code></a> 메서드가 호출된다.</p><p>이 메서드에서는 실행 후 <code class="language-plaintext highlighter-rouge">triggerExecutor</code>의 <code class="language-plaintext highlighter-rouge">execute</code> 메서드에 Streaming Query 실행 로직을 전달하므로써 주기적으로 Micro Batch Query를 수행한다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre>protected def runActivatedStream(sparkSessionForStream: SparkSession): Unit = {

    val noDataBatchesEnabled =
      sparkSessionForStream.sessionState.conf.streamingNoDataMicroBatchesEnabled

    triggerExecutor.execute(() =&gt; {
      ...//Streaming Query 실행 로직
    }
}
</pre></table></code></div></div><p>위의 <code class="language-plaintext highlighter-rouge">TriggerExecutor</code>에서 확인한 것처럼 <code class="language-plaintext highlighter-rouge">execute</code>에 전달된 함수는 Streaming Application이 중지되거나, 사용자가 쿼리를 중지하기 전까지 반복적으로 실행되는 로직이다. 내부 로직이 길기 때문에 큰 기능 단위로 나누어 분석해 보았다.</p><h4 id="micro-batch-loop의-첫-번째-실행과-초기-정보-설정">Micro Batch Loop의 첫 번째 실행과 초기 정보 설정</h4><p>Micro Batch를 실행하는 Loop의 첫 번째 실행은 이후의 다른 실행들과 약간 다른 처리가 존재한다. 기존 실행 이력(Checkpoint에 기록된)을 기반(없다면 사용자의 설정)으로 초기 정보(Starting Offset 등)를 설정해야 하기 때문이다.</p><p><code class="language-plaintext highlighter-rouge">StreamExecution</code>에는 <code class="language-plaintext highlighter-rouge">currentBatchId</code>라는 Long 타입 변수가 존재하는데, 이 값은 각 배치에 할당되는 ID로써 0-based로 1씩 단조 증가하는 값이다. -1로 초기화한 상태에서 실행되므로 이 값이 -1이라면 Loop의 첫번째 실행이라는 것을 판단할 수 있다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>if (currentBatchId &lt; 0) {
  populateStartOffsets(sparkSessionForStream)
  logInfo(s"Stream started from $committedOffsets")
}
</pre></table></code></div></div><p>위와 같이 <code class="language-plaintext highlighter-rouge">currentBatchId</code>가 0 미만의 값인 경우에만 <code class="language-plaintext highlighter-rouge">populateStartOffsets</code>라는 메서드를 실행한다. 매 Micro Batch 마다 <code class="language-plaintext highlighter-rouge">currentBatchId</code>가 계속 1씩 증가므로 최초 실행 시에만 <code class="language-plaintext highlighter-rouge">populateStartOffsets</code>가 실행된다.</p><p><code class="language-plaintext highlighter-rouge">populateStartOffsets</code> 메서드는 Checkpoint에 기록된 Offset Log(WAL), Commit Log를 기반으로</p><ul><li>실행할 배치 ID(<code class="language-plaintext highlighter-rouge">currentBatchId</code>)<li>마지막으로 커밋된 Offset 정보(<code class="language-plaintext highlighter-rouge">committedOffsets</code>)<li>이번 배치에서 처리해야할 Offset 정보(<code class="language-plaintext highlighter-rouge">availableOffsets</code>) 를 초기화한다.</ul><blockquote><p>일부 케이스에서는 <code class="language-plaintext highlighter-rouge">committedOffsets</code>나 <code class="language-plaintext highlighter-rouge">availableOffsets</code>를 초기화할 수 없는 경우도 존재한다. 이러한 경우 내부 변수인 <code class="language-plaintext highlighter-rouge">isCurrentBatchConstructured</code>를 <code class="language-plaintext highlighter-rouge">false</code>로 설정한 뒤, 다음 실행되는 <code class="language-plaintext highlighter-rouge">constructNextBatch</code> 메서드(<code class="language-plaintext highlighter-rouge">isCurrentBatchConstructured</code>가 <code class="language-plaintext highlighter-rouge">false</code>인 경우에만 실행)에서 초기화할 수 있도록 처리된다.</p></blockquote><p>메서드 내부에 분기 처리가 많은데, 대략적인 분기와 해당 분기에서 설정/처리되는 로직, 정보는 아래와 같다.</p><blockquote><p>위에서 말했듯 배치에는 Long 타입의 ID가 부여되며, 매 배치가 끝날 때마다 배치 ID와 동일한 ID를 가지는 Commit이 생성된다는 것을 알고 아래 내용을 읽어본다!</p></blockquote><h5 id="case-1-offset-log에-마지막-실행-정보가-존재하는-경우">Case 1. Offset Log에 마지막 실행 정보가 존재하는 경우</h5><p>Checkpoint Location에 이전 애플리케이션에서 실행하던 Streaming Query에 대한 정보가 남아 있는 상황이다. Checkpoint의 Offset Log를 기반으로 아래 정보들을 초기화 한 뒤, Commit Log를 기반으로 아래 정보들을 보정(업데이트)한다.</p><blockquote><p>위에서 간략히 설명했지만 <code class="language-plaintext highlighter-rouge">committedOffsets</code>와 <code class="language-plaintext highlighter-rouge">availableOffsets</code>라는 용어가 등장한다.</p><p>한 배치의 <code class="language-plaintext highlighter-rouge">committedOffsets</code>와 <code class="language-plaintext highlighter-rouge">availableOffsets</code>는 같다. 다만 <code class="language-plaintext highlighter-rouge">committedOffsets</code>는 배치가 성공적으로 수행된 후 기록되며 <code class="language-plaintext highlighter-rouge">availableOffsets</code>는 배치 수행 전에 미리 기록된다(Write Ahead Log).</p><p>결과적으로 N번째 Micro Batch에서 수행해야 하는 Offset의 범위는 N-1 번째 Micro Batch의 <code class="language-plaintext highlighter-rouge">committedOffsets</code> ~ N 번째 Micro Batch의 <code class="language-plaintext highlighter-rouge">availableOffsets</code> 까지이다.</p></blockquote><ul><li><code class="language-plaintext highlighter-rouge">currentBatchId</code>: Offset Log에 남아 있는 마지막 Batch ID로 설정<li><code class="language-plaintext highlighter-rouge">isCurrentBatchConstructured</code>: 우선 <code class="language-plaintext highlighter-rouge">true</code>로 설정.(다음 배치 정보를 초기화할 필요 없다는 의미)<li><code class="language-plaintext highlighter-rouge">availableOffsets</code>: 실행되었던 마지막 Batch의 <code class="language-plaintext highlighter-rouge">availableOffsets</code>로 설정<li><code class="language-plaintext highlighter-rouge">committedOffsets</code>: 실행되었던 마지막 Batch ID가 0이 아닌 경우(즉, 마지막 전에도 1개 이상의 배치가 존재했던 경우), Last Batch ID - 1 번째의 Batch의 <code class="language-plaintext highlighter-rouge">availableOffsets</code>로 설정된다.</ul><p>위와 같이 Offset Log로 마지막 배치 실행 시의 상황을 대략적으로 추정한 뒤, Commit Log를 기반으로 아래와 같이 보정을 진행한다.</p><ul><li>Offset Log에 기록된 마지막 배치 ID와 Commit Log에 기록된 커밋 ID가 일치하는 경우: 기존 애플리케이션의 마지막 배치가 정상 커밋되어 Gracefully Shutdown 된 경우이다.<ul><li>새로운 배치를 준비(<code class="language-plaintext highlighter-rouge">constructNextBatch</code>의 수행)할 수 있도록 <code class="language-plaintext highlighter-rouge">isCurrentBatchConstructed</code>를 <code class="language-plaintext highlighter-rouge">false</code>로 설정한다.<li>마지막 배치가 정상 수행된 것이므로 <code class="language-plaintext highlighter-rouge">committedOffsets</code>에 마지막 배치의 <code class="language-plaintext highlighter-rouge">availableOffsets</code>를 추가한다.</ul><li>Offset Log에 기록된 마지막 배치 ID가 Commit Log에 기록된 커밋 ID보다 1이 큰 경우: 마지막 배치가 실행 중 비정상 Shutdown 된 경우이다.<ul><li>이 경우 새로운 배치를 준비할 필요가 없다(즉, <code class="language-plaintext highlighter-rouge">isCurrentBatchConstructured</code>를 그대로 <code class="language-plaintext highlighter-rouge">true</code>로 두어도 된다). 마지막 배치가 처리하려던 <code class="language-plaintext highlighter-rouge">availableOffsets</code>까지 처리를 수행하면 되기 때문이다.<li><code class="language-plaintext highlighter-rouge">availableOffsets</code>와 <code class="language-plaintext highlighter-rouge">committedOffsets</code>도 기존과 동일하게 두면 된다.</ul><li>그 이외의 경우: 별도 처리를 하지 않는다.</ul><h5 id="case-2-offset-log에-마지막-실행-정보가-존재하지-않는-경우">Case 2. Offset Log에 마지막 실행 정보가 존재하지 않는 경우</h5><p>기존에 실행된 적 없는 Streaming Query의 실행이다. <code class="language-plaintext highlighter-rouge">currentBatchId</code>가 0으로 설정되며, <code class="language-plaintext highlighter-rouge">isCurrentBatchConstructured</code>가 초기 값인 <code class="language-plaintext highlighter-rouge">false</code>로 남아 있게 된다.</p><h4 id="다음-배치-실행-여부를-결정하는-constructnextbatch-메서드">다음 배치 실행 여부를 결정하는 <code class="language-plaintext highlighter-rouge">constructNextBatch</code> 메서드</h4><p>매 Loop에서는 처리해야 할 새로운 데이터의 존재 여부를 확인하여 존재하는 경우에만 새로운 Micro Batch를 생성한다. 이 때 새로운 데이터의 존재 여부를 확인하는 메서드가 <code class="language-plaintext highlighter-rouge">constructNextBatch</code> 메서드이다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>if (!isCurrentBatchConstructed) {
  isCurrentBatchConstructed = constructNextBatch(noDataBatchesEnabled)
}
</pre></table></code></div></div><p><code class="language-plaintext highlighter-rouge">constructNextBatch</code> 메서드는 위와 같이 <code class="language-plaintext highlighter-rouge">isCurrentBatchConstructured</code>가 <code class="language-plaintext highlighter-rouge">false</code>일 때만 실행되는데, 위에서도 한번 설명했지만 <code class="language-plaintext highlighter-rouge">isCurrentBatchConstructured</code>가 어떨 때 <code class="language-plaintext highlighter-rouge">true</code>이고, 어떨 때 <code class="language-plaintext highlighter-rouge">false</code>로 설정되는지 다시 한번 정리해본다.</p><ul><li><code class="language-plaintext highlighter-rouge">true</code>로 설정되는 경우: 처리할 데이터가 있는 것을 이미 인지한 경우<ul><li>최초 Loop 실행에서 완료되지 않은 이전 배치의 기록이 존재하는 경우</ul><li><code class="language-plaintext highlighter-rouge">false</code>로 설정되는 경우<ul><li>최초 Loop 실행에서 이전 배치가 정상적으로 완료된 경우<li>최초 Loop 실행에서 이전에 Streaming Query가 수행된 적이 없는 경우(Checkpoint Location이 깔끔한 경우)</ul></ul><p><code class="language-plaintext highlighter-rouge">constructNextBatch</code> 내에서는 Streaming Query에서 사용되는 Source들의 현 시점 마지막 Offset을 가져와서 기존 Offset들과 비교하여 새로운 데이터 존재 여부를 확인하는 메서드(<code class="language-plaintext highlighter-rouge">isNewDataAvailable</code>)의 실행 결과와 <code class="language-plaintext highlighter-rouge">lastExecutionRequiresAnotherBatch</code> 값을 결합(OR 연산)하여 다음 배치를 실행해야하는지 여부(<code class="language-plaintext highlighter-rouge">shouldConstructNextBatch</code>)를 결정한다.</p><blockquote><p>주의해야 할 점은 처리할 새로운 데이터가 존재하지 않더라도(<code class="language-plaintext highlighter-rouge">isNewDataAvailable</code>이 <code class="language-plaintext highlighter-rouge">false</code>로 설정되어 있더라도), <code class="language-plaintext highlighter-rouge">lastExecutionRequiredAnotherBatch</code> 값이 <code class="language-plaintext highlighter-rouge">true</code>인 경우 Micro Batch 자체는 생성된다는 점이다</p></blockquote><p><code class="language-plaintext highlighter-rouge">shouldConstructNextBatch</code>는 <code class="language-plaintext highlighter-rouge">constructNextBatch</code>의 반환 값이며, 반환 전에 해당 값이 <code class="language-plaintext highlighter-rouge">true</code>인 경우 WAL에 이번 배치에 처리해야하는 Offset 정보(위에서 소스 별로 가져온 현 시점 마지막 Offset 정보들)를 기록한다.</p><h4 id="1-단위-micro-batch의-실행---runbatch">1 단위 Micro Batch의 실행 - <code class="language-plaintext highlighter-rouge">runBatch</code></h4><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre>currentBatchHasNewData = isNewDataAvailable

currentStatus = currentStatus.copy(isDataAvailable = isNewDataAvailable)
if (isCurrentBatchConstructed) {
  if (currentBatchHasNewData) updateStatusMessage("Processing new data")
  else updateStatusMessage("No new data but cleaning up state")
  runBatch(sparkSessionForStream)
} else {
  updateStatusMessage("Waiting for data to arrive")
}
</pre></table></code></div></div><p><code class="language-plaintext highlighter-rouge">isCurrentBatchConstructured</code>이 <code class="language-plaintext highlighter-rouge">true</code>인 경우 1개 단위의 Micro Batch를 만들고 이를 실행하는 <code class="language-plaintext highlighter-rouge">runBatch</code> 메서드가 실행된다. <code class="language-plaintext highlighter-rouge">runBatch</code>의 경우 스트리밍 소스 데이터와 사용자 쿼리를 기반으로 Plan을 생성하고, 이를 Sink에 기록하는 일련의 과정을 포함하고 있는데, 대략적으로 아래와 같다.</p><ol><li>모든 스트리밍 소스에 대해 처리할 데이터 범위(Offset)를 기반으로 데이터 프레임을 생성한다.<ul><li>이 부분이 <code class="language-plaintext highlighter-rouge">SQL</code> 탭에서 <code class="language-plaintext highlighter-rouge">getBatch</code>라고 기록되는 Phase이다.<li>처리할 오프셋 정보만 초기화된 것이고, 데이터는 아직 Fetch 해 오지 않은 상태이다.</ul><li>Logical Plan(사용자가 작성한 쿼리 혹은 코드)에 데이터 소스 정보를 덧붙인다.<li>Plan 내에서 사용되는 날짜/시간 관련 값들을 Wiring 한다.<li>Plan을 Dataset으로 변환한다.<li>쿼리를 수행하고 결과를 Sink로 내보낸다. 이 때 필요한 경우 Commit 도 수행한다.</ol><h4 id="내부-상태-정리">내부 상태 정리</h4><p>하나의 배치를 완료하였고, 다음 배치 실행 전 아래와 같이 내부 상태를 정리한다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre>if (isCurrentBatchConstructed) {
  currentBatchId += 1
  isCurrentBatchConstructed = false
} else 
  Thread.sleep(pollingDelayMs)
}
</pre></table></code></div></div><p>이번 배치를 수행한 경우에는 <code class="language-plaintext highlighter-rouge">currentBatchId</code>를 1 증가시키고, <code class="language-plaintext highlighter-rouge">isCurrentBatchConstructured</code> 값을 <code class="language-plaintext highlighter-rouge">false</code>로 설정하므로써 다음 실행 시 새로 처리할 데이터 정보를 Fetch 해야한다는 사실을 Marking한다.</p><p>이번 배치를 수행하지 않을 경우에는 <code class="language-plaintext highlighter-rouge">pollingDelayMs</code> 만큼 Sleep 한 뒤 다음 Loop를 실행하게 된다.</p><h1 id="정리">정리</h1><p>처음에는 Spark Structured Streaming에서 Kafka의 시작/종료 Offset을 어떻게 가져오나 정도만 간략히 알아보려는 의도였는데, Streaming Query 실행에 대한 부분이 다른 코드(Spark SQL 등을 처리하는)보다 간단해서 길게 정리하게 되었습니닫.</p><p>원본 글을 참고하긴 했지만 전체적 맥락을 파악하는 수준에서만 참고하였고, 대부분은 코드를 따라가면서 정리했기 때문에 정확하지 않거나 건너뛴 부분이 존재할 수 있습니다.</p><p>다만 이 글을 읽으시는 분들이 Spark Structured Streaming의 실행 순서 정도나 대략적인 동작 원리에 대해서는 알아가시지 않을까 하는 생각입니다. 도움이 되셨으면 좋겠습니다.</p></div><div class="post-tail-wrapper text-muted"><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/apache-spark/" class="post-tag no-text-decoration" >apache-spark</a> <a href="/tags/kafka/" class="post-tag no-text-decoration" >kafka</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Spark Structured Streaming의 MicroBatch 동작 원리 알아보기 - leeyh0216's devlog&url=https://leeyh0216.github.io/posts/spark-structured-streaming-microbatch/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Spark Structured Streaming의 MicroBatch 동작 원리 알아보기 - leeyh0216's devlog&u=https://leeyh0216.github.io/posts/spark-structured-streaming-microbatch/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Spark Structured Streaming의 MicroBatch 동작 원리 알아보기 - leeyh0216's devlog&url=https://leeyh0216.github.io/posts/spark-structured-streaming-microbatch/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/ps/">ps</a> <a class="post-tag" href="/tags/spring/">spring</a> <a class="post-tag" href="/tags/leetcode/">leetcode</a> <a class="post-tag" href="/tags/apache-spark/">apache-spark</a> <a class="post-tag" href="/tags/java/">java</a> <a class="post-tag" href="/tags/kafka/">kafka</a> <a class="post-tag" href="/tags/apache-druid/">apache-druid</a> <a class="post-tag" href="/tags/string/">string</a> <a class="post-tag" href="/tags/study/">study</a> <a class="post-tag" href="/tags/docker/">docker</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/spark-structured-streaming-kafka-sink/"><div class="card-body"> <span class="timeago small" > Jul 31, 2022 <i class="unloaded">2022-07-31T13:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Apache Spark - Spark Structured Streaming Kafka Sink는 Exactly-Once를 지원하지 않는다</h3><div class="text-muted small"><p> Spark Structured Streaming Kafka Sink의 동작에 대해 알아봅니다. 기본적인 사용법보다는 내부적으로 Kafka Sink가 어떻게 동작하는지, 왜 Spark Structured Streaming Kafka Sink의 한계에 대한 이야기를 다루고 있습니다. Spark Structured Streaming Kafka Si...</p></div></div></a></div><div class="card"> <a href="/posts/spark-private-s3-migration/"><div class="card-body"> <span class="timeago small" > Sep 3, 2022 <i class="unloaded">2022-09-03T15:05:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Apache Spark과 S3 Compatible Object Storage 연동 시 Custom Endpoint 이슈</h3><div class="text-muted small"><p> Apache Spark과 S3 Compatible Object Storage 연동 시 Custom Endpoint 이슈 사내에서 개발하는 시스템에서 Apache Spark과 S3 Compatible Object Storage인 Ceph를 연동해야 할 일이 생겼다. Ceph는 S3 Compatible한 Gateway를 제공하기 때문에 Apache S...</p></div></div></a></div><div class="card"> <a href="/posts/spark-udf-null/"><div class="card-body"> <span class="timeago small" > Nov 13, 2018 <i class="unloaded">2018-11-13T10:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Spark UDF와 DataSet에서의 NULL 처리</h3><div class="text-muted small"><p> 개요 Spark SQL에서는 UDF(User Defined Function)를 만들 수 있는 기능을 제공한다. SQL만으로 처리가 힘들거나 코드가 지저분해지는 상황이 발생했을 때 유용하게 사용할 수 있다. 다만 NULL 처리에 관해서는 매우 신경을 써 줘야하는데, 오늘 1시간 넘게 UDF 구현 시 NULL 관련 오류를 접했던 삽질을 정리한다. ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/spark-structured-streaming-kafka-sink/" class="btn btn-outline-primary" prompt="Older"><p>Apache Spark - Spark Structured Streaming Kafka Sink는 Exactly-Once를 지원하지 않는다</p></a> <a href="/posts/spark-private-s3-migration/" class="btn btn-outline-primary" prompt="Newer"><p>Apache Spark과 S3 Compatible Object Storage 연동 시 Custom Endpoint 이슈</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2024 <a href="https://twitter.com/username">leeyh0216</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/ps/">ps</a> <a class="post-tag" href="/tags/spring/">spring</a> <a class="post-tag" href="/tags/leetcode/">leetcode</a> <a class="post-tag" href="/tags/apache-spark/">apache spark</a> <a class="post-tag" href="/tags/java/">java</a> <a class="post-tag" href="/tags/kafka/">kafka</a> <a class="post-tag" href="/tags/apache-druid/">apache druid</a> <a class="post-tag" href="/tags/string/">string</a> <a class="post-tag" href="/tags/study/">study</a> <a class="post-tag" href="/tags/docker/">docker</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://leeyh0216.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
